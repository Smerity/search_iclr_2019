Under review as a conference paper at ICLR 2019
LEARNING ADVERSARIAL EXAMPLES WITH RIEMANNIAN GEOMETRY
Anonymous authors Paper under double-blind review
ABSTRACT
Adversarial examples, referred to as augmented data points generated by imperceptible perturbation of input samples, have recently drawn much attention. Wellcrafted adversarial examples may even mislead state-of-the-art deep models to make wrong predictions easily. To alleviate this problem, many studies focus on investigating how adversarial examples can be generated and/or resisted. All the existing work handles this problem in the Euclidean space, which may however be unable to describe data geometry. In this paper, we propose a generalized framework that addresses the learning problem of adversarial examples with Riemannian geometry. Specifically, we define the local coordinate systems on Riemannian manifold, develop a novel model called Adversarial Training with Riemannian Manifold, and design a series of theory that manages to learn the adversarial examples in the Riemannian space feasibly and efficiently. The proposed work is important in that (1) it is a generalized learning methodology since Riemmanian manifold space would be degraded to the Euclidean space in a special case; (2) it is the first work to tackle the adversarial example problem tractably through the perspective of geometry; (3) from the perspective of geometry, our method leads to the steepest direction of the loss function. We also provide a series of theory showing that our proposed method can truly find the decent direction for the loss function with a comparable computational time against traditional adversarial methods. Finally, the proposed framework demonstrates superior performance to the traditional counterpart methods on benchmark data including MNIST, CIFAR10 and SVHN.
1 INTRODUCTION
Recently Deep Neural Networks (DNN) achieve a big success on a wide range of challengeable tasks, such as image classification, speech recognition, and object detection (LeCun et al., 2015)(He et al., 2017). However, recent studies have found that DNNs can be easily fooled by some special input called adversarial examples which are referred to as augmented data points generated by imperceptible perturbation of input samples (Szegedy et al., 2013)(Biggio et al., 2013)(Nguyen et al., 2015). Although such perturbation is visually imperceptible, it can lead DNNs to make incorrect predictions with high confidence.
There have been a lot of proposals studying how to generate more powerful adversarial examples, and how to build up robust networks to defend them (Goodfellow et al., 2014)(Szegedy et al., 2013). This interesting problem was first studied in (Liu & Nocedal, 1989) where the authors proposed a simple way to produce adversarial examples with L-BFGS optimization. A more powerful approach Fast Gradient Sign Method (FGSM) is later proposed in (Goodfellow et al., 2014) and further extended to a more general case with lp constraint for perturbation (Lyu et al., 2015)(Shaham et al., 2015). The multi-step variant FGSMk was proposed in (Kurakin et al., 2016) which is essentially projected gradient decent (PGD) on the negative loss. Aside from studying how to generate adversarial examples, some researchers developed methods to defend them. The adversarial training was proposed by (Goodfellow et al., 2014) (Lyu et al., 2015) which augmented the training set with adversarial examples. This method not only increases the model robustness for adversarial examples but also improves the generalization for benign samples. Some feature squeezing (Xu et al., 2017) and defensive distillation (Papernot et al., 2016) were also exploited to resist adversarial attacking. Semisupervised version of adversarial training was developed in (Miyato et al., 2015) (Miyato et al.,
1

Under review as a conference paper at ICLR 2019

2018) (Miyato et al., 2016) called Virtual Adversarial Training (VAT), where the output distribution was smoothed by penalizing the KL-divergence between outputs of original and adversarial examples. Moreover, some researchers provided the theory and principles for adversarial examples (Fawzi et al., 2016). Furthermore, (Ma et al., 2018) have demonstrated that the adversarial examples are a dense region of pixel space instead of isolated points.

All these existing adversarial training methods simply consider the adversarial example problem in the Euclidean space with the orthogonal coordinate system. Specifically, this traditional adversarial training methods aim to solve a robust optimization problem (Lyu et al., 2015):

min


E(x,y)

D

[max


L(x

+

,

y,

)]

s.t.

p  

(1)

where L denotes a loss function and the pair of input and label (x, y) is assumed to be drawn from the data distribution D. The robust optimization problem is defined as a min-max problem with respect to the worst perturbation  and the best model parameters . The adversarial perturbation
 is restricted within lp-ball around benign example x. The FGSM can be seen as a special case with p = . Such restriction is defined in Euclidean space and the similarity between two points is
measured by Minkowski distance.

(a) Riemannian space

(b) Euclidean space

Figure 1: 1(a) shows a Riemanian space M , where (t) is the geodesic connecting two points (0) and (a). The distance between these two points is measured by the geodesic distance g. TpM is the tangent space of M at point (0) and ^(t) represents the derivative of curve function (t). 1(b) demonstrates the Euclidean space where the distance between two points is described by Euclidean distance d. Detailed notations can be seen in Section 2.
However, data points may be in practice attached on a geometric manifold which cannot be appropriately described with Euclidean coordinate system. In this case, the Euclidean metric would be not rational. Moreover, existing adversarial training methods usually search the worst perturbation through the gradient of loss function with respect to x, since the gradient is considered as the steepest direction. However, in a geometric manifold, particularly in Riemannian space, the gradient of a loss function unnecessarily presents the steepest direction. Figure 1 illustrates the difference between a Riemannian space and the Euclidean space, where the detailed mathematic notation can be seen in Section 2. Clearly, In this figure, assuming that the data are attached in the manifold as defined in Figure 1(a), the Euclidean distance may not appropriately reflect the true distance between two points (e.g., (0) and (a)).
In this paper, we extend the traditional adversarial problem to Riemannian space and propose a novel adversarial method called Adversarial Training with Riemannian Manifold (ATRM). ATRM is regarded as a generalized framework in that Riemannian space contains the Euclidean space as a special case. In more details, we start with defining the local coordinate system and Riemannian metric tensor to evaluate the similarity between two points in Riemannian space. We then propose to restrict the adversarial perturbation within lp-ball around natural examples x on Riemannian manifold, and develop a framework to search the worst perturbation through the generalized trust region method. Our proposed method is to solve the adversarial problem from the perspective of geometry which is similar to Natural Gradient methods (Amari, 1998), however, our method is implemented on input space instead of parameter space of DNNs.
We list the main contributions of this paper as follows: 1) To our best knowledge, this is the first work to tackle the adversarial example problem through the perspective of geometry. 2) We study the adversarial example in the more generalized Riemannian space of which Euclidean space is a special case. 3) Our method considers the curvature information of the loss function which can be viewed as the second order method, enabling a more accurate direction of adversarial perturbation. Importantly, from the perspective of geometry, our method leads to the steepest direction of loss

2

Under review as a conference paper at ICLR 2019

function in Riemannian space. 4) We also provide a series of theory showing that our proposed method can truly find the decent direction for the loss function with a comparable computational time against traditional adversarial method (one more backward backward prorogation).

2 MAIN METHODOLOGY

In this section, we first study how to generate adversarial examples within l2-ball in Riemannian Manifold. We then define the local metric tensor on the manifold and generate the adversarial
examples using our proposed ATRM with l2-ball restriction. Next, we extend our proposed method to lp-ball restriction on Riemannian manifold. Finally, we propose the adversarial training method called ATRM and also provide theories showing that ATRM can find the decent direction of the loss.

2.1 RIEMANNIAN GEOMETRY

In this subsection, we first introduce the mathematical notations and some background of geometry. The Einstein notation is used in this subsection. The Riemannian Manifold is defined as Definition 2.1:

Definition 2.1. (Riemannian Manifold (Walschap, 2012)) In differential geometry, a Riemannian
manifold (M, g) is a real smooth manifold M equipped with inner product in tangent space TpM at each point p varying smoothly on M , defined by positive definite metric tensor gp.

Theorem 2.1. (Geodesic (Amari, 2016)) A curve that connects two points by a minimal distance is

a geodesic under the Levi-Civita connection, where the length of a curve c = (t) connecting (0)

and (a) is given by

 a l = gij(t)i(t)j(t) dt
0

(2)

where gij(t) denotes the metric tensor at point (t).

The geodesic can be calculated with Theorem 2.1, which measures the distance of two points on Riemannian manifold. It can be seen as an extension of the Euclidian distance in Euclidian space.

Lemma 2.2. Let (0) and (a) be two closed points on Riemannian manifold, where (t) is a shortest curve connecting these two points. Then, we have the square of geodesic distance between these two points:

ds2 = gij (t)didj

(3)

where di = (t)i is the ith component of small vector d and gij(t) is the metric tensor (proof can be seen in Appendix D).

We can also rewrite ds2 in form of inner production:

ds2 = diei, djej = ei, ejdidj

(4)

where basis vectors {ei} is the set of tangent vectors along the coordinate curves. Combining these two equations, we have:

gij = ei, ej 

(5)

Therefore, the metric tensor G = (gij) is the inner product of basis vectors. In the case of Euclidean

space (orthonormal coordinate system), the metric tensor is:

{

gij = ij =

1 0

i=j otherwise

(6)

where ij represents the Kronecker delta. The Euclidean space can be viewed as a special case of Riemannian space with the identity metric tensor. For traditional adversarial training, the data are assumed to be in Euclidean space with the identity metric tensor. In this paper, we consider a more general case that the data are attached on the Riemannian manifold with positive definite metric tensor varying smoothly on the manifold. Figure 1 illustrates the difference between the two spaces.

3

Under review as a conference paper at ICLR 2019

2.2 ADVERSARIAL PERTURBATION WITHIN l2-BALL ON MANIFOLD
In this subsection, we introduce in details how we exploit a generalized trust region method to search the adversarial perturbation on the Riemannian manifold.
To search the adversarial examples on the Riemannian manifold feasibly, we propose to solve the inner optimization problem of (1) with the generalized trust region method:

 = arg max Tk{L, x, }


s.t. d(x, x + )  

(7)

where  is a small perturbation and  is a small value. Tk{L, x, } denotes the kth order Taylor expansion of function L(.) around x evaluated at x + . Here k can be set to 1 or 2. d(x, x + )
represents the distance between two points x and x + . In this paper, we follow the setting of previous research (Lyu et al., 2015) (Shaham et al., 2015) and provide the 1th Taylor expansion for the loss function L(.). We define the d(.) geodesic distance between two points on Riemannian
manifold. Since the perturbation  is very small, by applying Lemma 2.2, (7) can be reformulated
as:

 = arg max L(x) + xLT  s.t.


gij (x)ij  2

(8)

where G = (gij(x)) denotes the metric tensor at the point x on data manifold. In (7), since geodesic d(x, x + )  , the geodesic can be evaluated by (3). It can be proved that we can solve the
problem (8) with Lagrangian multiplier method and the worst perturbation can be given as:

  G-1xL The detailed proof of (9) can be seen in Appendix A.

(9)

2.3 DEFINING METRIC TENSOR
In the previous subsection, we have derived that the direction of the worst perturbation is relevant to metric tensor and the first derivative of L with respect to x. It is easy to evaluate xL in DNNs through back propagation. It is then very crucial to define the metric tensor G. For defining G, we need to rethink the restriction of the problem (7). We first take the nth order Taylor expansion of L around x evaluated at x +  (n is an extremely large value):

L(x + ) = L(x) + L(x1)(x)  + Lx(2)(x) 2 + ... + Lx(n)(x) n

1! 2!

n!

= L(x) + L(x1)(x)  + m(x) 1!

(10)

where L(xn)(x) denotes the nth order derivative of L with respect to x and m(k) = L(x2)(x) 2 + o(x) 2!

(11)

The loss function L(x + ) can be written as summation of its 1th order Taylor expansion and the other components of Taylor series m(x). The 1th order Taylor expansion is more reliable when
|m(x)| is small enough. Naturally, the restriction can be defined as:

d(x, x + )2

=

|m(x)|

=

| Lx(2)(x) 2| 2!

=

1 |T H| 2



2

(12)

However, it is difficult to deal with the constraint (12) in the optimization problem. We can simplify it with its upper bound by using Lemma 2.3.

4

Under review as a conference paper at ICLR 2019

Lemma 2.3. Assume H be a symmetric square matrix in Rn × Rn and r  Rn be a vector. Then we have |rT Hr|  rT |H|r and |H| represents the matrix with taking the absolute value of each
eigenvalue of H (proof can be seen in Appendix E).

Based on Lemma 2.3, we can have

1 |T H|  1 T |H|  2 22

(13)

where H is the Hessian matrix of L with respect to x and  is a small value.

Comparing (13) with constraint of (8), we can define the metric tensor as |H|. Substituting |H| in (8), we can easily get the worst perturbation:

  |H|-1xL

(14)

In contrast to the traditional adversarial training methods, the metric tensor |H|-1 of our method involves the curvature information of the loss function which can be seen as the second order method. Through the perspective of geometry, the direction of gradient is not guaranteed to be steepest in Riemannian space, however, the metric tensor adjusts it to the steepest one as illustrated in Figure 2. Note that, for DNNs, it is easy to evaluate the Hessian matrix of L with respect to input x by back propagation.

Figure 2: The red circle denotes the region of 2  , while the red arrow illustrates the direction of gradient. The blue ellipse shows the region of T |H|  2, the blue arrow represents the direction found by the proposed method, and green lines present the contour lines. The steepest direction is given by the gradient of the loss function, which is orthogonal to contour lines only when an orthonormal coordinate system is used in Euclidean space. In the Riemannian space, the steepest direction is not guaranteed to be orthogonal to contour lines. However, adjusted with the metric tensor |H|-1, the direction of gradient can be approximate to the steepest direction. The graph is better viewed in color.

2.4 ADVERSARIAL PERTURBATION WITHIN lp-BALL ON MANIFOLD

In the previous subsections, we have calculated the worst perturbation within l2-ball on Riemannian manifold. Similar to traditional adversarial training methods, we can also extend our method to lp-ball on manifold. First, we introduce Lemma 2.4 before we proceed to the case of lp-ball.
Lemma 2.4. Let A a real symmetric positive definite matrix in Rn × Rn. Then we have a unique positive definite matrix S in Rn × Rn so that A = S2 (proof can be seen in Appendix F).

Using Lemma 2.4, we reformulate the constraint of (13)

T |H| = T SST  = (T S)2  2

(15)

where S is a positive definite matrix which we call a transformation matrix. Then we can easily extend (15) to lp-ball on manifold:

5

Under review as a conference paper at ICLR 2019

 T Sp = ( |T S|ip)1/p  
i

(16)

Substituting (16) with the constraint of (8), we can easily evaluate the corresponding worst perturbation (details are provided in Appendix B):



=

sign(LT

S-1)(

|LT S-1| LT S-1p

1
) p-1

S -1

(17)

where

p

is

the

dual

of

p,

i.e.,

1 p

+

1 p

=

1.

Clearly,

when

p

=

2,

the

worst

perturbation

is

reduced

to (14) which is the case of the perturbation within l2-ball on manifold. When p = , our method

reduces to the generalized FGSM:



=



lim
p

sign(LT

S

-1

)(

|LT S-1| LT S-1p

)

1 p-1

S

-1

=

sign(LT

S-1)S-1

(18)

Though we can evaluate the adversarial perturbation for any lp-ball on Riemannan manifold through (17). In this paper, we focus on the constraint of l2-ball and will develop the corresponding adversarial training method to improve the performance of DNNs in the next subsection.

2.5 ADVERSARIAL TRAINING METHOD WITH RIEMANNIAN MANIFOLD

After studying the adversarial examples on manifold, we now consider to design an optimization method to improve the DNNs using the theory in the previous subsections. We first define the overall optimization as the robust optimization problem in a way similar to the traditional adversarial training:

min


E(x,y)

D

[max


L(x

+

,

y

,

)]

s.t. T Sp  

(19)

In this paper, we focus on the l2-ball constraint, while it is easily extended to the lp-ball constraint. In the case of l2, we can reduce the constraint in (19) to T |H|  . To optimize this problem, we can first solve the inner optimization problem then followed by the outer one. We then repeat
this process until it converges. The whole process is shown as Algorithm 1. On the other hand, Algorithm 2 demonstrates the function of approximating |H|-1xL(yi, xi, ). More details can be seen in Appendix C.

Algorithm 1 Framework of ensemble learning for our system.

1: for number of training iterations do
2: Sample a batch of labeled data (xi, yi) with size N . 3: for i in 1...N do 4: di  |H|-1xL(yi, xi, ) 5: iadv = di 6: end for
7: Update the parameters of neural network with stochastic gradient:

8: 9:

-

1 N

N
i=1

logL(yi, xi

+

iadv, )

10: end for

In Algorithm 1, |H|-1xL(yi, xi, ) represents the normalization of |H|-1xL(yi, xi, ). We now provide the theoretical analysis showing that our proposed method truly offers the decent di-
rection for the optimization problem as (Madry et al., 2017). In order to do this, we first present
Theorem 2.5.
Theorem 2.5. (Danskin). Let S be nonempty compact topological space and g : R × S  R such that g(., ) is differentiable for every   S and g(, ) is continuous on Rn × S. Also assume () = {  arg maxS g(, )}. Then the max-function () = maxS g(, ) is locally Lipschitz continuous, directionally differentiable, and its directional derivatives satisfy: () = sup() hT g(, ) In particular, if for some   Rn the set () = {} is a singleton, the max-function is differentiable at  and () = g(, ).

6

Under review as a conference paper at ICLR 2019

Algorithm 2 Approximation for |H|-1xL(yi, xi, ).

1: function APPROHD(yi, xi, , )

2: Give  very small value

3: g0 = xL(yi, xi, )

4: g1 = xL(yi, xi + g0, )

5: y = g1 - g0

6: s = g0

7:



=

1 yT s

8:  = sT g1

9: q = g1 - y

10: r0 = q0 11:  = yT r0

12: r1 = r0 + ( - )s

13: return r1

14: end function

This theorem states that the gradients of () are local objects and the gradients are locally the same as that of g(, ). With Theorem 2.5, we describe the theory showing that our proposed optimization method truly offers the decent direction: Lemma 2.6. Let ^  S be a maximizer of maxL(, x+, y). Then, we have that -thetaL(, x+ ^, y) is a decent direction for () = maxS L(, x + , y).
Proof. We apply Theorem 2.5 that g(, ) := L(, x + , y) and S = Bp(), which is defined as the lp-ball with radius  on Riemannian manifold. The directional derivative in the direction of h = L(, x + ^, y) satisfies:

(, h) = sup hT L(, x + .y)  hT h = L(, x + ^, y)22  0
^()

(20)

2.6 COMPUTATIONAL ANALYSIS
Compared with traditional adversarial training methods, our proposed ATRM need compute the Hessian matrix of the loss function with respect to input additionally. It may cost extra computation to calculate the Hessian matrix. Nonetheless, we exploit in this paper the first-order derivative of the loss function to approximate the product of Hessian matrix and the vector, which is shown in Algorithm 2. Therefore, our proposed method requires backward propagation three times and forward prorogation once. Specifically, the first backward prorogation is used to approximate the Hessian matrix, the second one is used to evaluate the adversarial perturbation, and the last time is to update the parameters of DNNs. In contrast to traditional adversarial training methods, our proposed method need merely one additional backward propagation which is acceptable in practice.
3 EXPERIMENT
To validate the efficacy of our proposed method, we conduct a series of experiments on benchmark data including MNIST, CIFAR-10, and SVHN. In these experiments, we compare our proposed ATRM with other competitive methods. For MNIST datasets we use the same baseline as (Rasmus et al., 2015). The same base structure called 'conv-large' is used on dataset CIFAR-10 and SVHN, which follows (Miyato et al., 2018). Specifically, 'conv-large' means a large convolutional neural network with seven convolutional layers and three fully-connected layers with dropout where the size of all the convolutional kernels is 3 × 3.
7

Under review as a conference paper at ICLR 2019

We first implement our proposed ATRM on handwriting dataset MNIST. Since there is no previous adversarial research on this baseline model on this dataset, we conduct the experiment on two methods (adversarial training with l and l2 constraint) for comparison. The model is trained with 60, 000 labeled samples without any data augmentation and is tested with 10, 000 samples. We train the model with a batch size of 32 and the maximum 500 epochs. There are two hyper parameters {, } in Algorithm 1 and Algorithm 2. We set  to a very small value, which is 10-6 in this paper. We tune the value of  in the range of {0.1, 0.2, 0.5, 1, 2, 5, 10}. We use the set of hyper parameters that achieved the best performance on the validation set of size 5, 000, selected randomly from the pool of training samples of size 60, 000.
Table 1 lists the performance of various methods including our proposed ATRM and other competitive methods. Except for ATRM, we also conduct the same experiment for the baseline model and traditional adversarial training methods with l2-ball and l-ball constraint. We conduct the experiment with this same setting for five times and calculate the mean and standard deviation. As observed, our proposed ATRM demonstrates the best performance. In particular, all the adversarial methods achieve remarkably good performance, while the ATRM shows a further improvement. This validates the advantages of our proposed method over the other methods, especially the other traditional adversarial methods.

Table 1: Test performance on MNIST

Method

MNIST Test error rate(%)

SVM

1.40

Dropout (Srivastava et al., 2014)

1.05

Ladder networks (Rasmus et al., 2015) 0.57 ± 0.02

VAT (Miyato et al., 2018)

0.72

RPT (Miyato et al., 2018)

0.82

Baseline (Rasmus et al., 2015)

0.32

Baseline+l adversarial training Baseline+l2 adversarial training
ATRM

0.30 ± 0.013 0.26 ± 0.019 0.22 ± 0.016

For CIFAR-10, we train our proposed model ATRM with 50, 000 labeled samples with data augmentation as conducted in (Miyato et al., 2018) (translation and horizontal flip). The test dataset of CIFAR-10 involves 10, 000 samples. Similar to the experiment on MNIST, we set  to a small vaule 10-6, and tune the value of  in the range of {1, 2, 5, 8, 10}. We run the experiments for five times and report the average performance and corresponding standard deviation.

Table 2: Test performance on CIFAR-10

Method

CIFAR-10 Test error rate(%)

Network in Network (Lin et al., 2013)

8.81

All-CNN (Springenberg et al., 2014)

7.25

Deeply Supervised Net (Lee et al., 2015) 7.97

Highway Network (Srivastava et al., 2015) 7.72

RPT (Miyato et al., 2018)

6.25 ± 0.04

ResNet (1,001 layers) (He et al., 2016)

4.62 ± 0.2

DenseNet (190 layers) (Huang et al., 2017) 3.46

Baseline (Miyato et al., 2018)

6.76 ± 0.07

VAT (Miyato et al., 2018)

5.81 ± 0.02

Baseline+l adversarial training Baseline+l2 adversarial training
ATRM

6.35 ± 0.03 5.82 ± 0.02 5.35 ± 0.03

Table 2 summarizes the results of different methods on CIFAR-10 dataset. In this experiment, we intentionally compare our proposed method ATRM with the other two very deep models, i.e., the densely connected network (DenseNet) with 190 layers and very deep residual network (ResNet)

8

Under review as a conference paper at ICLR 2019

with 1, 001 layers. Overall, our proposed method demonstrates competitive performance. Though not as good as the very deep networks DenseNet and ResNet, the proposed ATRM shows superior performance to those adversarial learning methods and all the other remaining approaches. Once again, this shows that adversarial learning should be conducted on the geometric manifold rather than the traditional Euclidean space.

Table 3: Test performance on SVHN

Method

SVHN Test error rate(%)

Network in Network (Lin et al., 2013)

2.35

Deeply Supervised Net (Lee et al., 2015) 1.92

ResNet (110 layers) (He et al., 2016)

2.01

DenseNet (250 layers) (Huang et al., 2017) 1.74

Baseline

2.09 ± 0.06

Baseline+l adversarial training Baseline+l2 adversarial training
ATRM

1.95 ± 0.05 1.82 ± 0.04 1.56 ± 0.05

The Street View House Numbers (SVHN) dataset contains 32 × 32 colored digit images. There are 73, 257 images in the training set, 26, 032 images in the test set, and 531, 131 images for additional training. We train our model using the same setting as (Huang et al., 2017). As can be clearly observed in Table 3, our method demonstrates the best performance. It is even much better than the very deep networks (DenseNet and ResNet). More importantly, our method achieves an obvious improvement compared with the traditional adversarial training algorithms.

4 CONCLUSION
We present the novel framework called Adversarial Training with Riemannian Manifold (ATRM) which generalizes the traditional adversarial training method to Riemannian space. For traditional adversarial training methods, the worst perturbation is often searched with the gradient xL. However, when the data lay on a geometric manifold defined as a Riemannian manifold, the gradient xL is not the steepest direction, leading the adversarial perturbation is not the worst one. We present a series of theory showing that our method leads to the steepest direction of the loss function in Riemannian space. In practice, we also develop a practical algorithm guaranteeing the decent direction for the loss function at each epoch. Experiments demonstrate encouraging results on benchmark data including MNIST, CIFAR-10 and SVHN.

REFERENCES
Shun-Ichi Amari. Natural gradient works efficiently in learning. Neural computation, 10(2):251­ 276, 1998.
Shun-ichi Amari. Information geometry and its applications. Springer, 2016.
M. S. Bartlett. An inverse matrix adjustment arising in discriminant analysis. Annals of Mathematical Statistics, 22(1):107­111, 1951.
Battista Biggio, Igino Corona, Davide Maiorca, Blaine Nelson, Nedim S rndic´, Pavel Laskov, Giorgio Giacinto, and Fabio Roli. Evasion attacks against machine learning at test time. In Joint European conference on machine learning and knowledge discovery in databases, pp. 387­402. Springer, 2013.
Richard H Byrd, Jorge Nocedal, and Robert B Schnabel. Representations of quasi-newton matrices and their use in limited memory methods. Mathematical Programming, 63(1-3):129­156, 1994.
Alhussein Fawzi, Seyed-Mohsen Moosavi-Dezfooli, and Pascal Frossard. Robustness of classifiers: from adversarial to random noise. In Advances in Neural Information Processing Systems, pp. 1632­1640, 2016.

9

Under review as a conference paper at ICLR 2019
Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples. arXiv preprint arXiv:1412.6572, 2014.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Identity mappings in deep residual networks. In European conference on computer vision, pp. 630­645. Springer, 2016.
Kaiming He, Georgia Gkioxari, Piotr Dolla´r, and Ross Girshick. Mask r-cnn. In Computer Vision (ICCV), 2017 IEEE International Conference on, pp. 2980­2988. IEEE, 2017.
Gao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kilian Q Weinberger. Densely connected convolutional networks. In CVPR, volume 1, pp. 3, 2017.
Alexey Kurakin, Ian Goodfellow, and Samy Bengio. Adversarial machine learning at scale. arXiv preprint arXiv:1611.01236, 2016.
Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. nature, 521(7553):436, 2015.
Chen-Yu Lee, Saining Xie, Patrick Gallagher, Zhengyou Zhang, and Zhuowen Tu. Deeplysupervised nets. In Artificial Intelligence and Statistics, pp. 562­570, 2015.
Min Lin, Qiang Chen, and Shuicheng Yan. Network in network. arXiv preprint arXiv:1312.4400, 2013.
Dong C Liu and Jorge Nocedal. On the limited memory bfgs method for large scale optimization. Mathematical programming, 45(1-3):503­528, 1989.
Chunchuan Lyu, Kaizhu Huang, and Hai-Ning Liang. A unified gradient regularization family for adversarial examples. In Data Mining (ICDM), 2015 IEEE International Conference on, pp. 301­309. IEEE, 2015.
Xingjun Ma, Bo Li, Yisen Wang, Sarah M Erfani, Sudanthi Wijewickrema, Michael E Houle, Grant Schoenebeck, Dawn Song, and James Bailey. Characterizing adversarial subspaces using local intrinsic dimensionality. arXiv preprint arXiv:1801.02613, 2018.
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu. Towards deep learning models resistant to adversarial attacks. arXiv preprint arXiv:1706.06083, 2017.
Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, Ken Nakae, and Shin Ishii. Distributional smoothing with virtual adversarial training. arXiv preprint arXiv:1507.00677, 2015.
Takeru Miyato, Andrew M Dai, and Ian Goodfellow. Adversarial training methods for semisupervised text classification. arXiv preprint arXiv:1605.07725, 2016.
Takeru Miyato, Shin-ichi Maeda, Shin Ishii, and Masanori Koyama. Virtual adversarial training: a regularization method for supervised and semi-supervised learning. IEEE transactions on pattern analysis and machine intelligence, 2018.
Anh Nguyen, Jason Yosinski, and Jeff Clune. Deep neural networks are easily fooled: High confidence predictions for unrecognizable images. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 427­436, 2015.
Nicolas Papernot, Patrick McDaniel, and Ian Goodfellow. Transferability in machine learning: from phenomena to black-box attacks using adversarial samples. arXiv preprint arXiv:1605.07277, 2016.
Antti Rasmus, Mathias Berglund, Mikko Honkala, Harri Valpola, and Tapani Raiko. Semisupervised learning with ladder networks. In Advances in Neural Information Processing Systems, pp. 3546­3554, 2015.
Uri Shaham, Yutaro Yamada, and Sahand Negahban. Understanding adversarial training: Increasing local stability of neural nets through robust optimization. arXiv preprint arXiv:1511.05432, 2015.
Jost Tobias Springenberg, Alexey Dosovitskiy, Thomas Brox, and Martin Riedmiller. Striving for simplicity: The all convolutional net. arXiv preprint arXiv:1412.6806, 2014.
10

Under review as a conference paper at ICLR 2019

Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. Dropout: A simple way to prevent neural networks from overfitting. The Journal of Machine Learning Research, 15(1):1929­1958, 2014.
Rupesh Kumar Srivastava, Klaus Greff, and Ju¨rgen Schmidhuber. Highway networks. arXiv preprint arXiv:1505.00387, 2015.
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, and Rob Fergus. Intriguing properties of neural networks. arXiv preprint arXiv:1312.6199, 2013.
Gerard Walschap. Metric structures in differential geometry, volume 224. Springer Science & Business Media, 2012.
Weilin Xu, David Evans, and Yanjun Qi. Feature squeezing: Detecting adversarial examples in deep neural networks. arXiv preprint arXiv:1704.01155, 2017.

A FIND THE ADVERSARIAL PERTURBATION WITHIN l2-BALL ON MANIFOLD
Recall our goal is to maximize the value of the problem:

arg max L(x) + xLT 

s.t. gij(x)ij  2
Since L(x) is independent of  and the worst perturbation has the norm , then we have:

arg max xLT 

s.t. gij(x)ij = 2
Then we apply the Lagrangian multiplier method on this problem:

arg max xLT  - (gij(x)ij - 2)

Making the first derivative of (21) with respect to  zero, we have:

(21)

Then we have: Therefore:

xL = gij(x)i



=

1 

G-1xL

  G-1xL

B FIND THE ADVERSARIAL PERTURBATION WITH lp-BALL ON MANIFOLD

The optimization problem is:

 = arg max L(x) + xLT 

s.t. T Sp  

11

Under review as a conference paper at ICLR 2019

Similar to Appendix A, we reduce the problem to:
 = arg max L(x) + xLT 

s.t. T Sp = 
We solve it with the Lagrangian multiplier method again and set r = T S and f (r)  rp = . We have

xLrS-1 = (f (r) - ) Then we make the first derivative respect to r:

xLS-1

=

rp-1



 p( i

pi

)1-

1 p

xLS-1

=

 ( r )p-1 p

(x

LS

-1

)

p p-1

=

(



)

p p-1

(

r

)p

p

If we sum over two sides, we have

 (x

LS

-1

)

p p-1

=

 (



)

p p-1

(

r

)p

p

(22)

x LS -1 pp

=

(  )p p



1

(

 p

)

=

xLS-1p

By combining (22) and (23), we have

r

=

sign(LT

S

-1

)(

|LT S-1| LT S-1p

1
) p-1

Since r = T S, we have

(23)



=

sign(LT

S-1)(

|LT S-1| LT S-1p

1
) p-1

S -1

C FIND THE APPROXIMATION FOR |H|-1xL(yi, xi, ).
We develop a modified BFGS method to approximate the |H|-1. To solve the memory problem, we use the simplified Limited-memory BFGS (L-BFGS) to approximate |H|-1xL(yi, xi, ) directly (based on BFGS). We first present Theorem C.1.

12

Under review as a conference paper at ICLR 2019

Theorem C.1. (Sherman Morrison formula (Bartlett, 1951)) Let A  Rn×n be an invertible square matrix and v, u  Rn be column vectors. Then A + uvT is invertible if and only if 1 + vT A-1u = 0. And its inverse is given by

(A

+

uvT )-1

=

A-1

-

A-1uvT A-1 1 + vT A-1u

We then take the second order Taylor expansion for L(x + 1) (where 1 is a small value):

(24)

L(x + 1)  L(x) + L(x)1 + 1T 2L(x)1 If we make the first derivative on both sides with respect to 1, we can have:

L(x + 1) - L(x)  H1 where H denotes the Hessian matrix of L(x) with respect to 1. We can define y = L(x + 1) - L(x), then
y  H1

(25)

Next, we use modified BFGS algorithm to approximate H and let

B = I + M

(26)

where B represents the approximation for H, I is identity matrix, and M denotes difference matrix. Our aim is to evaluate M . First we define

M = auuT + bvvT

(27)

where a, b  R and u, v  RN are undetermined. It is easy to get that M is symmetric. We combine (27), (26) and (25):

y = I1 + auuT 1 + bvvT 1 = I1 + (auT 1)u + (bvT 1)v

We can further assume

auT 1 = 1, bvT 1 = -1

Therefore, we have

1 a = uT 1 ,

b

=

-

1 vT 1

If we combine (28) and (30), we have

(28) (29) (30)

u - v = y - I1

Therefore, we can set

u = y, v = I1

By combining (32) and (30), we have 1
a = yT 1 ,

b

=

-

1 T1 I1

13

(31) (32) (33)

Under review as a conference paper at ICLR 2019

Then, we combine (26), (32), and (33):

B

=

I

+

yyT yT 1

-

11T 1T 1

(34)

(34) can be viewed as a simplified BFGS method with one step approximation. When the dimension

of s this

and 1 increases, a large amount of memory is needed problem, we then use the simplified L-BFGS method

to to

store the evaluate

matrix ssT directly |H

|a-n1d1xL1T(.yTi,oxsio, lv)e.

We first use Theorem C.1 to reformulate (34) as:

D

=

(I

-

1yT yT 1

)(I

-

y1T yT 1

)

+

1T1 yT 1

Then, we can easily implement the method L-BFGS as (Byrd et al., 1994) and get Algorithm 3.

Algorithm 3 Approximation for |H|-1xL(yi, xi, ).

1: function APPROHD(yi, xi, , )

2: Set  to a very small value

3: g0 = xL(yi, xi, )

4: g1 = xL(yi, xi + g0, )

5: y = g1 - g0

6: s = g0

7:



=

1 yT s

8:  = sT g1

9: q = g1 - y

10: r0 = q0 11:  = yT r0

12: r1 = r0 + ( - )s

13: return r1

14: end function

D PROOF FOR LEMMA 2.2

Let (0) and (a) be two closed points on Riemannian manifold, where (t) is a shortest curve connecting these two points. Then, we have the square of geodesic distance between these two points:

ds2 = gij (t)didj

(35)

where di = (t)i is the ith component of small vector d and gij(t) is the metric tensor.

Proof. We evaluate the geodesic distance between (0) and (a) through Theorem 2.1:

 a

ds =

gij(t)i(t)j(t) dt

0

Since (0) and (a) are closed points, a  0. Then we have

 a



ds

=

lim
a0

0

gij(t)i(t)j(t) dt = gij(t)i(t)j(t)

Therefore, we have

ds2 = gij (t)didj

(36) (37) (38)

14

Under review as a conference paper at ICLR 2019

E PROOF FOR LEMMA 2.3
Assume H be a symmetric square matrix in Rn × Rn and r  Rn be a vector. Then we have |rT Hr|  rT |H|r and |H| represents the matrix with taking the absolute value of each eigenvalue of H.
Proof. Assume {e1, e2, ..., en} and {1, 2, ..., n} are the eigenvectors and corresponding eigenvalues of matrix H. Then we reformulate |rT Hr| with eigenvectors and corresponding eigenvalues as:

 |rT Hr| = | (rT ei)i(eiT r)| = | i(rT ei)2|
ii
 We can now use the triangle inequality | i ri|  i|ri| and we have:
 |rT Hr|  |i(rT ei)2| = (rT ei)||(rT ei) = rT |H|r
ii

(39) (40)

F PROOF FOR LEMMA 2.4
Let A be a real symmetric positive definite matrix in Rn × Rn. Then we have a unique positive definite matrix S in Rn × Rn so that A = S2.
Proof. To prove existence: Since A is a real symmetric positive definite matrix, we have A = P T diag(1, ..., n)P , where P is an orthogonal matrix and {i} are the Eigen values of A (i > 0).
11
We can find S = P T diag(12 , ..., n2 ) that A = S2. To prove uniqueness: Let B be another positive definite matrix and A = B2. Since B is positive definite, we have A = T T diag(µ1, ..., µn)T , where T is an orthogonal matrix and {µi} are Eigen values of B (µi > 0). We have A = P T diag(1, ..., n)P , therefore

T -1diag(µ1, ..., µn)T = P -1diag(1, ..., n)P

(41)

Let U = (uij)n×n = P T -1 and we have:

diag(µ21, ..., µ2n)U = U diag(1, ..., n)

(42)

which is equivalent to:

iuij = uij µ2j

(43)

11
When  = µ2j , uij = 0, we have i2 = uijµj. When i = µ2j , we also have i2 = uijµj. Therefore:

11
diag(µ1, ..., µn)U = U diag(12 , ..., n2 )

(44)

Then we have:

B

=

T -1diag(µ1, ..., µn)T

=

P

-1

1
diag(12

,

...,

1
n2

)P

=

S

(45)

15

