Under review as a conference paper at ICLR 2019
LEARNING TO REPRESENT EDITS
Anonymous authors Paper under double-blind review
ABSTRACT
We introduce the problem of learning distributed representations of edits. By combining a "neural editor" with an "edit encoder", our models learn to represent the salient information of an edit and can be used to apply edits to new inputs. We experiment on natural language and source code edit data. Our evaluation yields promising results that suggest that our neural network models learn to capture the structure and semantics of edits. We hope that this interesting task and data source will inspire other researchers to work further on this problem.
1 INTRODUCTION
One great advantage of electronic storage of documents is the ease with which we can edit them, and edits are performed in a wide variety of contents. For example, right before a conference deadline, papers worldwide are finalized and polished, often involving common fixes for grammar, clarity and style. Would it be possible to automatically extract rules from these common edits? Similarly, program source code is constantly changed to implement new features, follow best practices and fix bugs. With the widespread deployment of (implicit) version control systems, these edits are quickly archived, creating a major data stream that we can learn from.
In this work, we study the problem of learning distributed representations of edits. We only look at small edits with simple semantics that are more likely to appear often and do not consider larger edits; i.e., we consider "add definite articles" rather than "rewrite act 2, scene 3." Concretely, we focus on two questions: i) Can we group semantically equivalent edits together, so that we can automatically recognize common edit patterns? ii) Can we automatically transfer edits from one context to another? A solution to the first question would yield a practical tool for copy editors and programmers alike, automatically identifying the most common changes. By leveraging tools from program synthesis, such groups of edits could be turned into interpretable rules and scripts (Rolim et al., 2017). When there is no simple hard rule explaining how to apply an edit, an answer to the second question would be of great use, e.g., to automatically rewrite natural language following some stylistic rule.
We propose to handle edit data in an autoencoder-style framework, in which an "edit encoder" f is trained to compute a representation of an edit x-  x+, and a "neural editor"  is trained to construct x+ from the edit representation and x-. This framework ensures that the edit representation is semantically meaningful, and a sufficiently strong neural editor allows this representation to not be specific to the changed element. We experiment with various neural architectures that can learn to represent and apply edits and hope to direct the attention of the research community to this new and interesting data source, leading to better datasets and stronger models.
Briefly, the contributions of our paper are: (a) in Sect. 2, we present a new and important machine learning task on learning representations of edits (b) we present a family of models that capture the structure of edits and compute efficient representations in Sect. 3 (c) we create a new source code edit dataset, which we release at anonymousLocation (d) we perform a set of experiments on the learned edit representations in Sect. 4 for natural language text and source code and present promising empirical evidence that our models succeed in capturing the semantics of edits.
2 TASK
In this work, we are interested in learning to represent and apply edits on discrete sequential or structured data, such as text or source code parse trees. Figure 1 gives a graphical overview of the task, described precisely below.
1

Under review as a conference paper at ICLR 2019

Edit 1

x-: var greenList = trivia==null ? null : trivia.Select(t=> t.UnderlyingNode);
x+: var greenList = trivia?.Select(t=> t.UnderlyingNode);

Edit Representation f(x-, x+)  Rn

Edit 2

x-: me = ((ue!=null) ? ue.Operand : null) as MemberExpression;
x+: me = ue?.Operand as MemberExpression;

Neural Editor (x-, f(x-, x+))

Figure 1: Given an edit (Edit 1) of x- to x+, f computes an edit representation vector. Using that representation vector the neural editor  applies the same edit to a new x-. The code snippets shown here are real code change examples from the roslyn open-source compiler project.
Edit Representation Given a dataset of edits {x(-i)  x(+i)}iN=1, where x(-i) is the original version of some object and x+(i) its edited form (see upper half of Figure 1 for an example), our goal is to learn a representation function f that maps an edit operation x-  x+ to a real-valued edit representation f(x-, x+)  Rn. A desired quality of f is for the computed edit representations to have the property that semantically similar edits have nearby representations in Rn, which allows unsupervised clustering of similar changes and many other downstream tasks.

Neural Editor Given an edit representation function f, we want to learn to apply edits in a new context. This can be achieved by learning a neural editor  that accepts an edit representation
f(x-, x+) and a new input x- and generates x+. This is illustrated in the lower half of Figure 1.

3 MODEL

We cast the edit representation problem as an autoencoding task, where we aim to minimize the
reconstruction error of  for the edited version x+ given the edit representation f(x-, x+) and the original version x-. By limiting the capacity of f's output and allowing the model to freely use information about x-, we are introducing a "bottleneck" that forces the overall framework to not simply treat f(x-, x+) as an encoder of x+. The main difference from traditional autoencoders is that in our setup, an optimal solution requires to re-use as much information as possible from x- to make the most of the capacity of f. Formally, given a probabilistic editor function P such as a neural network and a dataset {x(-i)  x(+i)}Ni=1, we seek to minimize the negative likelihood loss

L=-1 N

log P(x+ | x-, f(x-, x+)).

i

Note that this loss function can be interpreted in two ways: (1) as a conditional autoencoder that
encodes the salient information of an edit, given x- and (2) as an encoder-decoder model that encodes x- and decodes x+ conditioned on the edit representation f(x-, x+). In the rest of this section, we discuss our methods to model P and f as neural networks.

3.1 NEURAL EDITOR
As discussed above,  should retrieve as much information as possible from x-, and hence, an encoder-decoder architecture with the ability to copy from the input is most appropriate. As we are primarily interested in edits on text and source code in this work, we explored two architectures: a sequence-to-sequence model for text, and a graph-to-tree model for source code, whose known semantics we can leverage both on the encoder as well as on the decoder side. Other classes of edits, for example, image manipulation, would most likely be better served by convolutional neural models.

Sequence-to-Sequence Neural Editor First, we consider a standard sequence-to-sequence model with attention (over the tokens of x-). The architecture of our sequence-to-sequence model is similar to that of Bahdanau et al. (2014), with the difference that we use a bidirectional LSTM in the encoder

2

Under review as a conference paper at ICLR 2019

AssignStmt Expr

AST Child Next Token

h1 root  Expr h2 Expr  Expr Op Expr

h EXPANDR action h GENTERM action h TREECP action

u=x+x (a)

h3 TREECP Expr h4 Op  - h5 Expr  IntLit
h6 IntLit  23 (b)

Action Flow Parent Feed Copied

Figure 2: (a) Graph representation of statement u = x + x. Rectangular (resp. rounded) nodes denote tokens (resp. non-terminals). (b) Sequence of tree decoding steps yielding x + x - 23, where x + x is copied (using the TREECP action) from the context graph in (a).

and a token-level copying mechanism (Vinyals et al., 2015) that directly copies tokens into the decoded sequence. Whereas in standard sequence-to-sequence models the decoder is initialized with the representation computed by the encoder, we initialize it with the concatenation of encoder output and the edit representation. We also feed the edit representation as input to the decoder LSTM at each decoding time step. This allows the LSTM decoder to take the edit representation into consideration while generating the output sequence.
Graph-to-Tree Neural Editor Our second model aims to take advantage of the additional structure of x- and x+. To achieve this, we combine a graph-based encoder with a tree-based decoder. We use T (x) to denote a tree representation of an element, e.g., the abstract syntax tree (AST) of a fragment of source code. We extend T (x) into a graph form G(x) by encoding additional relationships (e.g., the "next token" relationship between terminal nodes, etc.) (see Figure 2(a)). To encode the elements of G(x-) into vector representations, we use a gated graph neural network (GGNN) (Li et al., 2015). Similarly to recurrent neural networks for sequences (such as biRNNs), GGNNs compute a representation for each node in the graph, which can be used in the attention mechanisms of a decoder. Additionally, we use them to obtain a representation of the full input x-, by computing their weighted average following the strategy of Gilmer et al. (2017) (i.e., computing a score for each node, normalizing scores with a softmax, and using the resulting values as weights).
Our tree decoder follows the semantic parsing model of Yin & Neubig (2017), who sequentially generate a tree T (x+) as a series of expansion actions a1 . . . aN . The probability of taking an action is modeled as p(at | a<t, s), where s is the input (a sequence of words in the original semantic parsing setting) and a<t is the partial tree that has been generated so far. The model of Yin & Neubig (2017) has two types of actions: EXPANDR expands the current non-terminal using a grammar rule, and GENTERM generates a terminal token from a vocabulary or copies a token from s. The dependence on the partial tree a<t is modeled by an LSTM cell which is used to maintain state throughout the generation procedure. Additionally, the LSTM receives the decoder state used to pick the action at the parent node as an additional input ("parent-feeding"). This process illustrated in Figure 2(b).
We extend this model to our setting by replacing the input sequence s by x-; concretely, we condition the decoder on the graph-level representation computed for G(x-). Additionally, we use the change representation f(·) as an additional input to the LSTM initial state and at every decoding step. Based on the observation that edits to source code often manipulate the syntax tree by moving expressions around (e.g. by nesting statements in a conditional, or renaming a function while keeping its arguments), we extend the decoding model of Yin & Neubig (2017) by adding a facility to copy entire subtrees from the input. For this, we add a decoder action TREECP. This action is similar to standard copying mechanism known from pointer networks (Vinyals et al., 2015), but instead of copying only a single token, it copies the whole subtree pointed to.
However, adding the TREECP action means that there are many correct generation sequences for a target tree. This problem appears in token-copying as well, but can be easily circumvented by marginalizing over all correct choices at each generation step (by normalizing the probability distribution over allowed actions to sum up those that have the same effect). In the subtree-copying setting, this solution is insufficient, as the lengths of action sequences representing different choices may differ. We follow Liu et al. (2018) to handle this problem during training and simply pick one correct generation sequence (the one greedily selecting TREECP) but change the objective such that

3

Under review as a conference paper at ICLR 2019

--==== v .F=x+x u = x + x

AssignStmt

FieldAccess

Expr

v . F=x+x

AssignStmt Expr
u=x+x

(a) (b)
Figure 3: Sequence (a) and graph (b) representation of edit of v.F = x + x to u = x + x.

no correct decoder action choice is penalized; achieved by a "many-hot" encoding of correct choices. At test time, we resolve the issue by using beam search and merging beams with identical results.
3.2 EDIT REPRESENTATION
To compute a useful edit representation, a model needs to focus on the differences between x- and x+. A risk in our framework is that f degenerates into an encoder for x+, turning  into a decoder. To avoid this, we need to follow the standard autoencoder trick, i.e. it is important to limit the capacity of the result of f by generating the edit representation into a low-dimensional space RN that acts as a bottleneck and encodes only the information that is needed to reconstruct x+ from x-. We again experimented with both sequence-based and graph-based representations of edits.
Sequence Encoding of Edits Given x- (resp. x+) as sequence of tokens t(-0), . . . t(-T-) (resp. t(+0), . . . t+(T+)), we can use a standard (deterministic) diffing algorithm to compute an alignment of tokens in the two sequences. We then use extra symbols  for padding, + for additions, - for deletions,  for replacements, and = for unchanged tokens to generate a single sequence representing both x- and x+. This is illustrated in Figure 3(a). By embedding the three entries in each element of the sequence separately and concatenating their representation, they can be fed into a standard sequence encoder whose final state is our desired edit representation. In this work, we use a biLSTM.
Graph Encoding of Edits As in the graph-to-tree neural editor, we represent x- and x+ as trees T (x-) and T (x+). We combine these trees into a graph representation G(x-  x+) by merging both trees into one graph, using "Removed", "Added" and "Replaced" edges. To connect the two trees, we compute the same alignment as in the sequence case, connecting leaves that are the same and each replaced leaf to its replacement. We also propagate this information up in the trees, i.e., two inner nodes are connected by "=" edges if all their descendants are connected by "=" edges. This is illustrated in Figure 3(b). Finally, we also use the same "+" / "-" / "" / "=" tags for the initial node representation, computing it as the concatenation of the string label (i.e. token or nonterminal name) and the embedding of the tag. To obtain an edit representation, we use a GGNN unrolled for a fixed number of timesteps and again use the weighted averaging strategy of Gilmer et al. (2017).
4 EVALUATION
Evaluating an unsupervised representation learning method is challenging, especially for a newly defined task. Here, we aim to evaluate the quality of the learned edit representations with a series of qualitative and quantitative metrics on natural language and source code. Throughout the evaluation we use a fixed size of 512 for all edit representations.
4.1 DATASETS
Natural Language Edits We use the WikiAtomicEdits (Faruqui et al., 2018) dataset of pairs of short edits on Wikipedia articles. We sampled 1040K edits from the English insertion portion of the dataset and split the samples into 1000K/20K/20K train-valid-test sets.
Source Code Edits To obtain a dataset for source code, we clone a set of 54 C# projects on GitHub and collected a GitHubEdits dataset (see Appendix A for more information). We selected all changes

4

Under review as a conference paper at ICLR 2019

in the projects that are no more than 3 lines long and whose surrounding 3 lines of code before and after the edited lines has not been changed, ensuring that the edits are separate and short. We then parsed the two versions of the source code and take as x- and x+ the code that belongs to the top-most AST node that contains the edited lines. Finally, we remove trivial changes such variable renaming, changes within comments or formatting changes. Overall, this yields 111 724 edit samples. For each edit we run a simple C# analysis to detect all variables and normalize variable names such that each unique variable within x- and x+ has a unique normalized name V0, V1, etc. This step is necessary to avoid the sparsity of data induced by the variety of different identifier naming schemes. We split the dataset into 91 372 / 10 176 / 10 176 samples as train/valid/test sets.
Additionally, we introduce a labeled dataset of source code edits by using C# "fixers". Fixers are small tools built on top of the C# compiler, used to perform common refactoring and modernization tasks (e.g., using new syntactic sugar). We selected 16 of these fixers and ran them on 6 C# projects to generate a small C#Fixers dataset of 2,878 edit pairs with known semantics. We present descriptions and examples of each fixer in Appendix A.

4.2 QUALITY OF EDIT REPRESENTATIONS First, study the ability of our models to encode edits in a semantically meaningful way.

Visualizing Edits on Fixers Data In a first

experiment, we train our sequential neural editor model on our GitHubEdits data and then compute

RCS1146

representations for the edits generated by the

C# fixers. A t-SNE visualization (Maaten & Hinton, 2008) of the encodings is shown in

RCS1146

Figure 4. For this visualization, we randomly selected 100 examples from the edits of each

RCS1206

fixer (if that fixer has more than 100 samples)

RCS1077

RCS1207

and discarded fixer categories with less than 40

examples. Readers are referred to Appendix A

for detailed descriptions of each fixer category. We find that our model produces dense clusters for simple or distinctive code edits, e.g.

RCS1089 CA2007

IDE004

RCS1021

fixer RCS1089 (using the ++ or -- unary

operators instead of a binary operator (e.g.,

i = i + 1  i++), and fixer CA2007 (adding .ConfigureAwait(false) for await statements). We also analyzed cases where (1) the edit examples from the same fixer

Figure 4: t-SNE visualization of edits from 13 C# fixers, where point color indicates the fixer. Labels indicate the id of the fixer, see main text.

are scattered, or (2) the clusters of different fixers overlap with each other. For example, the fixer

RCS1077 covers 13 different aspects of optimizing LINQ method calls (e.g., type casting, counting,

etc.), and hence its edits are scattered. On the other hand, fixers RCS1146 and RCS1206 yield

overlapping clusters, as both fixers change code to use the ?. operator. Fixers RCS1207 (change

a lambda to a method group, e.g. foo(x=>bar(x))  foo(bar)) and RCS1021 (simplify

lambda expressions, e.g. foo(x=>{return 4;})  foo(x=>4)) are similar, as both inline

lambda expressions in two different ways. Analysis yields that the representation is highly dependent

on surface tokens. For instance, IDE004 (removing redundant type casts, e.g. (int)2  2) and

RCS1207 (removing explicit argument lists) yield overlapping clusters, as both involve deleting

identifiers wrapped by parentheses.

Human Evaluation on Encoding Natural Language WikiAtomicEdits In a second experiment, we evaluate how well neighborhoods in edit representation space correspond to semantic similarity. For this, we computed the five nearest neighbors of 200 randomly sampled edits from our training set, using both our trained sequence-to-sequence editing model with sequential edit encoder, as well as a simple bag-of-words baseline based on TF-IDF scores. We then rated the quality of the retrieved neighbors on a scale of 0 ("unrelated edit"), 1 ("similar edit") and 2 ("semantically or syntactically same edit"). We show the (normalized) discounted cumulative gain (DCG, Manning et al. (2008)) for the two models at the top of Tab. 1 (higher is better). The results indicate that our neural model

5

Under review as a conference paper at ICLR 2019

Bag of Words Model

Seq2Seq ­ Seq Edit Encoder

DCG@5 by edit size NDCG@5

9.3 1: 14.7 67.3%

2-3: 10.8

>3: 5.4

13.5 1: 16.2 90.3%

2-3: 12.9

>3: 12.4

she , along with her follow artist carolyn mase studied with impressionist landscape painter john henry

twachtman at the art students league of new york .

NN-1 his brother was draughtsman william daniell the first painting was a portrait of a young girl

and his uncle was landscape painter thomas , emerantia van beresteyn , the sister of the

daniell .

landscape painter nicolaes van beresteyn , the

later founder of half of this hofje .

NN-2 william james linton ( december 7 , 1812 - de- he was the club 's top scorer with 22 goals in

cember 29 , 1897 ) was an english - born ameri- all competitions , one more than senegalese

can wood engraver , landscape painter , po- striker lamine diarra , who left the club at the

litical reformer and author of memoirs , novels , end of the season .

poetry and non-fiction .

NN-3 early on , hopper modeled his style after chase caforio " aggressively attacked " his opponent ,

and french impressionist masters douard republican incumbent steve knight , for his

manet and edgar degas .

delayed response to the leak .

daniel james nava ( born february 22 , 1983 ) is an american professional baseball outfielder nava is only

the fourth player in mlb history to hit a grand slam in his first major league at bat and the second to do it on the

first pitch .

NN-1 he batted .302 with 73 steals , and received a arthur ray briles ( born december 3 , 1955 )

september call - up to the major leagues as an is a former american football coach and his

outfielder .

most recent head coaching position was at bay-

lor university , a position he held from the 2008

season through the 2015 season .

NN-2 he played as an outfielder for the hanshin jonathan david disalvatore ( born march 30

tigers .

, 1981 ) is a professional ice hockey he was

selected by the san jose sharks in the 4th round

( 104th overall ) of the 2000 nhl entry draft .

NN-3 in 2012 , his senior at oak mountain , dahl had a professor paul talalay ( born march 31 , 1923

.412 batting average , 34 runs batted in ( rbis ) , ) is the john jacob abel distinguished service

and 18 stolen bases as an outfielder .

professor of pharmacology and director of the

laboratory for molecular sciences at johns hop-

kins school of medicine in baltimore .

Table 1: Natural language human evaluation results and 3 nearest neighbors. Inserted text marked.

clearly outperforms the simplistic baseline. Tab. 1 also presents example edits we sampled along with their nearest neighbors, which show that the neural model succeeded in learning semantics of edits for both n-grams (upper example) and complex clauses (lower example). We observed that the edit representations learned by the neural editing model on WikiAtomicEdits are somewhat sensitive to position, i.e. the position of the inserted tokens in both the seed edit and the nearest neighbors is similar. This is illustrated in the first example in Tab. 1, where the second ("senegalese striker") and the third ("republican incumbent") nearest neighbors returned by the neural model have similar editing positions as the seed edit, while they are semantically diverse.

4.3 EDIT ENCODER PERFORMANCE
To evaluate the performance of our two edit encoders discussed in Sect. 3.2 and disentangle it from the choice of neural editor, we train various combinations of our neural editor model and manually evaluate the quality of the edit representation. More specifically, we trained our neural editor models on GitHubEdits and randomly sampled 200 seed edits and computed their 3 nearest neighbors using each end-to-end model. We then rated the resulting groups using the same 0-2 scale as above. The resulting relevance scores are shown in Tab. 2.
Comparing the sequential edit encoders trained with Seq2Seq and Graph2Tree editors, we found that the edit encoder trained with the Graph2Tree objective performs better. We hypothesize that this is because the Graph2Tree editor better captures structural-level information about an edit. For instance, Example 1 in Tab. 3 removes explicit type casting. The Seq2Seq editor has difficulty distinguishing

6

Under review as a conference paper at ICLR 2019

Table 2: Relevance scores of human evaluation on GitHubEdits data. Acc.@1 denotes the ratio that the 1-nearest neighbor has a score 2.

Model

DCG@3 NDCG@3 (%) Acc.@1 (%)

BoW Seq2Seq ­ Seq Edit Encoder Graph2Tree ­ Seq Edit Encoder Graph2Tree ­ Graph Edit Encoder

7.77 10.09 10.56 9.44

75.99 90.05 91.40 86.20

58.46 75.90 79.49 72.31

Table 3: Two example source code edits and their nearest neighbors based on the edit representations

computed by each model.

Example 1

Example 2

x-: V0.SendSelectSoundRequest((int)V1); x+: V0.SendSelectSoundRequest(V1);

x-: string V0; string V1; x+: string V1; string V0;

Seq2Seq ­ Seq Edit Encoder
x-: V0.Debug(() => LITERAL); x+: V0.Debug(LITERAL);

Seq2Seq ­ Seq Edit Encoder
x-: RetryConfig V0; string V1; x+: string V1; RetryConfig V0;

x-: V0.Debug(() => LITERAL); x+: V0.Debug(LITERAL);

x-: string[] V0; string[] V1; int V2; x+: int V2; string[] V0; string[] V1;

x-: V0.WriteCompressedInteger((uint)V1); x+: V0.WriteCompressedInteger(V1);

x-: Type V0= null; BindingFlags V1= 0; x+: BindingFlags V1= 0; Type V0= null;

Graph2Tree ­ Seq Edit Encoder
x-: V0.WriteCompressedInteger((uint)V1); x+: V0.WriteCompressedInteger(V1);

Graph2Tree ­ Seq Edit Encoder
x-: RetryConfig V0; string V1; x+: string V1; RetryConfig V0;

x-: V0.WriteCompressedInteger((uint)V1); x+: V0.WriteCompressedInteger(V1);

x-: string[] V0; string[] V1; int V2; x+: int V2; string[] V0; string[] V1;

x-: V0.WriteCompressedInteger((uint)V1); x+: V0.WriteCompressedInteger(V1);

x-: int V0 = V1; int V2 = V3; x+: int V2 = V3; int V0 = V1;

Graph2Tree ­ Graph Edit Encoder
x-: V0.UpdateLastRead(this.V1); x+: V0.UpdateLastRead(V1);

Graph2Tree ­ Graph Edit Encoder
x-: RetryConfig V0; string V1; x+: string V1; RetryConfig V0;

x-: V0.UpdateLastWrite(this.V1); x+: V0.UpdateLastWrite(V1);

x-: int V0 = V1; int V2 = V3; x+: int V2 = V3; int V0 = V1;

x-: V0.Append(this.V1); x+: V0.Append(V1);

x-: double V0= -1; double V1= -1; x+: double V1= -1; double V0= -1;

this type of edit, confusing it with changes of lambda expressions to method groups (1st and 2nd nearest neighbors) since both two types of edits involve removing paired parentheses.
Surprisingly, we found that the graph-based edit encoder does not outperform the sequence-based encoder. However, we observe that the graph edit encoder in many cases tends to better capture high-level and abstract structural edit patterns. Example 2 in Tab. 3 showcases a seed edit that swaps two consecutive declarations, which corresponds to swapping the intermediate Expression nodes representing each statement on the underlying AST. In this case, the graph edit encoder is capable of grouping semantically similar edits, while it seems to be more difficult for the sequential encoder encoder to capture the edit pattern. On the other hand, we found that the graph edit encoder often fails to capture simpler, lexical level edits (e.g., Example 1). This might suggest that terminal node information is not effectively propagated, an interesting issue worth future investigation.
4.4 PRECISION OF NEURAL EDITORS
Finally, we evaluate the performance of our end-to-end system by predicting the edited input x+ given x- and the edit representation. We are interested in answering two research questions: First, how well can our neural editors generate x+ given the gold-standard edit representation f(x-, x+)? Second, and perhaps more interestingly, can we use the representation of a similar edit f(x-, x+) to generate x+ by applying that edit to x- (i.e. x^+ = (x-, f(x-, x+)))?
To answer the first question, we trained our neural editor models on the WikiAtomicEdits and the GitHubEdits dataset, and evaluate the performance of encoding and applying edits on test sets. Tab. 4 lists the evaluation results. On WikiAtomicEdits, our Seq2Seq editor with the sequential edit encoder achieves an accuracy of 72.9%, demonstrating that the neural editor is capable of using the edit
7

Under review as a conference paper at ICLR 2019

Table 4: Test performance of different neural editors.

Model

Acc.@1 (%) Recall@5 (%) PPL per token

GitHubEdits Seq2Seq ­ Seq Edit Encoder Graph2Tree ­ Seq Edit Encoder Graph2Tree ­ Graph Edit Encoder
WikiAtomicEdits Seq2Seq ­ Seq Edit Encoder

59.63 57.49 48.05
72.94

65.46 62.94 56.51
76.53

1.2792 1.3043 1.3712
1.0527

Table 5: Transfer learning results on C# fixers data, averaged across all fixer categories.

Model

Acc.(%) Acc.(%) Recall@5(%) Recall@5(%)

Seq2Seq ­ Seq Edit Encoder

38.35

77.67

41.50

83.84

Graph2Tree ­ Seq Edit Encoder 49.21

77.30

51.93

81.77

: upper-bound performance of predicting x+ using the gold-standard edit representations.

representation to make high-quality edits. On the GitHubEdits dataset, we find that the Seq2Seq editor with sequential edit encoder registers the best performance. However, it should be noted that better performance does not necessarily imply better (more generalizable) edit representation, since we encode the gold-standard edit f(x-, x+) to predict x+. Nevertheless, we hypothesize that the higher accuracy of the Seq2Seq edit is due to the fact that a significant proportion of edits in this dataset is small and primarily syntactically simple. Indeed we find that 69% of test examples have a token-level edit distance of less than 5.
To answer the second question, we use the trained neural editors from the previous experiment, and test their performance in an "one-shot" transfer learning scenario. Specifically, we use our highquality C#Fixers dataset, and for each fixer category F of semantically similar edits, we randomly select a seed edit {x-  x+}  F , and use its edit representation f(x-, x+) to predict the updated code for all examples in F , i.e., we have x^+ = (x-, f(x-, x+)),  {x-  x+}  F . This task is highly non-trivial, since a fixer category could contain more than hundreds of edit examples collected from different C# projects. Therefore, it requires the edit representations to generalize and transfer well, while being invariant of local lexical information like specific method names. To make the experimental evaluation more robust to noise, for each fixer category F, we randomly sample 10 seed edit pairs {x-  x+}, compute their edit representations and use them to predict the edited version of the examples in F and evaluate accuracy of predicting the exact final version. We then report the best score among the 10 seed representations as the performance metric on F.
Tab. 5 summarizes the results and also reports the upper bound performance when using the goldstandard edit representation f(x-, x+) to predict x+. We found that our neural Graph2Tree editor with the sequential edit encoder significantly outperforms the Seq2Seq editor, even though Seq2Seq performs better when using gold-standard edit representations. This suggest that the edit representations learned with the Graph2Tree model generalize better, especially for edits discussed in Sect. 4.2 that involve syntactic variations like RCS1021 (lambda expression simplification, 7.8% vs. 30.7% for Seq2Seq and Graph2Tree), and RCS1207 (change lambdas to method groups, 7.1% vs. 26.2%). Interestingly, we also observe that Seq2Seq outperforms the Graph2Tree model for edits with trivial surface edit sequences, where the Graph2Tree model does not have a clear advantage. For example, on RCS1015 (use nameof operator, e.g. Exception("x")  Exception(nameof(x))), the accuracies for Seq2Seq and Graph2Tree are 40.0% (14/35) and 28.6% (10/35), resp. We include more statistics of the results in Appendix C.
5 RELATED WORK
Edits have recently been considered in NLP by Faruqui et al. (2018), as they represent interesting linguistic phenomena in language modeling and discourse. Related to this work, Guu et al. (2017) present a generative model of natural language sentences via editing prototypes. In contrast to these examples of natural language generative modeling, our work focuses on representing edits in a semantically meaningful way. We are not aware of any related work that classifies or otherwise represents the differences over similar input, with the exception of differential recurrent neural networks used

8

Under review as a conference paper at ICLR 2019
for action recognition in videos (Veeriah et al., 2015; Zhuang et al., 2018). This is a substantially different task, as the data includes a temporal component as well.
Source code edits are a widely studied artifact. Specialized software, such as git, is widely used to store source code revision histories. Nguyen et al. (2013) studied the repetitiveness of source code changes by identifying identical types of changes using a deterministic differencing tool. In contrast, we employ on a neural network to cluster similar changes together. Rolim et al. (2017) use such clusters to synthesize small programs that perform the edit. The approach is based on Rolim et al. (2018) extract manually designed syntactic features from code and cluster over multiple changes to find repeatable edit rules. Similarly, Paletov et al. (2018) extract syntactic features specifically targeting edits in cryptography API protocols. In this work, we try to avoid hand-designed features and allow a neural network to learn the relevant aspects of a change by directly giving as input the original and final version of a changed code snippet.
Modeling tree generation with machine learning is an old problem that has been widely studied in NLP. Starting with Maddison & Tarlow (2014), code generation has also been considered as a tree generation problem. Close to our work is the decoder of Yin & Neubig (2017) which we use as the basis of our decoder. The work of Chen et al. (2018) is also related, since it provides a tree-to-tree model, but focuses on learning a single translation tasks and cannot be used directly to represent multiple types of edits. Both Yin & Neubig (2017) and Chen et al. (2018) have copying mechanism for single tokens, but our subtree copying mechanism is novel.
Autoencoders (see Goodfellow et al. (2016) for an overview) have a long history in machine learning. Variational autoencoders (Kingma & Welling, 2013) are similar to autoencoders but instead of focusing on the learned representation, they aim to create accurate generative probabilistic models. Most (variational) autoencoders focus on encoding images but there have been works that autoencode sequences, such as text (Dai & Le, 2015; Yang et al., 2017; Bowman et al., 2015) and graphs (Simonovsky & Komodakis, 2018; Liu et al., 2018). Conditional variational autoencoders (Sohn et al., 2015) have a related form to our model (with the exception of the KL term), but are studied as generative models, whereas we are primarily interested in the edit representation.
6 DISCUSSION & CONCLUSIONS
In this work, we presented the problem of learning distributed representation of edits. We believe that the dataset of edits is highly relevant and should be studied in more detail. While we have presented a set of initial models and metrics on the problem and obtained some first promising results, further development in both of these areas is needed. We hope that our work inspires others to work on this interesting problem in the future.
REFERENCES
Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly learning to align and translate. arXiv preprint arXiv:1409.0473, 2014.
Samuel R Bowman, Luke Vilnis, Oriol Vinyals, Andrew M Dai, Rafal Jozefowicz, and Samy Bengio. Generating sentences from a continuous space. arXiv preprint arXiv:1511.06349, 2015.
Xinyun Chen, Chang Liu, and Dawn Song. Tree-to-tree neural networks for program translation. arXiv preprint arXiv:1802.03691, 2018.
Andrew M Dai and Quoc V Le. Semi-supervised sequence learning. In Advances in neural information processing systems, pp. 3079­3087, 2015.
Manaal Faruqui, Ellie Pavlick, Ian Tenney, and Dipanjan Das. WikiAtomicEdits: A multilingual corpus of Wikipedia edits for modeling language and discourse. In EMNLP, 2018.
Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, and George E Dahl. Neural message passing for quantum chemistry. In International Conference on Machine Learning (ICML), 2017.
Ian Goodfellow, Yoshua Bengio, and Aaron Courville. Deep Learning. MIT Press, 2016. http: //www.deeplearningbook.org.
9

Under review as a conference paper at ICLR 2019
Kelvin Guu, Tatsunori B Hashimoto, Yonatan Oren, and Percy Liang. Generating sentences by editing prototypes. arXiv preprint arXiv:1709.08878, 2017.
Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114, 2013.
Yujia Li, Daniel Tarlow, Marc Brockschmidt, and Richard Zemel. Gated graph sequence neural networks. arXiv preprint arXiv:1511.05493, 2015.
Qi Liu, Miltiadis Allamanis, Marc Brockschmidt, and Alexander L. Gaunt. Constrained graph variational autoencoders for molecule design. In Neural Information Processing Systems (NIPS), 2018.
Laurens van der Maaten and Geoffrey Hinton. Visualizing data using t-SNE. Journal of machine learning research, 9(Nov):2579­2605, 2008.
Chris Maddison and Daniel Tarlow. Structured generative models of natural source code. In International Conference on Machine Learning (ICML), 2014.
Christopher D. Manning, Prabhakar Raghavan, and Hinrich Schu¨tze. Introduction to Information Retrieval. Cambridge University Press, New York, NY, USA, 2008. ISBN 0521865719, 9780521865715.
Hoan Anh Nguyen, Anh Tuan Nguyen, Tung Thanh Nguyen, Tien N Nguyen, and Hridesh Rajan. A study of repetitiveness of code changes in software evolution. In Proceedings of the 28th IEEE/ACM International Conference on Automated Software Engineering, pp. 180­190. IEEE Press, 2013.
Rumen Paletov, Petar Tsankov, Veselin Raychev, and Martin Vechev. Inferring crypto API rules from code changes. In Proceedings of the 39th ACM SIGPLAN Conference on Programming Language Design and Implementation, pp. 450­464. ACM, 2018.
Reudismam Rolim, Gustavo Soares, Loris D'Antoni, Oleksandr Polozov, Sumit Gulwani, Rohit Gheyi, Ryo Suzuki, and Bjo¨rn Hartmann. Learning syntactic program transformations from examples. In Proceedings of the 39th International Conference on Software Engineering, pp. 404­415. IEEE Press, 2017.
Reudismam Rolim, Gustavo Soares, Rohit Gheyi, and Loris D'Antoni. Learning quick fixes from code repositories. arXiv preprint arXiv:1803.03806, 2018.
Martin Simonovsky and Nikos Komodakis. GraphVAE: Towards generation of small graphs using variational autoencoders. arXiv preprint arXiv:1802.03480, 2018.
Kihyuk Sohn, Honglak Lee, and Xinchen Yan. Learning structured output representation using deep conditional generative models. In Advances in Neural Information Processing Systems, pp. 3483­3491, 2015.
Vivek Veeriah, Naifan Zhuang, and Guo-Jun Qi. Differential recurrent neural networks for action recognition. In Proceedings of the IEEE international conference on computer vision, pp. 4041­ 4049, 2015.
Oriol Vinyals, Meire Fortunato, and Navdeep Jaitly. Pointer networks. In Advances in Neural Information Processing Systems, pp. 2692­2700, 2015.
Zichao Yang, Zhiting Hu, Ruslan Salakhutdinov, and Taylor Berg-Kirkpatrick. Improved variational autoencoders for text modeling using dilated convolutions. arXiv preprint arXiv:1702.08139, 2017.
Pengcheng Yin and Graham Neubig. A syntactic neural model for general-purpose code generation. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), volume 1, pp. 440­450, 2017.
Naifan Zhuang, The Duc Kieu, Guo-Jun Qi, and Kien A Hua. Deep differential recurrent neural networks. arXiv preprint arXiv:1804.04192, 2018.
10

Under review as a conference paper at ICLR 2019

A DATASETS AND CONFIGURATION
WikiAtomicEdits We randomly sampled 1040K insertion examples from the English portion of WikiAtomicEdits (Faruqui et al., 2018) dataset, with a train, dev and test splits of 1000K, 20K and 20K .
GitHubEdits We cloned the top 54 C# GitHub repositories based on their popularity (Tab. 8). For each commit in the master branch, we collect the previous and updated versions of the source code, and extract all consecutive lines of edits that are smaller than three lines, and with at least three preceding and successive lines that have not been changed. We then filter trivial changes such as variable and identifier renaming, and changes happened within comments. We also limit the number of tokens for each edit to be smaller than 100, and down-sample edits whose frequency is larger than 30. Finally, we split the dataset by commit ids, ensuring that there are no edits in the training and testing (development) sets coming from the same commit. Tab. 6 lists some statistics of the dataset.

Table 6: Statistics of the GitHubEdits Dataset

Average Num. Tokens in x- Average Num. Tokens in x+ Average Edit Distance

16.4 17.0 5.0

Average size of AST for T (x-) 28.5 Average size of AST for T (x+) 29.4

C#Fixers We selected 16 C# fixers from Roslyn1 and Roslynator2, and ran them on 6 C# projects to generate a small, high-quality C# fixers dataset of 2 878 edit pairs with known semantics. Table 7 lists the detailed descriptions for each fixer category. And more information can be found at https://github.com/JosefPihrt/Roslynator/blob/master/ src/Analyzers/README.md.
Network Configuration Throughout the experiments, we use a fixed edit representation size of 512. The dimensionality of word embedding, the hidden states of the encoder LSTMs, as well as the gated graph neural network is 128, while the decoder LSTM uses a larger hidden size of 256. For the graph-based edit encoder, we used a two-layer graph neural network, with 5 information propagation steps at each layer. During training, we performed early stopping, and choose the best model based on perplexity scores on development set. During testing, we decode a target element x+ using beam size with a beam size of 5.
B CLUSTERING EXPERIMENTS
To qualitatively evaluate the quality of the learned edit representations. We use the models trained on the WikiAtomicEdits and GitHubEdits datasets to cluster natural language and code edits. We run K-Means clustering algorithm on 0.5 million sampled edits from WikiAtomicEdits, and all 90K code edits fromGitHubEdits, producing 50 000 and 20 000 clusters for each dataset.
Tab. 9 and Tab. 10 list some example clusters on WikiAtomicEdits and GitHub datasets, respectively. Due to the size of clusters, we omit out-liners and present distinctive examples from each cluster. On the WikiAtomicEdits dataset, we found clusters whose examples are semantically and syntactically similar. More interestingly, on the source code data, we find representative clusters that relate to idiomatic patterns and best practices of programming. The clustering results produced by our model would be useful for programming synthesis toolkits to generate interpretable code refractory rules, which we leave as interesting future work.
1http://roslyn.io 2https://github.com/JosefPihrt/Roslynator
11

Under review as a conference paper at ICLR 2019

Fixer ID CA2007
IDE0004 RCS1015

Table 7: Descriptions of fixer categories in C#Fixers dataset

Description

Num. Edits Example

apply .ConfigureAwait(false) to await statements

1051

x-: await Console.WriteAsync() x+: await Console.WriteAsync()

.ConfigureAwait(false)

Cast is redundant

53

x-: var x = 1; var b = (int)x; x+: var x = 1; var b = x;

Use nameof operator

35

x-: Exception("parameter"); x+: Exception(nameof(parameter));

RCS1021 Simplify lambda expression

var x = items.Select(f =>

411

x-: { return f.ToString();

});

x+: var

x

= f

items.Select( => f.ToString());

RCS1032 Remove redundant parentheses

RCS1058 Use compound assignment

RCS1077 Optimize LINQ method call

RCS1089

Use --/++ operator instead of assignment

RCS1097 Remove redundant ToString call

24 x-: if ((x)) {} x-: if (x) {}

43

x-: i = i + 2; x+: i += 2;

200

x-: items.Where(f => Foo(f)).Any(); x+: items.Any(f => Foo(f));

75

x-: i = i + 1; x+: i += 1;

20

x-: var x = s.ToString(); x+: var x = s;

RCS1118 Mark local variable as const

477

x-:

string string

s = "a"; s2 = s +

"b";

x+:

const string s = "a"; string s2 = s + "b";

RCS1123

Add parentheses according to operator precedence

109

x-: if (x || y && z) {} x+: if (x || (y && z) ) {}

RCS1146 Use conditional access

71

x-: x != null && x.StartsWith("a"); x+: x?.StartsWith("a");

Optimize call of StringBuilder's RCS1197 Append/AppendLine

95

x-: sb.Append(s + "x"); x+: sb.Append(s).Append("x");

RCS1202 Avoid NullReferenceException 56

RCS1206

Use conditional access instead of conditional expression

RCS1207

Use method group instead of anonymous function

116 42

x-: items.First().ToString(); x+: items?.First().ToString();

x-: int

i

= (x != null) ? x.Value.GetHashCode()

:

0;

x+: int i = x?.GetHashCode() ?? 0;

x-: items.Select(f => Foo(f)); x+: items.Select(Foo);

C BREAK-DOWN ANALYSIS OF TRANSFER LEARNING RESULTS
Tab. 11 lists the detailed evaluation results for the transfer learning experiments discussed in Sect. 4.4. The neural Graph2Tree editor outperforms the Seq2Seq editor on 10 out of 16 fixer categories. Interestingly, we found that there are categories where the end-to-end system under-performs, even though the upper-bound accuracy is high (e.g. RCS1077, RCSRCS1197, RCS1207). While these are more complex refractory rules where a single local seed edit might not be able to generalize to
12

Under review as a conference paper at ICLR 2019

Name
acat akka.net aspnetboilerplate AutoMapper BotBuilder CefSharp choco cli CodeHub coreclr corefx dapper dnSpy duplicati EntityFramework EntityFrameworkCore FluentValidation framework GVFS Hangfire ILSpy JavaScriptServices MahApps.Metro MaterialDesignInXamlToolkit
mono monodevelop MonoGame msbuild Mvc Nancy Newtonsoft.Json NLog OpenLiveWriter OpenRA Opserver orleans PowerShell Psychson PushSharp ravendb ReactiveUI RestSharp roslyn Rx.NET ServiceStack shadowsocks-windows ShareX SignalR Sonarr SpaceEngineers SparkleShare StackExchange.Redis WaveFunctionCollapse Wox

Table 8: Our C# GitHub dataset projects

GitHub Id

Description

intel/acat akka/akka.net aspnetboilerplate/aspnetboilerplate AutoMaper/AutoMapper Microsoft/BotBuilder cefsharp/CefSharp chocolatey/choco dotnet/cli CodeHubApp/CodeHub dotnet/coreclr dotnet/corefx StackExchange/Dapper 0xd4d/dnSpy duplicati/duplicati aspnet/EntityFramework aspnet/EntityFrameworkCore JeremySkinner/FluentValidation accord-net/framework Microsoft/VFSForGit HangfireIO/Hangfire icsharpcode/ILSpy aspnet/JavaScriptServices MahApps/MahApps.Metro MaterialDesignInXamlToolkit/ MaterialDesignInXamlToolkit mono/mono mono/monodevelop MonoGame/MonoGame Microsoft/msbuild aspnet/Mvc NancyFx/Nancy JamesNK/Newtonsoft.Json NLog/NLog OpenLiveWriter/ OpenLiveWriter OpenRA/OpenRA opserver/Opserver dotnet/orleans PowerShell/PowerShell brandonlw/Psychson Redth/PushSharp ravendb/ravendb reactiveui/ReactiveUI restsharp/RestSharp dotnet/roslyn dotnet/reactive ServiceStack/ServiceStack shadowsocks/ shadowsocks-windows ShareX/ShareX SignalR/SignalR Sonarr/Sonarr KeenSoftwareHouse/ SpaceEngineers hbons/SparkleShare StackExchange/ StackExchange.Redis mxgmn/ WaveFunctionCollapse Wox-launcher/Wox

Assistive Context-Aware Toolkit Distributed Actors ASP.NET boilerplate Object-Object Mapper Bot Framework Chromium Embedded Framework Bindings package mananger .NET CLI Tools iOS application .NET Framework .NET FOundational Libraries Object Mapper .NET debugger and assembly editor Encrypted Cloud Backups Object-Relational Mapper Object-Relational Mapper ­ Core Validation Rules ML, CV Framework Git Virual File System Background job library Decompiler ASP.NET JS Services WPF Framework Design XAML & WPF
.NET implementation IDE Game Framework Build Tool MVC Framework HTTP based services JSON framework Loggin for .NET Text editor Strategy Game Engine Monitoring System Distributed Virtual Actors Command Line Firmware Push Notifications Database Reactive MVC Framework HTTP/REST Client .NET Compiler Reactive extensions. Web Service Framework Cryptography Screen Recorder Real-time web framework PVR Game File Sharing Redis Client Bitmap/tilemap Generator Launcher

13

Under review as a conference paper at ICLR 2019
Table 9: Example clusters on WikiAtomicEdits data using representations learned by a neural Seq2Seq editor with sequential edit encoder
Description Add a person's middle name 1. isaiah marcus rankin ( born 22 may 1978 in london ) is an english professional footballer
currently playing for stevenage borough . 2. audrey kathleen brown ( born 24 may , 1913 ) is a british athlete who competed mainly in
the 100 metres . 3. alice edith rumph was a painter , etcher , and teacher . 4. mark larry taufua is an australian professional rugby league player . 5. monique edith lamoureux ( born july 3 , 1989 ) is an american ice hockey player . Description Add a parenthetical expression also ... as to modify the subject 1. mid-state regional airport , also known as mid-state airport , is a small airport on in rush
township , centre county in pennsylvania in the united states . 2. islamic culture , also known as saracenic culture , is a term primarily used in secular
academia to describe the cultural practices common to historically islamic peoples . 3. birds of prey , also known as raptors , are birds that hunt for food primarily via flight , using
their keen senses , especially vision . 4. tetyana styazhkina , also written as tetyana stiajkina , ( ; born april 10 , 1977 ) is a ukrainian
cycle racer who rides for the chirio forno d'asolo team . 5. acid jazz , also known as club jazz , is a musical genre that combines elements of jazz , soul
, funk , disco and hip hop . Description Specify location using a prepositional phrase. 1. the douro fully enters portuguese territory just after the confluence with the gueda river ; once
the douro enters portugal , major population centres are less frequent along the river . 2. mochou lake and mochou lake park are located at 35 hanzhongmen da jie in the jianye district
of nanjing , china , west to qinhuai river . 3. reiner gamma is an albedo feature that is located on the oceanus procellarum , to the west of the
reiner crater on the moon . 4. she made a brief return to the screen in " parrish " ( 1961 ) , playing the supporting role of
mother which received little attention by the press . 5. he was involved in a few storylines , including one where he broke his toe and had a heart attack
after he was pushed by a mugger in the market . Description Add positional or temporal clause 1. at the time ajax and hercules were trapped behind a landslide at the gaillard cut , both were
working to clear the landslide . 2. at the docks , hikaru attempts to befriend the tiger , but finds that it dislikes humans . 3. about the second , i do know they exist , but the question is whether they are considered a
genre outside of japan . 4. in the battle , shirou uses his reality marble , unlimited blade works and defeats gilgamesh . 5. in the game , red is a curious 11 - year - old boy from pallet town .
all scenarios, improving the generalization ability of the edit representations and the performance of end-to-end system would be interesting future directions.
14

Under review as a conference paper at ICLR 2019

Table 10: Example clusters on GithubEdits data using representations learned by a Graph2Tree editor with sequential edit encoder. Locally defined variable names are canonicalized.
Description Switch from Assert.Equal to Assert.Empty

x- Assert.Equal(0, V0.ProjectIds.Count); x+ Assert.Empty(V0.ProjectIds);

x- Assert.Equal(0, V0.ProjectReferences.Count()); x+ Assert.Empty(V0.ProjectReferences);

x- Assert.Equal(0, V0.TrustedSelectionPaths.Count); x+ Assert.Empty(V0.TrustedSelectionPaths);

x- Assert.Equal(0, V0.Count); x+ Assert.Empty(V0);

x- Assert.Equal(0, V0.Messages.Count); x+ Assert.Empty(V0.Messages);

Description Use conditional access

x- Type V0 = V1 == null ? null : V1.GetType(); x+ Type V0 = V1?.GetType();

x- V0 = ((V1!= null) ? V1.Operand : null) as MemberExpression; x+ V0 = V1?.Operand as MemberExpression;

x- string V0 = V1 == null ? null : V1.GetType().Name; x+ string V0 = V1?.GetType().Name;

x- var V0 = V1 == null ? null : V1(V2).ToArray(); x+ var V0 = V1?.Invoke(V2).ToArray();

x- Assert.Equal(0, V0.Messages.Count); x+ Assert.Empty(V0.Messages);

Description Optimize LINQ queries

x- var V0 = V1.Customers.Where(V2 => V2.CustomerID == LITERAL) .FirstOrDefault();

x+

var V0 = V1.Customers .FirstOrDefault(V2 => V2.CustomerID == LITERAL);

x- var V0 = V1.TypeConverters.Where(V2 => V2.CanConvertTo(V3, V1)) .FirstOrDefault();

x+ var V0 = V1.TypeConverters .FirstOrDefault(V2 => V2.CanConvertTo(V3, V1));

x-

var V0 = this.V1.Where(V2 => V2.CanDeserialize(V3)) .FirstOrDefault();

x+ var V0 = this.V1.FirstOrDefault(V2 => V2.CanDeserialize(V3));

x-

var V0 = V1.Where(V2 => V2.Item1 == V3 && V2.Item2 == V4) .FirstOrDefault();

x+ var V0 = V1.FirstOrDefault(V2 => V2.Item1 == V3 && V2.Item2 == V4);

Description Change from Add function to indexer.

x- V0.Add(V1.key, V1.V2); x+ V0[V1.key] = V1.V2;

x- V0.Add(V1.Id, V2); x+ V0[V1.Id] = V2;

x- V0.Add(V1.Etag, V1); x+ V0[V1.Etag] = V1;

x- V0.Add(V1.V2, V3.Merge(V1.V4)); x+ V0[V1.V2] = V3.Merge(V1.V4);

15

Under review as a conference paper at ICLR 2019

Table 11: Break-down performance results on the transfer learning task. See Tab. 7 for descriptions

of each fixer category.

Fixer ID CA2007 IDE0004 RCS1015 RCS1021 RCS1032 RCS1058 RCS1077 RCS1089 RCS1097 RCS1118 RCS1123 RCS1146 RCS1197 RCS1202 RCS1206 RCS1207

Graph2Tree -- Seq Edit Encoder

Seq2Seq -- Seq Edit Encoder

Acc.(%) Acc.(%) Recall@5(%) Recall@5(%) Acc.(%) Acc.(%) Recall@5(%) Recall@5(%)

88.0 89.2

88.2

94.3 52.7 91.9 61.0

93.8

69.8 92.5

73.6

94.3 45.3 98.1 45.3

98.1

28.6 82.9

40.0

82.9 40.0 71.4 42.9

71.4

30.7 60.8

33.3

67.6

7.8 56.2

17.8

72.3

8.3 37.5

8.3

45.8 20.8 45.8 20.8

45.8

93.0 88.4

95.3

90.7 37.2 69.8 39.5

76.7

6.5 69.5

6.5

74.0 7.5 84.0 7.5

84.5

96.0 98.7

98.7

98.7 76.0 98.7 76.0

98.7

15.0 90.0

15.0

90.0 25.0 90.0 25.0

95.0

95.4 98.1

99.6

99.6 93.7 99.6 98.7

1.00

66.1 81.7

68.8

86.2 64.2 87.2 65.1

94.5

54.9 81.7

56.3

85.9 45.1 76.1 57.7

91.5

5.3 25.3

5.3

33.7 12.6 40.0 12.6

50.0

28.6 67.9

37.5

75.0 28.6 69.6 32.1

80.4

75.0 99.1

75.9

99.1 50.0 1.00 50.0

1.00

26.2 73.8

28.6

90.5

7.1 64.3

11.9

88.1

: upper-bound performance of predicting x+ using the gold-standard edit representations.

16

