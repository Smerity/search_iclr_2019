Under review as a conference paper at ICLR 2019
LEARNING NEURAL RANDOM FIELDS WITH INCLUSIVE AUXILIARY GENERATORS
Anonymous authors Paper under double-blind review
ABSTRACT
Neural random fields (NRFs), which are defined by using neural networks to implement potential functions in undirected models, provide an interesting family of model spaces for machine learning. In this paper we develop a new approach to learning NRFs with inclusive-divergence minimized auxiliary generator - the inclusive-NRF approach. The new approach enables us to flexibly use NRFs in unsupervised, supervised and semi-supervised settings and successfully train them in a black-box manner. Empirically, inclusive-NRFs achieve state-of-theart sample generation quality on CIFAR-10 in both unsupervised and supervised settings. Semi-supervised inclusive-NRFs show strong classification results on par with state-of-the-art generative model based semi-supervised learning methods, and simultaneously achieve superior generation, on the widely benchmarked datasets MNIST, SVHN and CIFAR-10.
1 INTRODUCTION
One of the core research problems in machine learning is learning with probabilistic models, which can be broadly classified into two classes - directed and undirected1 (Koller & Friedman, 2009). Significant progress has been made recently on learning with deep generative models (DGMs), which generally refer to models with multiple layers of stochastic or deterministic variables. There have emerged a bundle of deep directed generative models, such as variational AutoEncoders (VAEs) (Kingma & Welling, 2014), generative adversarial networks (GANs) (Goodfellow et al., 2014) and so on. In contrast, undirected generative models (also known as random fields (Koller & Friedman, 2009), energy-based models (LeCun et al., 2006)) received less attention with slow progress. This is presumably because fitting undirected models is more challenging than fitting directed models. In general, calculating the log-likelihood and its gradient is analytically intractable, because it involves the expectation with respect to (w.r.t.) the model distribution.
In this paper, we aims to advance the learning of neural random fields (RFs) which use neural networks with multiple (deterministic) layers to define the potential function2 u(x) over observation x with parameter . The probability distribution p(x)  exp(u(x)) is then defined by normalizing the exponentiated potential function. This type of RFs has been studied several times in different contexts, once called deep energy models (DEMs) (Ngiam et al., 2012; Kim & Bengio, 2016), descriptive models (Xie et al., 2016), generative ConvNet (Dai et al., 2014), neural random field language models (Wang & Ou, 2017). For convenience, we refer to such models as neural random fields (NRFs) in general.
An important method of maximum likelihood (ML) learning of random fields is called stochastic maximum likelihood (SML) (Younes, 1989), which approximates the model expectations by Monte Carlo sampling for calculating the gradient. A recent progress in learning NRFs as studied in Kim & Bengio (2016); Xie et al. (2016); Wang & Ou (2017); Kuleshov & Ermon (2017) is to pair the target random field p with an auxiliary directed generative model (often called generator) q(x) parameterized by , which approximates sampling from the target random field. Learning
1An easy way to tell an undirected model from a directed model is that an undirected model involves the normalizing constant (also called the partition function in physics), while the directed model is self-normalized.
2Note that compared to modeling with multiple deterministic layers, modeling with multiple stochastic layers, e.g. deep Boltzmann machines (DBMs) (Salakhutdinov & Hinton, 2009), presents much greater challenge for model learning and thus yields inferior performance. This is observed in both directed and undirected models.
1

Under review as a conference paper at ICLR 2019

is performed by maximizing the log-likelihood of training data under p or some bound of the log-likelihood, and simultaneously minimizing some divergence between the target random field p and the auxiliary generator q. Different learning algorithms mainly differ in the objective functions used in the joint training of p and q, and thus have different computational and statistical properties (partly illustrated in Figure 1). For example, minimizing the exclusive-divergence KL[q||p]
qlog (q/p) w.r.t. , as employed in Kim & Bengio (2016), involves the intractable entropy term and tends to enforce the generator to seek modes, yielding missing modes. We leave detailed discussion of existing learning algorithms and their respective drawbacks to section 3 (related work).
In this paper, we propose to use inclusive-divergence minimized auxiliary generators (section 2.1) and use SGLD (stochastic gradient Langevin dynamics (Welling & Teh, 2011)) and SGHMC (stochastic gradient Hamiltonian Monte Carlo (Chen et al., 2014)) for model sampling with theoretical examinations (section 2.2). Our approach offers some advantages over previous methods. First, minimizing the inclusive-divergence KL[p||q] plog (p/q) w.r.t.  avoids the annoying entropy term and tends to drive the generator to cover modes of the target density p. The SGLD/SGHMC sampling further pushes the samples towards the modes of p. This helps to produce Markov chains that mix fast between modes and facilitate model learning. Second, our approach enables us to flexibly use NRFs in unsupervised, supervised and semi-supervised learning (SSL) settings and train them in a black-box manner (section 2.3).
The main contributions of this paper can be summarized as follows:
· We develop a new approach to learning NRFs with inclusive auxiliary generators, abbreviated as the inclusive-NRF approach.
· Inclusive-NRFs achieve state-of-the-art sample generation quality, measured by both Inception Score (IS) and Frechet Inception Distance (FID). On CIFAR-10, we obtain unsupervised IS 8.28 (FID 20.9) and supervised IS 9.06 (FID 18.1), both using unconditional generation.
· Semi-supervised inclusive-NRFs show strong classification results on par with state-ofthe-art DGM-based SSL methods, and simultaneously achieve superior generation, on the widely benchmarked datasets - MNIST, SVHN and CIFAR-10.

2 THE INCLUSIVE-NRF APPROACH

Consider a random field for modeling observation x with parameter :

1 p(x) = Z() exp [u(x)]

(1)

where Z() = exp(u(x))dx is the normalizing constant, u(x) is the potential function3 which assigns a scalar value to each configuration of random variable x. The general idea of neural random fields (NRFs) is to implement u(x) : Rdx  R, by a neural network, taking the multi-dimensional x  Rdx as input and outputting the scalar u(x)  R. In this manner, we can take advantage of the representation power of neural networks for RF modeling 4. It is usually intractable to maximize the
data log-likelihood logp(x~) for observed x~, since the gradient involves expectation w.r.t. the model distribution, as shown below:

 log p(x~) = u(x~) - Ep(x) [u(x)]

2.1 INTRODUCING INCLUSIVE-DIVERGENCE MINIMIZED AUXILIARY GENERATORS
In this paper, we further develop NRF learning with auxiliary generators5. We are mainly concerned with modeling fixed-dimensional continuous observations x  Rdx (e.g. images), and choose a
3Negating the potential function defines the energy function. 4The RFs used in our experiments are different from those in previous studies Kim & Bengio (2016); Wang & Ou (2017); Xie et al. (2016). The differences are: Kim & Bengio (2016) includes linear and squared terms in u(x), Wang & Ou (2017) defines over sequences, and Xie et al. (2016) defines in the form of exponential tilting of a reference distribution (Gaussian white noise). 5There exist different choices for the generator, e.g. a GAN model in Kim & Bengio (2016), a LSTM in Wang & Ou (2017), or a latent-variable model in Xie et al. (2016). All are easy to do sampling.

2

Under review as a conference paper at ICLR 2019

Algorithm 1 Learning NRFs with inclusive auxiliary generators

repeat Sampling: Draw a minibatch M = (x~i, xi, hi), i = 1, · · · |M| from p~(x~)p(x)q(h|x);
Updating:

Update 

by ascending:

1 |M|

Update



by

ascending:

1 |M|

until convergence

(x~,x,h)M [u(x~) - u(x)]; (x~,x,h)M logq(x, h);

directed generative model, q(x, h) q(h)q(x|h), for the auxiliary generator, which specifically is

defined as follows6:

h  N (0, Ih), x = g(h) + ,  N (0, 2I ),

(2)

where g(h) : Rdh  Rdx is implemented as a neural network with parameter , which maps the latent code h to the observation space. Ih and I denote the identity matrices, with dimensionality implied by h and respectively. Drawing samples from the generator q(x, h) is simple as it is just ancestral sampling from a 2-variable directed graphical model.

Suppose that data D = {x~1, · · · , x~n}, consisting of n observations, are drawn from the true but

unknown data distribution p0(·). p~(x~)

1 n

n k=1

(x~

-

x~k )

denotes

the

empirical

data

distribu-

tion. Then we formulate the maximum likelihood learning of p(x) with the inclusive-divergence

minimized generator q(x) as optimizing7

 

min


K

L

[p~(x~)||p

(x~)]



min


K

L

[p

(x)||q(x)]

(3)

It can be easily seen that the gradients w.r.t.  and  (to be ascended) are defined as follows8:

 = Ep~(x~) [logp(x~)] = Ep~(x~) [u(x~)] - Ep(x) [u(x)] ,  = Ep(x) [logq(x)] = Ep(x)q(h|x) [logq(x, h)] .

(4)

In practice, we calculate noisy gradient estimators, and apply minibatch based stochastic gradient descent (SGD) to solve the optimization problem Eq.(3), as shown in Algorithm 1.

2.2 APPLYING SGLD/SGHMC FOR MODEL SAMPLING

In Algorithm 1, we need to draw samples from p(x)q(h|x) given current  and . For continuous

observations, SGLD (stochastic gradient Langevin dynamics) (Welling & Teh, 2011) and SGHMC

(Stochastic Gradient Hamiltonian Monte Carlo) (Chen et al., 2014) sampling provide mechanisms for

exploiting (stochastic) gradients of the target density p(x)q(h|x), enabling efficient exploration of

the state space. We take the theoretical results about SGLD from Teh et al. (2016) and SGHMC from

Chen et al. (2014), which are briefly summarized in Theorem 1 in the Supplement, and apply them

in the sampling step in Algorithm 1. Denoting the target density as p(z; ) with given , Theorem

1

shows

that

SGLD/SGHMC,

by

utilizing

 z

log

p(z; ),

yields

a

non-homogeneous

Markov

chain

z(l), l  1 , which converges to the equilibrium distribution p(z; ).

By letting z (x, h), p(z; ) p(x)q(h|x),  (, )T in Theorem 1, we can perform the sampling step in Algorithm 1 by running |M| parallel chains, each chain being executed as follows:

1. Do ancestral sampling by the generator, namely first drawing h  p(h ), and then drawing x  q(x |h );
6Note that during training, 2 is absorbed into the learning rates and does not need to be estimated. 7Such optimization using two objectives is employed in a number of familiar learning methods, such as GAN with logD trick (Goodfellow et al., 2014), wake-sleep algorithm (Hinton et al., 1995). 8The second part of Eq.(4) holds, because Eq(h|x) [logq(h|x)] = 0. Thus we have logq(x) = Eq(h|x) [logq(x)] = Eq(h|x) [logq(x, h) - logq(h|x)] = Eq(h|x) [logq(x, h)].

3

Under review as a conference paper at ICLR 2019

2. Starting from (x , h ) = z(0), run finite steps of SGLD/SGHMC (l = 1, · · · , L) to obtain (x, h) = z(L), which we call sample revision, according to Eq.(10)/(11).

In sample revision, the calculation of the gradient w.r.t.

h,

 h

log

p(z;

)

=

 h

log

q(h,

x),

is

straightforward. For the gradient w.r.t. x, we have

 



x log p(z; ) = x log p(x) + x log q(h, x) - x log q(x),

(5)

where the last term can be approximated by an unbiased estimate, as proved in Proposition 1 in the

Supplement:

 x

log q(x)



 x

log q(h, x).

Therefore,

we

can

use

 x

log

p (x)9

as

an

unbiased

estimate

of

the

gradient

 x

log

p(z; ),

and

we

can apply Theorem 1 with tractable gradients w.r.t. both x and h.

Remarks. Intuitively, the generator gives a proposal (x , h ), and then the system follows the gradients
of p(x) and q(h, x) (w.r.t. x and h respectively) to revise (x , h ) to (x, h). The gradient terms pull samples moving to low energy region of the random field and adjust the latent code of the generator,
while the noise term brings randomness. In this manner, we obtain Markov chain samples from p(x)q(h|x). Note that finite steps in sample revision will produce biased estimates of the gradients  and  in Eq.(4). We did not find this to pose problems to the SGD optimization in practice, as similarly found in Bornschein & Bengio (2015); Kuleshov & Ermon (2017) which work with biased
gradient estimators.

2.3 SEMI-SUPERVISED LEARNING WITH INCLUSIVE NRFS

In the following, we apply our inclusive-NRF approach in the SSL setting to show its flexibility. Note that different models are needed in unsupervised and semi-supervised learning, because SSL needs to additionally consider labels apart from observations.

Model definition. In semi-supervised tasks, we consider the following RF for joint modeling of observation x  Rdx and class label y  {1, · · · , K}:

1 p(x, y) = Z() exp [u(x, y)]

(6)

which is different from Eq.1 for unsupervised learning without labels. To implement the potential function u(x, y), we consider a neural network (x) : Rdx  RK , with x as the input and the output size being equal to the number of class labels, K. Then we define u(x, y) = onehot(y)T (x), where onehot(y) represents the one-hot encoding vector for the label y. In this manner, p(y|x) is
the classifier, defined as follows:

p (y|x)

=

p(x, y) p (x)

=

exp [u(x, y)] y exp [u(x, y)]

(7)

which acts like multi-class logistic regression using K logits calculated from x by the neural network (x). And we do not need to calculate Z() for classification. The auxiliary generator is implemented the same as in Eq.2, i.e. an unconditional generator.

With the definition in Eq. 6, it can be shown that, with abuse of notation, the marginal density

p (x)

=

1 Z ()

exp [u(x)]

where

u (x)

log

y exp [u(x, y)].

Model learning. Suppose that among the data D = {x~1, · · · , x~n}, only a small subset of the observations, for example the first m observations, have class labels, m n. Denote these labeled data as L = {(x~1, y~1), · · · , (x~m, y~m)}. Then we can formulate the semi-supervised learning as jointly optimizing


 

min


K

L

[p~(x~)||p

(x~)]

-

d

logp (y~|x~)

(x~,y~)L

(8)

 

min

K

L

[p

(x)||q(x)]



9Note

that

 x

log p(x)

=

 x

u

(x)

does

not need

the

calculation

of the

normalizing constant.

4

Under review as a conference paper at ICLR 2019

which are defined by hybrids of generative and discriminative criteria, similar to Zhu (2006); Larochelle et al. (2012); Kingma et al. (2014). The hyper-parameter d controls the relative weight between generative and discriminative criteria. It can be easily seen that the gradients w.r.t.  and  (to be ascended) are defined as follows:

semi =Ep~(x~) [logp(x~)] + d

 log p (y~|x~)



 

(x~,y~)L





=Ep~(x~) [u(x~)] - Ep(x) [u(x)] + d

 log p (y~|x~)



 

(x~,y~)L





semi =Ep(x) [logq(x)] = Ep(x)q(h|x) [logq(x, h)]

(9)

In practice, we calculate noisy gradient estimators, and apply minibatch based stochastic gradient descent (SGD) to solve the optimization problem Eq.(8), as shown in Algorithm 2 in the Supplement. Apart from the basic losses as shown in Eq.(8), there are some regularization losses that are found to be helpful to guide SSL learning and are presented in the Supplement. To conclude, we show that the inclusive-NRF can be easily applied to SSL. To the best of our knowledge, there are no priori studies in applying random fields to SSL. The semi-supervised inclusive-NRF model defined above is novel itself for SSL.

3 RELATED WORK

Connection and comparison of our inclusive-NRF approach to existing studies are provided in the following from three perspectives.
Learning NRFs with auxiliary generators. These studies are most relevant to this work, which aims to learn NRFs. The classic method for learning RFs is the SML method (Younes, 1989), which works with the single target model p. A recent progress in learning NRFs as studied in Kim & Bengio (2016); Xie et al. (2016); Wang & Ou (2017); Kuleshov & Ermon (2017) is to jointly train the target random field p(x) and an auxiliary generator q(x). Different algorithms mainly differ in the objective functions used in the joint training, and thus have different computational and statistical properties.

· It is shown in Proposition 2 in the Supplement that learning in Kim & Bengio (2016) minimizes the exclusive-divergence KL[q||p] w.r.t. , which involves the intractable entropy term and tends to enforce the generator to seek modes, yielding missing modes. We
refer to this approach as exclusive-NRF.

· Learning in Xie et al. (2016); Wang & Ou (2017) and in this paper minimizes the inclusivedivergence KL[p||q] w.r.t. , which is desirable in the sense that it avoids the annoying entropy term and tends to drive the generator to cover modes of the target density p. Compared to this paper, Xie et al. (2016) intuitively uses Langevin sampling, without theoretical examinations which we present in section 2.2. Compared to Wang & Ou (2017) which uses Metropolis independence sampling (MIS) and is applicable for discrete data (natural sentences), this paper proposes to utilize SGLD/SGHMC to exploit gradient information to handle continuous observations (images).

· Learning in Kuleshov & Ermon (2017) minimizes the 2-divergence 2[q||p]

(p -q)2 q

w.r.t.

, which also tends to drive the generator to cover modes.

But this

approach is severely limited by the high variance of the gradient estimator w.r.t. , and is

only tested on the simpler MNIST and Omniglot.

Monte Carlo sampling. One step in our inclusive-NRF approach is to apply SGLD/SGHMC to draw samples from the target density p, starting from the proposal sample from the generator. Theoretically, improvements in NRF sampling methods could be potentially integrated into NRF learning algorithms. For example, it is recently studied in Levy et al. (2018) to learn MCMC transition kernels, also parameterized by neural networks, to improve the HMC sampling from the given target distribution. Integration into learning NRFs is interesting but outside the scope of this paper.

5

Under review as a conference paper at ICLR 2019

(a) Training data

(b) GAN generation (c) WGAN-GP generation (d) Exc. NRF generation

(g) Exc. NRF potential (h) Inc. NRF potential (e) Inc. NRF generation (f) Inc. NRF revision
Figure 1: Comparison of different methods over GMM synthetic data. Stochastic generations from GAN with logD trick, WGAN-GP, Exclusive-NRF, Inclusive-NRF generation (i.e. sampling from the auxiliary generator) and Inclusive-NRF revision (i.e. after sample revision), are shown in (b)-(f) respectively. Each generation contains 1,000 samples. The learned potentials u(x) from exclusive and inclusive NRFs are shown in (g) and (h) respectively, where the red dots indicate the mean of each Gaussian component. Inclusive NRFs are clearly superior in learning data density and sample generation.
Comparison and connection with GANs. On the one hand, there are some efforts that aim to address the inability of GANs to provide sensible energy estimates for samples. The energy-based GANs (Zhao et al., 2017) proposes to view the discriminator as an energy function by designing an auto-encoder discriminator. The recent work in Dai et al. (2017a) connects Zhao et al. (2017) and Kim & Bengio (2016), and show another two approximations for the entropy term. However, it is known that as the generator converges to the true data distribution, the GAN discriminator converges to a degenerate uniform solution. This basically afflicts the GAN discriminator to provide density information, though there are some modifications. In contrast, our inclusive-NRFs, unlike GANs, naturally provide (unnormalized) density estimate. Moreover, none of the above energy-related GAN studies examine their methods or models for SSL, except in EBGAN which performs moderately.
On the other hand, there are interesting connections between inclusive-NRFs and GANs, as elaborated in section 10 in the Supplement. When interpreting the potential function u(x) as the critic in Wasserstein GANs, inclusive-NRFs seem to be similar to Wasserstein GANs, except that in optimizing  in inclusive-NRFs, the generated samples are further revised by taking finite-step-gradient of u(x) w.r.t. x. However, the critic in Wasserstein GANs can hardly be interpreted as an unnormalized log-density. Thus strictly speaking, inclusive-NRFs are not GAN-like.
4 EXPERIMENTS
We conduct a series of experiments to evaluate the performances of our approach (inclusive-NRFs) and various existing methods on synthetic and real-world datasets for both unsupervised and semisupervised learning tasks, with both visual and numerical evaluation. We refer to the Supplement for experimental details and additional results.
4.1 GMM SYNTHETIC EXPERIMENT
The synthetic data consist of 1,600 training examples generated from a 2D Gaussian mixture model (GMM) with 32 equally-weighted, low-variance ( = 0.1) Gaussian components, uniformly laid out on four concentric circles as in Figure 1(a). The data distribution exhibits many modes separated
6

Under review as a conference paper at ICLR 2019

Table 1: Numerical evaluations over the GMM (32 components) synthetic data. The "covered modes" metric is defined as the number of covered modes by a set of generated samples. The "realistic ratio" metric is defined as the proportion of generated samples which are close to a mode. The measurement details are presented in section 11.1 in the Supplement. Mean and SD are from 10 independent runs.

Methods

covered modes realistic ratio

GAN with logD trick WGAN-GP (Gulrajani et al., 2017) Exclusive-NRF (Kim & Bengio, 2016) Inclusive-NRF generation Inclusive-NRF revision

22.25 ± 1.54 27.81 ± 1.40 28.14 ± 0.68 29.52 ± 0.54 30.75 ± 0.43

0.90 ± 0.01 0.74 ± 0.04 0.73 ± 0.03 0.84 ± 0.01 0.97 ± 0.01

Table 2: Inception score (IS) and FID on CIFAR-10 for unsupervised and supervised learning.

Methods
DCGAN (Radford et al., 2015) Improved-GAN (Salimans et al., 2016) WGAN-GP (Gulrajani et al., 2017) SGAN (Huang et al., 2017) DFM (Warde-Farley & Bengio, 2017) CT-GAN (Wei et al., 2018) Fisher-GAN (Mroueh & Sercu, 2017) BWGAN (Adler & Lunz, 2018) SNGAN (Miyato et al., 2018)
Inclusive-NRF generation

Unsupervised IS FID
6.16 ± 0.07

7.86 ± 0.07

7.72 ± 0.13 8.12 ± 0.12 7.90 ± 0.05 8.26 ± 0.07 8.22 ± 0.05
8.28 ± 0.09

21.7 ± 0.21 20.9 ± 0.25

Supervised IS FID 6.58 8.09 ± 0.07 8.42 ± 0.10 8.59 ± 0.12
8.81 ± 0.13 8.16 ± 0.12
9.06 ± 0.10 18.1 ± 0.23

by large low-probability regions, which makes it suitable to examine how well different learning methods can deal with multiple modes. For comparison, we experiment with GAN with logD trick (Goodfellow et al., 2014) and WGAN-GP (Gulrajani et al., 2017) for directed generative model, exclusive-NRF (Kim & Bengio, 2016) and inclusive-NRF for undirected generative model.
Figure 1 visually shows the generated samples from the trained models using different methods. Table 1 reports the "covered modes" and "realistic ratio" as numerical measures of how the multi-modal data are fitted, similarly as in Dumoulin et al. (2017). The main observations are as follows. (1) GAN suffers from mode missing, generating realistic but not diverse samples. WGAN-GP increases "covered modes" but decreases "realistic ratio". Inclusive-NRF performs much better than both GAN and WGAN-GP in sample generation. (2) Inclusive-NRF outperforms exclusive-NRF in both sample generation and density estimation. (3) After revision, samples from inclusive-NRF become more like real samples, achieving the best in both "covered modes" and "realistic ratio" metrics.
4.2 IMAGE GENERATION ON CIFAR-10
We examine both unsupervised and supervised learning over the widely used real-world dataset CIFAR-10 Krizhevsky (2009) for image generation. To evaluate generation quality quantitatively, we use inception score (IS) Salimans et al. (2016), and Frechet inception distance (FID) Heusel et al. (2017). Table 2 reports the inception score and FID for state of the art methods, for both unsupervised and supervised settings. The supervised learning of inclusive-NRF is conducted as a special case of semi-supervised learning over all labeled images (m = n), which uses unconditional generation. We use ResNet in this experiment, see section 11.2 in the Supplement for experimental details.
From the comparison results in Table 2, it can be seen that the proposed inclusive-NRF model achieves the best inception score over CIFAR-10, to the best of our knowledge, in both unsupervised and supervised settings. Some generated samples are shown in Figure 5(c)(d) for unsupervised and supervised settings respectively. We also show in the Supplement the capability of inclusive-NRFs in latent space interpolation (section 13) and conditional generation (section 14).
7

Under review as a conference paper at ICLR 2019

Table 3: Comparison with state-of-the-art methods on three benchmark datasets. "CIFAR-10 IS" means the inception score for samples generated by SSL models trained on CIFAR-10. "" is obtained
by running the released code accompanied by the corresponding papers. "-" means the results are not reported or not applicable. "" uses image data augmentation which significantly helps classification
performance. The upper/lower blocks show generative/discriminative SSL methods respectively.

Methods

error (%) MNIST

error (%) SVHN

error (%) CIFAR-10

CatGAN (Springenberg, 2016) SDGM (Maaloe et al., 2016) Ladder network (Rasmus et al., 2015) ADGM (Maaloe et al., 2016) Improved-GAN (Salimans et al., 2016) EBGAN (Zhao et al., 2017) ALI (Dumoulin et al., 2017) Triple-GAN (Li et al., 2017) Triangle-GAN (Gan et al., 2017)
BadGAN (Dai et al., 2017b) Sobolev-GAN (Mroueh et al., 2018) Semi-supervised inclusive-NRF

1.91 ± 0.10 1.32 ± 0.07 1.06 ± 0.37 0.96 ± 0.02 0.93 ± 0.07 1.04 ± 0.12
0.91 ± 0.58
-
0.80 ± 0.10
0.97 ± 0.10

16.61 ± 0.24
22.86 8.11 ± 1.3
7.42 ± 0.65 5.77 ± 0.17
-
4.25 ± 0.03
5.84 ± 0.15

19.58 ± 0.46
20.40 ± 0.47
18.63 ± 2.32
17.99 ± 1.62 16.99 ± 0.36 16.80 ± 0.42
14.41 ± 0.30 15.77 ± 0.19 15.12 ± 0.36

Results below this line cannot be directly compared to those above.

VAT small (Miyato et al., 2017)  model (Laine & Aila, 2017) Temporal Ensembling (Laine & Aila, 2017) Mean Teacher (Tarvainen & Valpola, 2017) VAT+EntMin (Miyato et al., 2017) CT-GAN (Wei et al., 2018)

1.36 -
0.89 ± 0.13

6.83 4.82 ± 0.17 4.42 ± 0.16 3.95 ± 0.19
3.86 -

14.87 12.36 ± 0.31 12.16 ± 0.31 12.31 ± 0.28
10.55 9.98 ± 0.21

IS CIFAR-10
3.57 ± 0.13 -
3.87 ± 0.03 -
5.08 ± 0.09 -
3.46 ± 0.11 -
7.72 ± 0.09
-

4.3 SEMI-SUPERVISED LEARNING RESULTS
For semi-supervised learning, we consider the three widely used benchmark datasets, namely MNIST (LeCun et al., 1998), SVHN (Netzer et al., 2011), and CIFAR-10 (Krizhevsky, 2009). As in previous work, we randomly sample 100, 1,000, and 4,000 labeled samples from MNIST, SVHN, and CIFAR10 respectively during training, and use the standard data split for testing. See section 11.3 in the Supplement for experimental details. We also provide a SSL toy experiment in section 12 in the Supplement to help understanding how semi-supervised inclusive-NRF works.
It can be seen from Table 3 that semi-supervised inclusive-NRFs produce strong classification results on par with state-of-art DGM-based SSL methods. See Figure 5(a)(b) in the Supplement for generated samples. Bad-GANs achieve better classification results, but as indicated by the low inception score, their generation is much worse than semi-NRF-IAGs. In fact, among DGM-based SSL methods, inclusive-NRFs achieve the best performance in sample generation. This is in contrast to the conflict of good classification and good generation, as observed in GAN-based SSL (Salimans et al., 2016; Dai et al., 2017b). It is analyzed in Dai et al. (2017b) that good GAN-based SSL requires a bad generator10. This is embarrassing and in fact obviates the original idea of generative SSL successful generative training, which indicates good generation, provides regularization for finding good classifiers (Zhu, 2006; Larochelle et al., 2012). In this sense, Bad-GANs could hardly be classified as a generative SSL method.
Finally, note that some discriminative SSL methods, as listed in the lower block in Table 3 also produce superior performances, by utilizing data augmentation and consistency regularization. However, these methods are unable to generate (realistic) samples. It can be seen that discriminative SSL methods utilize different regularization from generative SSL methods and cannot be directly compared to generative SSL methods. Their combination, as an interesting future work, could yield further performance improvement.
10This analysis is based on using the (K + 1)-class GAN-like discriminator objective for SSL. To the best of our knowledge, the conflict does not seem to be reported in previous generative SSL methods Zhu (2006); Larochelle et al. (2012) which use the K-class classifier like in semi-supervised inclusive-NRFs.
8

Under review as a conference paper at ICLR 2019

Table 4: Ablation study of our inclusive-NRF method on CIFAR-10, regarding the use of sample revision and SGLD/SGHMC. Mean and SD are from 5 independent runs for each setting. For unsupervised learning, we examine generated samples (i.e. directly from the generator) and revised samples (i.e. after sample revision) respectively, in term of inception scores (IS). For semi-supervised learning, we examine the classification error rates.

Setting
SGLD L = 1 SGLD L = 5 SGLD L = 10 SGHMC L = 10

Unsupervised Generation IS Revision IS

7.47 ± 0.15 7.44 ± 0.16 7.43 ± 0.18 7.46 ± 0.12

7.53 ± 0.13 7.49 ± 0.12 7.50 ± 0.13 7.57 ± 0.10

Semi-supervised error (%)
17.08 ± 0.39 16.15 ± 0.44 15.60 ± 0.31 15.12 ± 0.36

4.4 ABLATION STUDY
We report the results of ablation study of our inclusive-NRF method on CIFAR-10 in Table 4. In this experiment, we use the standard CNN (Miyato et al., 2018) for unsupervised learning and the same networks as those used in Table 3 for semi-supervised learning. See section 11.4 in the Supplement for experimental details. We compare different settings, including revision step L = 1/5/10, and SGLD/SGHMC. The main observations are as follows. (1) After revision (following the gradient of the RF's potential u(x) w.r.t. x), the quality (IS) of samples is improved. This is consistent with the results in the GMM synthetic experiments. Remarkably, this demonstrates one benefit of random field modeling, which, unlike GANs, can learn density estimate about the data manifold. (2) With more revision steps and using SGHMC, the classification performance is improved. Utilizing SGHMC in inclusive-NRFs to exploit gradient information with momentum yields better performance than simple SGLD as used in Xie et al. (2016). (3) More revision steps do not significantly improve unsupervised IS. So we can use L = 1 in unsupervised learning for generation, which can reduce the computational cost.
5 DISCUSSION AND CONCLUSION
In this paper we develop a new approach to learning NRFs with inclusive auxiliary generators - the inclusive-NRF approach. Extensive empirical evaluations show that inclusive-NRFs obtain state-ofthe-art sample generation quality and achieve strong semi-supervised learning results on par with state-of-the-art DGMs. The superior performances presumably are attributed to the two distinctive features in inclusive-NRFs - introducing the inclusive-divergence minimized auxiliary generator and utilizing sample revision by SGLD/SGHMC. Intuitively, the revised samples from the RF will guide the training of the generator, and subsequently the generator will propose samples for the RF to sense the data manifold. This forms positive interactions between the random field and the generator, which enables successful joint training of both models.
The new approach enables us to flexibly use NRFs in unsupervised, supervised and semi-supervised settings and successfully train them in a black-box manner. Interesting future work will consider inclusive-NRFs in more challenging tasks, e.g. unsupervised and semi-supervised learning with sequential data (e.g. speech, language, video, etc.).

9

Under review as a conference paper at ICLR 2019
REFERENCES
Jonas Adler and Sebastian Lunz. Banach wasserstein gan. arXiv preprint arXiv:1806.06621, 2018.
Martin Arjovsky, Soumith Chintala, and Léon Bottou. Wasserstein generative adversarial networks. In ICML, 2017.
Jörg Bornschein and Yoshua Bengio. Reweighted wake-sleep. In ICML, 2015.
Tianqi Chen, Emily Fox, and Carlos Guestrin. Stochastic gradient hamiltonian monte carlo. In ICML, 2014.
Jifeng Dai, Yang Lu, and Ying-Nian Wu. Generative modeling of convolutional neural networks. arXiv preprint arXiv:1412.6296, 2014.
Zihang Dai, Amjad Almahairi, Philip Bachman, Eduard Hovy, and Aaron Courville. Calibrating energy-based generative adversarial networks. In ICLR, 2017a.
Zihang Dai, Zhilin Yang, Fan Yang, William W Cohen, and Ruslan R Salakhutdinov. Good semi-supervised learning that requires a bad gan. In NIPS, 2017b.
Vincent Dumoulin, Ishmael Belghazi, Ben Poole, Olivier Mastropietro, Alex Lamb, Martin Arjovsky, and Aaron Courville. Adversarially learned inference. In ICLR, 2017.
Zhe Gan, Liqun Chen, Weiyao Wang, Yuchen Pu, Yizhe Zhang, Hao Liu, Chunyuan Li, and Lawrence Carin. Triangle generative adversarial networks. In NIPS, 2017.
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In NIPS, 2014.
Ishaan Gulrajani, Faruk Ahmed, Martín Arjovsky, Vincent Dumoulin, and Aaron C. Courville. Improved training of wasserstein gans. In NIPS, 2017.
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. Gans trained by a two time-scale update rule converge to a local nash equilibrium. In NIPS, 2017.
Geoffrey E Hinton, Peter Dayan, Brendan J Frey, and Radford M Neal. The "wake-sleep" algorithm for unsupervised neural networks. Science, 268(5214):1158­1161, 1995.
Xun Huang, Yixuan Li, Omid Poursaeed, John Hopcroft, and Serge Belongie. Stacked generative adversarial networks. In CVPR, 2017.
Taesup Kim and Yoshua Bengio. Deep directed generative models with energy-based probability estimation. In ICLR Workshop, 2016.
Diederik P Kingma and Max Welling. Auto-encoding variational bayes. In ICLR, 2014.
Diederik P. Kingma, Danilo Jimenez Rezende, Shakir Mohamed, and Max Welling. Semi-supervised learning with deep generative models. In NIPS, 2014.
Daphne Koller and Nir Friedman. Probabilistic graphical models: principles and techniques. MIT press, 2009.
Alex Krizhevsky. Learning multiple layers of features from tiny images. Technical report, University of Toronto, 2009.
Volodymyr Kuleshov and Stefano Ermon. Neural variational inference and learning in undirected graphical models. In NIPS, 2017.
Samuli Laine and Timo Aila. Temporal ensembling for semi-supervised learning. In ICLR, 2017.
Hugo Larochelle, Michael I Mandel, Razvan Pascanu, and Yoshua Bengio. Learning algorithms for the classification restricted boltzmann machine. Journal of Machine Learning Research, 13(1):643­669, 2012.
Yann LeCun, Léon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278­2324, 1998.
Yann LeCun, Sumit Chopra, Raia Hadsell, M Ranzato, and F Huang. A tutorial on energy-based learning. Predicting structured data, 2006.
Daniel Levy, Matthew D. Hoffman, and Jascha Sohl-Dickstein. Generalizing hamiltonian monte carlo with neural networks. In ICLR, 2018.
10

Under review as a conference paper at ICLR 2019
Chongxuan Li, Taufik Xu, Jun Zhu, and Bo Zhang. Triple generative adversarial nets. In NIPS, 2017.
Xuanqing Liu and Cho-Jui Hsieh. From adversarial training to generative adversarial networks. arXiv preprint arXiv:1807.10454, 2018.
Lars Maaloe, Casper Kaae Sonderby, Soren Kaae Sonderby, and Ole Winther. Auxiliary deep generative models. In ICML, 2016.
Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, and Shin Ishii. Virtual adversarial training: a regularization method for supervised and semi-supervised learning. arXiv preprint arXiv:1704.03976, 2017.
Takeru Miyato, Toshiki Kataoka, Masanori Koyama, and Yuichi Yoshida. Spectral normalization for generative adversarial networks. In ICLR, 2018.
Youssef Mroueh and Tom Sercu. Fisher gan. In NIPS, 2017.
Youssef Mroueh, Chun-Liang Li, Tom Sercu, Anant Raj, and Yu Cheng. Sobolev GAN. In ICLR, 2018.
Radford M Neal. Mcmc using hamiltonian dynamics. Handbook of Markov Chain Monte Carlo, 2011.
Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and Andrew Y Ng. Reading digits in natural images with unsupervised feature learning. In NIPS workshop on deep learning and unsupervised feature learning, 2011.
Jiquan Ngiam, Zhenghao Chen, Wei Koh Pang, and Andrew Y. Ng. Learning deep energy models. In ICML, 2012.
Alec Radford, Luke Metz, and Soumith Chintala. Unsupervised representation learning with deep convolutional generative adversarial networks. arXiv preprint arXiv:1511.06434, 2015.
Antti Rasmus, Harri Valpola, Mikko Honkala, Mathias Berglund, and Tapani Raiko. Semi-supervised learning with ladder networks. In NIPS, 2015.
R. Salakhutdinov and G. Hinton. Deep boltzmann machines. Journal of Machine Learning Research, 5(2):1967 ­ 2006, 2009.
Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen. Improved techniques for training gans. In NIPS, 2016.
Jost Tobias Springenberg. Unsupervised and semi-supervised learning with categorical generative adversarial networks. In ICML, 2016.
Antti Tarvainen and Harri Valpola. Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results. In NIPS, 2017.
Yee Whye Teh, Alexandre H. Thiery, and Sebastian Vollmer. Consistency and fluctuations for stochastic gradient langevin dynamics. Journal of Machine Learning Research, 17:1­33, 2016.
Bin Wang and Zhijian Ou. Language modeling with neural trans-dimensional random fields. In IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU), 2017.
David Warde-Farley and Yoshua Bengio. Improving generative adversarial networks with denoising feature matching. In ICLR, 2017.
Xiang Wei, Zixia Liu, Liqiang Wang, and Boqing Gong. Improving the improved training of wasserstein GANs. In ICLR, 2018.
Max Welling and Yee Whye Teh. Bayesian learning via stochastic gradient langevin dynamics. In ICML, 2011.
Jianwen Xie, Yang Lu, Song-Chun Zhu, and Ying Nian Wu. Cooperative training of descriptor and generator networks. arXiv preprint arXiv:1609.09408, 2016.
Laurent Younes. Parametric inference for imperfectly observed gibbsian fields. Probability Theory and Related Fields, 82:625­645, 1989.
Junbo Zhao, Michael Mathieu, and Yann LeCun. Energy-based generative adversarial networks. In ICLR, 2017.
Xiaojin Zhu. Semi-supervised learning literature survey. Technical report, University of Wisconsin-Madison, 2006.
11

Under review as a conference paper at ICLR 2019

Supplement for "Learning Neural Random Fields with Inclusive
Auxiliary Generators"

6 SGLD/SGHMC

Theorem 1. Denote the target density as p(z; ) with given . Assume that one can compute a noisy,

unbiased

estimate

(z, ; )

to

the

gradient

 z

log p(z; ),

where



is

an

auxiliary

random

variable

which contains all the randomness involved in constructing the estimate, namely E [(z, ; )] =

 z

log

p(z;

).

Assume

the

stability

Assumptions

4

in

Teh

et

al.

(2016)

holds.

For a sequence of asymptotically vanishing time-steps {l, l  1} (satisfying

 l=1

l

=



and

 l=1

l2

<

), an i.i.d.

sequence (l), and an independent and i.i.d.

sequence l

of auxiliary

random variables, l  1, the SGLD iterates as follows, starting from z(0):

z(l)

=

z(l-1)

+

l 2

(z(l-1),

l

;

)

+

l(l), (l)  N (0, I), l = 1, · · ·

(10)

Starting from z(0) and v(0) = 0, the SGHMC iterates as follows:

 v(l)

=

v(l-1)

+

l 2

(z(l-1), l;

)

+

z(l) = z(l-1) + v(l), l = 1, · · ·

l(l), (l)  N (0, I)

(11)

Then in both cases, the non-homogeneous Markov chain z(l), l  1 converges to the equilibrium distribution p(z; ).

7 PROOF OF PROPOSITION 1

Proposition 1. Let z (x, h), p(z; ) p(x)q(h|x),  (, )T in Theorem 1. The initial value

(x(0), h(0)) is obtained from ancestral sampling by the generator. The SGLD/SGHMC as shown in

Eq.(10)/(11)

iteratively

generates

(x(m), h(m)),

m

=

1, · · · .

Then,

  x(m)

log q(h(m), x(m))

is

an

unbiased

estimate

of

the

gradient

  x(m)

log

q(x(m)),

m

=

0, 1, · · · .

Proof. Note that Langevin dynamics and Hamiltonian dynamics are reversible Neal (2011). Thus the SGLD/SGHMC transitions Eq.(10)/(11) satisfy the detailed balance condition:

(h(m-1), x(m-1))K(h(m), x(m)|h(m-1), x(m-1)) = (h(m), x(m))K(h(m-1), x(m-1)|h(m), x(m)),

where (·) denotes the target density, and K(·|·) denotes the transition kernel. Also note that

Ehq (h|x)

 x

log

q(h,

x)

=

 x

log

q(x).

Thus if we show that h(m) is indeed drawn from

q(h(m)|x(m)) during sample revision, m = 0, 1, · · · , then the unbiasedness will hold.

Denote by (m)(h(m), x(m)) the state-occupation density at step m. Then we need to show that (m)(h(m)|x(m)) actually follows (h(m)|x(m)), i.e. q(h(m)|x(m)), m = 0, 1, · · · .

First, it is obvious that this holds for (h(0), x(0)). Then, we proceed by mathematical induction. Suppose (m-1)(h(m-1)|x(m-1)) = (h(m-1)|x(m-1)). Then we have

(m-1)(h(m-1), x(m-1))K(h(m), x(m)|h(m-1), x(m-1))

=(m-1)(h(m-1)

,

x(m-1))

(h(m) (h(m-1)

, ,

x(m)) x(m-1))

K

(h(m-1)

,

x(m-1)|h(m),

x(m)).

(12)

12

Under review as a conference paper at ICLR 2019

Integrating out (h(m-1), x(m-1)) from both sides of Eq.12, we obtain

(m)(h(m), x(m)) = (h(m), x(m))

(m-1)(x(m-1)) (x(m-1))

K

(x(m-1)|h(m),

x(m)

)

x(m-1)

= (h(m), x(m))

(m-1)(x(m-1)) (x(m-1))

K

(x(m-1)|x(m))

x(m-1)

where the second equality, i.e. K(x|h , x ) = K(x|x ), holds because in the SGLD/SGHMC transitions Eq.(10)/(11), generating next step x only depends on current x and is independent of current h . Then we have

(m)(h(m)|x(m))

=

(h(m)

|x(m)

)



(x(m)) (m)(x(m))

(m-1)(x(m-1) (x(m-1))

)

K

(x(m-1)

|x(m))

x(m-1)

= (h(m)|x(m))

where the second equality holds because we have

(x(m)) (m)(x(m))

(m-1)(x(m-1) (x(m-1))

)

K

(x(m-1)

|x(m)

)

x(m-1)

1 = (m)(x(m))

(m-1)(x(m-1))

K

(x(m-1)|x(m))(x(m) (x(m-1))

)

x(m-1)

=1

Thereby, we show h(m)  (h(m)|x(m)), i.e. q(h(m)|x(m)). This concludes the inductive step.

8 SEMI-SUPERVISED LEARNING WITH INCLUSIVE-NRFS

Algorithm 2 Semi-supervised learning of inclusive-NRFs

repeat

Sampling:

Draw a unsupervised minibatch U  p~(x~)p(x)q(h|x) and a supervised minibatch S  L; Updating:

Update  by ascending:

1 |U |

(x~,x,h)U

[ u (x~)

-

 u (x)]

+

d

1 |S |

(x~,y~)S [logp(y~|x~)]

-

1 |U

|

(x~,x,h)U cH(p(y|x~)) + p [u(x~)]2 ;

Update  by ascending:

1 |U |

(x~,x,h)U logq(x, h);

until convergence

Apart from the basic losses, as shown in Eq.9, in applying inclusive-NRFs in SSL, there are some regularization losses that are helpful to guide the semi-supervised learning.
Confidence loss. Similar to Springenberg (2016); Li et al. (2017), we add the minimization of the conditional entropy of p(y|x~) averaged over training data to the loss w.r.t.  (i.e. the first line in Eq.8) as follows:

Lc() = Ep~(x~) [H(p(y|x~))] = -Ep~(x~)

p(y|x~) log p(y|x~)
y

In this manner, we encourage the classifier p(y|x) derived from the RF to make classifications confidently. In practice, we use stochastic gradients of Lc() over minibatches in optimizing , as shown in Algorithm 2.

13

Under review as a conference paper at ICLR 2019

Potential control loss. For random fields, the data log-likelihood logp(x~) is determined relatively by the potential value u(x~). To avoid the potential values not to increase unreasonably, we could control the squared potential values, by minimizing:
Lp() = Ep~(x~) [u(x~)]2
In this manner, the potential values would be attracted to zeros. In practice, we use stochastic gradients of Lp() over minibatches in optimizing , as shown in Algorithm 2.

9 PROOF OF PROPOSITION 2

Proposition 2. For the RF as defined in Eq. 1, we have the following evidence upper bound: logp(x~) = U (x~; , ) - KL(q(x)||p(x))  U (x~; , ), U (x~; , ) u(x~) - Eq(x) [u(x)] + H [q(x)] .

Proof. Note that logp(x~) = u(x~) - logZ(). And we have the following lower bound on Z()

logZ() = log

exp(u(x))dx = log

q

(x)

exp(u (x)) q (x)

dx



q

(x)log

exp(u (x)) q (x)

dx.

This can

be also seen from:

q(x)u(x)dx = q(x)logp(x)dx + logZ()

= - KL(q(x)||p(x)) + logZ() + q(x)logq(x)dx.

Furthermore, it can be seen that learning in Kim & Bengio (2016) amounts to optimizing the following

evidence upper bound:

max min U(x~; , ),


which is unfortunately not revealed in this manner in Kim & Bengio (2016).

10 CONNECTION BETWEEN INCLUSIVE-NRFS AND GANS

Note that for the generator as defined in Eq. 2, we have the following joint density

logq(x,

h)

=

-

1 22

||x

-

g(h)||2

+

constant.

The generator parameter  is updated according to Eq. 4, which is rewritten as follows:

Ep(x)q(h|x) [logq(x, h)] = 0

Specifically, we draw (h , x )  q and then perform one-step SGLD to obtain (h, x). To simply the analysis of the connection, suppose h  h , x  g(h )  g(h). Then we have

x = x + 1 2



x logp(x)

+
x=x

1(1), (1)  N (0, I)

x

-

g(h)



1 2

 x logp(x)

= 1

x=g (h)

2

 x u(x) x=g(h)

(13)

The gradient in the updating step in Algorithm 1 becomes:

logq(x, h)

=

1 2

  g(h)

[x - g(h)]



1 2

  g(h)

1 2

 x u(x)

=

1 2

1 2

  u(g(h))

x=g (h)

14

Under review as a conference paper at ICLR 2019

where

 

g(h)

is

a

matrix

of

size

dim()

×

dim(x).

Therefore,

the

inclusive-NRF

Algorithm

1

can

be viewed to perform the following steps:

1. Draw an empirical example x~  p0.

2. Draw h  p(h), x = g(h), and generate x by one-step-gradient according to Eq. 13.

3. Update  by ascending: u(x~) - u(x).

4.

Update  by descending:

-

 

u

(g(h)).

Now suppose that we interpret the potential function u(x) as the discriminator in GANs (or the critic in Wasserstein GANs), which assign high scalar scores to empirical samples x~  p0 and low scalar scores to generated samples x. Then, the inclusive-NRF training could be viewed as playing a
two-player minimax game:

min


max


Ex~p0

[u (x~)]

-

Ehp(h)

[u (g (h))]

,

(14)

except that in optimizing , the generated sample are further revised by taking one-step-gradient of u(x) w.r.t. x (as shown in the above Step 2). The discriminator u is trained to discriminate between empirical samples and generated samples, while the generator q is trained to fool the discriminator by assigning higher scores to generated samples. From the above analysis, we find some interesting
connections between inclusive-NRFs and existing studies in GANs.

· The optimization shown in Eq. 14 is in fact the same as that in Wasserstein GANs (Theorem 3 in Arjovsky et al. (2017)), except that in Wasserstein GANs, the critic u(x) is constrained to be 1-Lipschitz continuous. So hopefully we can improve the inclusive-NRF training by constraining the discriminator u(x) to be 1-Lipschitz continuous, e.g. by utilizing the recently developed technique of spectral normalization of weight matrices in the discriminator as in Miyato et al. (2018).
· To optimize , the generated sample is obtained by taking one-step-gradient of u(x) w.r.t. x. The tiny perturbation guided by the gradient to increase the score for the generated sample in fact creates an adversarial example. A similar idea is presented in Liu & Hsieh (2018) that when feeding real samples to the discriminator, 5 steps of PGD (Projected Gradient Descent) attack is taken to decrease the score to create adversarial samples. It is shown in Liu & Hsieh (2018) that training the discriminator with adversarial examples significantly improves the GAN traning. Hopefully in training the discriminator in inclusive-NRFs, the adversarial attack could be increasing scores for generated samples, or decreasing scores for real samples, or a mixed one.
· The above analysis assume the use of one-step SGLD. It can be seen that running finite steps of SGLD in sample revision in fact create adversarial samples to fool the discriminator.

11 DETAILS OF EXPERIMENTS
11.1 GMM SYNTHETIC EXPERIMENT
In the GMM experiment, we use the following procedure to estimate the metrics "covered modes" and "realistic ratio" for each trained model.
1. Stochastically generate 100 samples. 2. A mode is defined to be covered (not missed) if there exist generated samples located closely
to the mode (with squared distance < 0.02), and those samples are said to be realistic. 3. Count how many modes are covered and calculate the proportion of realistic samples. 4. Repeat the above steps 100 times and perform averaging.
For each method, we independently train 10 models and calculate the mean and standard deviation (SD) across the 10 independent runs.
The network architectures and hyperparameters are the same for all methods, as listed in Table 5. We use SGLD Welling & Teh (2011) for inclusive-NRFs on this synthetic dataset, with empirical revision hyperparameters l = 0.01.

15

Under review as a conference paper at ICLR 2019
11.2 IMAGE GENERATION ON CIFAR-10
Network architectures. For convenience, we refer to the two neural networks in implementing the potential u and the generator q in NRFs as the potential network and the generator network, respectively. For comparison of different methods, we use the same network architectures as in Table 4 in (Miyato et al., 2018) (ResNet using spectral normalization) for unsupervised learning of NRFs. For supervised learning, we use the semi-supervised inclusive-NRF Algorithm 2 over all labeled images. The difference in network architectures used for semi-supervised and unsupervised learning of inclusive-NRFs is that for SSL, the output layer of the potential network contains K = 10 scalar units, while a single scalar output unit is used for unsupervised learning.
Hyperparameters. We use Adam optimizer with the hyperparameter (1 = 0, 2 = 0.9 and  = 0.0003 for random fields,  = 0.0001 for generators). For sample revision for inclusive-NRFs, we empirically choose SGLD with L = 1 (l = 0.003). More revision steps do not significantly improve unsupervised IS, as discussed in section 4.4 Note that we use the potential control loss in both unsupervised (p = 0.1) and supervised (d = 1, p = 0.1) settings, which is found beneficial for stable training.
Evaluation. Figure 5(c)(d) show the generated samples from inclusive-NRFs for unsupervised and supervised settings respectively. We compute inception score (IS) and Frechet inception distance (FID) in the same way as in Miyato et al. (2018). We trained 10 models with different random seeds, and then generate 5000 images 10 times and compute the average inception score and the standard deviation. We compute FID between the true distribution and the generated distribution empirically over 10000 (test set) and 5000 samples.
11.3 SEMI-SUPERVISED EXPERIMENT ON MNIST, SVHN AND CIFAR-10
The network architectures (taken from the released code from Salimans et al. (2016) and widely used in Li et al. (2017); Dai et al. (2017b)) and hyperparameters for semi-supervised inclusiveNRFs on MNIST, SVHN and CIFAR-10 are listed in Table 6, Table 7 and Table 8 respectively. We use SGHMC for semi-supervised inclusive-NRFs for all three datasets, with empirical revision hyperparameters ( = 0.5, l = 0.003) for MNIST and CIFAR-10, and ( = 0.5, l = 0.01) for SVHN. The confidence loss is employed for semi-supervised inclusive-NRFs on MNIST and SVHN, and the potential control loss is employed on CIFAR-10.
Figure 5(a)(b) show the generated samples from semi-supervised inclusive-NRFs trained over SVHN and CIFAR-10 respectively.
11.4 ABLATION STUDY OF INCLUSIVE-NRFS ON CIFAR-10
For unsupervised learning, we use the same networks as in Table 3 in Miyato et al. (2018) (standard CNN using spectral normalization). We use Adam optimizer with the hyperparameter ( = 0.0002, 1 = 0, 2 = 0.9). For semi-supervised learning, the experimental setting is the same as in section 11.3 including the networks, number of labels, etc. For different revision steps, we use (l = 0.003) for SGLD, and ( = 0.5, l = 0.003) for SGHMC. The potential control loss is employed in both unsupervised (p = 0.1) and semi-supervised (d = 100, p = 0.1) learning.
12 SSL TOY EXPERIMENT
In Figure 2, we present the performance of semi-supervised inclusive-NRFs for SSL on a synthetic dataset, which emphasizes that inclusive-NRFs can provide (unnormalized) density estimates for p(x), p(x, y = 1) and p(x, y = 2). In contrast, the use of GANs as general purpose probabilistic generative models has been limited by the difficulty in using them to provide density estimates or even unnormalized potential values for sample evaluation.
The dataset is a 2D GMM with 16 Gaussian components, uniformly laid out on two concentric circles. The two circles represent two different classes, each class with 4 labeled data and 400 unlabeled data. The network architectures are the same as in Table 5, except that the neural network which implement the potential function u(x, y) for SSL now has two units in the output.
16

Under review as a conference paper at ICLR 2019

(a) Training data

(b) Learned u(x) (c) Learned u(x, y = 1) (d) Learned u(x, y = 2)

Figure 2: SSL toy experiment based on semi-supervised inclusive-NRFs. Each class has 4 labeled
points, red dots for class 1 and blue for class 2. The learned potentials for u(x), u(x, y = 1) and u(x, y = 2) are shown in (b)(c)(d) respectively.

13 LATENT SPACE INTERPOLATION

Figure 3: Latent space interpolation with inclusive-NRFs on MNIST. The leftmost and rightmost columns are from stochastic generations x1 with latent code h1 and x2 with h2. The columns in between correspond to the generations from the latent codes interpolated linearly from h1 to h2.
Figure 3 shows that the auxiliary generator smoothly outputs transitional samples as the latent code h moves linearly in the latent space. The interpolated generation demonstrates that the model has indeed learned an abstract representation of the data.
14 CLASS-CONDITIONAL GENERATION
Figure 4 shows class-conditional generation results on MNIST with semi-supervised inclusive-NRFs. Notice that the generator does not explicitly include class labels, thus it is unable to perform classconditional generation directly. However, the random field has modeling of p(x, y), based on which we can perform class-conditional generation as follows:
1. Generate a sample x unconditionally, by ancestral sampling with the generator. 2. Predict the label y for the sample x by the random field; 3. Starting from x, running SGLD/SGHMC revision with p(x|y) as the target density by
fixing y. The resulting samples could be viewed as conditional generations, according to Theorem 1.

17

Under review as a conference paper at ICLR 2019

Figure 4: Conditional generated samples from semi-supervised inclusive-NRFs trained on MNIST. Due to sample revision, the background pixels are not purely black.
Table 5: Network architectures and hyperparameters for the 2D GMM data.

Random Field
Input 2-dim data MLP 100 units, Leaky ReLU MLP 100 units, Leaky ReLU
MLP 1 unit, Linear
Batch size Number of iterations Leaky ReLU slope
Learning rate Optimizer
Sample revision steps

Generator
Noise h (2-dim) MLP 50 units, ReLU MLP 50 units, ReLU MLP 2 units, Linear
100 160,000
0.2 0.001 Adam (1 = 0.5, 2 = 0.9) L = 10

Table 6: Network architectures and hyperparameters for semi-supervised inclusive-NRFs on MNIST

Random Field
Input 28 × 28 Gray Image MLP 1000 units, Leaky ReLU, Weight norm MLP 500 units, Leaky ReLU, Weight norm MLP 250 units, Leaky ReLU, Weight norm MLP 250 units, Leaky ReLU, Weight norm MLP 250 units, Leaky ReLU, Weight norm
MLP 10 units, Linear, Weight norm
Batch size Number of epochs Leaky ReLU slope
Learning rate Optimizer
Sample revision steps  in SSL

Generator Noise h (100-dim) MLP 500 units, Sotfplus, Batch norm MLP 500 units, Sotfplus, Batch norm MLP 784 units, Sigmoid
100 200 0.2 0.001 Adam (1 = 0.0, 2 = 0.9) L = 20 d = 10, c = 10, p = 0

18

Under review as a conference paper at ICLR 2019

Table 7: Network architectures and hyperparameters for semi-supervised inclusive-NRFs on SVHN

Random Field
Input 32 × 32 Colored Image 3 × 3 conv. 64, Leaky ReLU, Weight norm 3 × 3 conv. 64, Leaky ReLU, Weight norm 3 × 3 conv. 64, Leaky ReLU, Weight norm
stride=2, dropout2d=0.5 3 × 3 conv. 128, Leaky ReLU, Weight norm 3 × 3 conv. 128, Leaky ReLU, Weight norm 3 × 3 conv. 128, Leaky ReLU, Weight norm
stride=2, dropout2d=0.5 3 × 3 conv. 128, Leaky ReLU, Weight norm 1 × 1 conv. 128, Leaky ReLU, Weight norm 1 × 1 conv. 128, Leaky ReLU, Weight norm
MLP 10 units, Linear, Weight norm
Batch size Number of epochs Leaky ReLU slope
Learning rate Optimizer
Sample revision steps  in SSL

Generator Noise h (100-dim) MLP 8192 units, ReLU, Batch norm Reshape 512 × 4 × 4 5 × 5 deconv. 256, ReLU, Stride=2 5 × 5 deconv. 128, ReLU, Stride=2 5 × 5 deconv. 3, Tanh, Stride=2
100 400 0.2 0.001 Adam (1 = 0.0, 2 = 0.9) L = 10 d = 10, c = 10, p = 0

Table 8: Network architectures and hyperparameters for semi-supervised inclusive-NRFs on CIFAR10

Random Field
Input 32 × 32 Colored Image 3 × 3 conv. 128, Leaky ReLU, Weight norm 3 × 3 conv. 128, Leaky ReLU, Weight norm 3 × 3 conv. 128, Leaky ReLU, Weight norm
stride=2, dropout2d=0.5 3 × 3 conv. 256, Leaky ReLU, Weight norm 3 × 3 conv. 256, Leaky ReLU, Weight norm 3 × 3 conv. 256, Leaky ReLU, Weight norm
stride=2, dropout2d=0.5 3 × 3 conv. 512, Leaky ReLU, Weight norm 1 × 1 conv. 256, Leaky ReLU, Weight norm 1 × 1 conv. 128, Leaky ReLU, Weight norm
MLP 10 units, Linear, Weight norm
Batch size Number of epochs Leaky ReLU slope
Learning rate Optimizer
Sample revision steps  in SSL

Generator Noise h (100-dim) MLP 8192 units, ReLU, batch norm Reshape 512 × 4 × 4 5 × 5 deconv. 256, ReLU, Stride=2 5 × 5 deconv. 128 ReLU, stride=2 5 × 5 deconv. 3, Tanh, Stride=2
100 600 0.2 0.001 Adam (1 = 0.0, 2 = 0.9) L = 10 d = 100, c = 0, p = 0.1

19

Under review as a conference paper at ICLR 2019
(a) (b)
(c) (d) Figure 5: Generated samples from semi-supervised inclusive-NRFs (i.e. trained for SSL) on SVHN and CIFAR-10 are shown in (a) and (b) respectively. Generated samples from unsupervised and supervised training of inclusive-NRFs on CIFAR-10 are shown in (c) and (d) respectively.
20

