Under review as a conference paper at ICLR 2019
LOCALIZED RANDOM PROJECTIONS CHALLENGE BENCHMARKS FOR BIO-PLAUSIBLE DEEP LEARNING
Anonymous authors Paper under double-blind review
ABSTRACT
Similar to models of brain-like computation, artificial deep neural networks rely on distributed coding, parallel processing and plastic synaptic weights. Training deep neural networks with the error-backpropagation algorithm, however, is considered bio-implausible. An appealing alternative to training deep neural networks is to use one or a few hidden layers with fixed random weights or trained with an unsupervised, local learning rule and train a single readout layer with a supervised, local learning rule. We find that a network of leaky-integrate-andfire neurons with fixed random, localized receptive fields in the hidden layer and spike timing dependent plasticity to train the readout layer achieves 98.1% test accuracy on MNIST, which is close to the optimal result achievable with errorbackpropagation in non-convolutional networks of rate neurons with one hidden layer. To support the design choices of the spiking network, we systematically compare the classification performance of rate networks with a single hidden layer, where the weights of this layer are either random and fixed, trained with unsupervised Principal Component Analysis or Sparse Coding, or trained with the backpropagation algorithm. This comparison revealed, first, that unsupervised learning does not lead to better performance than fixed random projections for large hidden layers on digit classification (MNIST) and object recognition (CIFAR10); second, networks with random projections and localized receptive fields perform significantly better than networks with all-to-all connectivity and almost reach the performance of networks trained with the backpropagation algorithm. The performance of these simple random projection networks is comparable to most current models of bio-plausible deep learning and thus provides an interesting benchmark for future approaches.
1 INTRODUCTION
While learning a new task, synapses deep in the brain undergo task-relevant changes (HayashiTakagi et al., 2015). These synapses are often many neurons downstream of sensors and many neurons upstream of actuators. Since the rules that govern such changes deep in the brain are poorly understood, it is appealing to draw inspiration from deep artificial neural networks (DNNs) (LeCun et al., 2015). DNNs and the cerebral cortex process information in multiple layers of many neurons (Yamins & DiCarlo, 2016; Kriegeskorte, 2015) and in both, the artificial and the biological neural networks, learning depends on changes of synaptic strengths (Hebbian theory, Hebb (1949)). However, learning rules in the brain are most likely different from the backpropagation algorithm (Crick, 1989; Marblestone et al., 2016; Rumelhart et al., 1986). Furthermore, biological neurons communicate by sending discrete spikes as opposed to real-valued numbers used in DNNs. Differences like these suggest that there exist other, possibly equally powerful, algorithms that are capable to solve the same tasks by using different, more biologically plausible mechanisms. Thus, an important question in computational neuroscience is how to explain the fascinating learning capabilities of the brain with bio-plausible network architectures and learning rules. On the other hand, from a pure machine learning perspective there is increasing interest in neuron-like architectures with local learning rules, mainly motivated by the current advances in neuromorphic hardware (Nawrocki et al., 2016).
Image recognition is a popular task to test the proposed models. Because of its relative simplicity and popularity, the MNIST dataset (28×28-pixel grey level images of handwritten digits, LeCun
1

Under review as a conference paper at ICLR 2019
(1998)) is often used for benchmarking. Typical performances of existing models are around 9799% classification accuracy on the MNIST test set (see section 2 and Table 8). This value lies in the region of the benchmarks for a large class of classical DNNs trained with backpropagation but without data-augmentation or convolutional layers (see table in LeCun (1998)). Thus, accuracies around this value are assumed to be an empirical signature of backpropagation-like deep learning (Lillicrap et al., 2016; Sacramento et al., 2017). It is noteworthy, however, that several of the most promising approaches that perform well on MNIST have been found to fail on harder tasks (Bartunov et al., 2018).
An alternative to supervised training of all layers with backpropagation are fixed random weights, as proposed by general approximation theory (Barron, 1993) and the extreme learning field (Huang et al., 2006), or unsupervised training in the first layers, combined with supervised training of a readout layer. Unsupervised methods are appealing since they can be implemented with local learning rules, see e.g. "Oja's rule" (Oja, 1982; Sanger, 1989) for principal component analysis or algorithms in Olshausen & Field (1997); Rozell et al. (2008); Liu & Jia (2012); Brito & Gerstner (2016) for sparse coding. A single readout layer can also be implemented with a local delta-rule (also called "perceptron rule"), which may be implemented by pyramidal spiking neurons with dendritic prediction of somatic spiking (Urbanczik & Senn, 2014). Since it is pointless to simply stack multiple fully connected layers trained with principal component analysis or sparse coding (Olshausen & Field, 1997) we investigate here networks with a single hidden layer.
The main objective of this study was to see how far we can go with a single hidden layer and local learning rules in networks of spiking neurons. To support the design choices of the spiking model, we compared the classification performance of different rate networks: networks trained with backpropagation, networks where the hidden layer is trained with unsupervised methods, and networks with fixed random projections in the hidden layer. Since sparse connectivity is sometimes superior to dense connectivity (Litwin-Kumar et al., 2017; Bartunov et al., 2018) and successful convolutional networks leverage local receptive fields, we investigated also sparse connectivity between input and hidden layer, where each hidden neuron receives input only from a few neighboring pixels of the input image.
2 RELATED WORK
In recent years, many bio-plausible approaches to deep learning have been proposed (see e.g. Marblestone et al. (2016) for a review). For achieving performances similar to deep learning methods, existing approaches usually use either involved architectures or elaborate mechanisms to approximate the backpropagation algorithm. Examples include the use of convolutional layers (Tavanaei & Maida (2016); Lee et al. (2018); Kheradpisheh et al. (2018) and table therein), dendritic computations (Hussain et al., 2014; Guergiuev et al., 2016; Sacramento et al., 2017) or approximations of the backpropagation algorithm such as feedback alignment (Lillicrap et al., 2016; Baldi et al., 2016; Nøkland, 2016; Samadi et al., 2017; Kohan et al., 2018; Bartunov et al., 2018) equilibrium propagation (Scellier & Bengio, 2017), membrane potential based backpropagation (Lee et al., 2016), restricted Boltzmann machines and deep belief networks (O'Connor et al., 2013; Neftci et al., 2014), (localized) difference target propagation (Lee et al., 2015; Bartunov et al., 2018), reinforcementsignal models like AuGMEnT (Rombouts et al., 2015) or approaches using predictive coding (Whittington & Bogacz, 2017). Many models implement spiking neurons to stress bio-plausibility (Liu et al. (2016); Neftci et al. (2017); Kulkarni & Rajendran (2018); Wu et al. (2018); Liu & Yue (2018) and table therein) or for coding efficiency (O'Connor et al., 2017). The conversion of DNNs to spiking neural networks (SNN) after training with backpropagation (Diehl et al., 2015) is a common technique to evade the difficulties of training with spikes. Furthermore, there are models including recurrent activity (Spoerer et al., 2017; Bellec et al., 2018) or even starting directly from realistic circuits (Delahunt & Kutz, 2018). We refer to Table 8 for a list of current bio-plausible MNIST benchmark models.
3 RESULTS
We study networks that consist of an input (l0), one hidden (l1) and an output-layer (l2) connected by weight matrices W1 and W2 (Figure 1). Training the hidden layer weights W1 with standard
2

Under review as a conference paper at ICLR 2019

A Both layers supervised
label: "8"

B Supervised

C
label: "8"

l2: output W2 W2T
l1: hidden W1
l0: Input

l2: output W2 V1
l1: hidden W1
l0: Input

p

Unsupervised or fixed RP

l1 W1
Full
 connectivity
l1
W1
Localized
 connectivity

Figure 1: The network model. A Training with Backpropagation (BP) through one hidden layer. B Architecture with unsupervised feature learning or fixed Random Projections (RP) in the first layer and a supervised classifier in the second layer. W stands for feed-forward, V for recurrent, inhibitory weights (Only used for unsupervised feature learning of the first layer weights W1). C Illustration of fully connected and localized receptive fields of W1.
supervised training involves (non-local) error backpropagation using the transposed weight matrix WT2 (Figure 1A). In the bio-plausible network considered in this paper (Figure 1B), the input-tohidden weights W1 are either learned with an unsupervised method (Principal Component Analysis or Sparse Coding) or are fixed random projections. The unsupervised methods assume recurrent inhibitory weights V1 between hidden units to implement competition.

3.1 SPIKING LOCALIZED RANDOM PROJECTIONS
We first present the results with networks of leaky integrate-and-fire (LIF) neurons. The network architecture is as in Figure 1B, but without the recurrent connections V1. For implementing localized Random Projections (l-RP) in the hidden layer weights W1, we first chose the centers of the localized receptive fields at random positions in the input space and then randomly chose the weights therein, see Figure 1C. The receptive field patches span p × p pixels around their center position (we used p = 10 for the 28×28-pixel MNIST data). The output layer weights W2 are trained with a supervised spike timing dependent plasticity (STDP) rule.

3.1.1 LIF AND STDP DYNAMICS

The spiking dynamics follow the usual LIF equations (see methods A.4) and the readout weights
W2 evolve according to a supervised STDP delta rule using post-synaptic spike-traces tri(t) and a post-synaptic target trace tgti(t)

tr

dtri(t) dt

=

-tri(t) +

 t - tif

f

w2,ij =  · tgtipost(t) - tripost(t)  t - tjf .

(1)

Thus, for a specific readout weight w2,ij, the post-synaptic trace is updated at every post-synaptic spike time tfi and the weight is updated at every pre-synaptic spike time tfj . The target trace is used for feeding in the one-hot coded, supervisory signal for the MNIST classification into the output
layer (l2).

For a proof-of-principle and efficient parameter search we first investigate an LIF rate model. This rate model mimics the LIF dynamics by using the LIF activation function LIF as nonlinearity,

rate(u) = LIF (u) =

abs - m ln

1-  u

-1
,

(2)

3

Under review as a conference paper at ICLR 2019

where u is the membrane potential, abs the refractory period, m the membrane time constant and  the firing threshold of the LIF model. Furthermore, it employs the rate-version of the STDP delta
rule Equation 1 (see methods section A.4 for details)

wij = ~ · ratepjre · tgtratepiost - ratepiost ,

(3)

where tgtrateipost is the post-synaptic target rate, corresponding to the post-synaptic target trace tgti(t) in Equation 1. We obtained similar spiking and weight dynamics when the readout weights W2 were either directly trained with STDP or trained with the LIF rate model and then plugged into the
spiking LIF network (as done in e.g. Diehl et al. (2015)).

To illustrate the LIF and STDP dynamics, a toy example consisting of one pre- connected to one post-synaptic neuron was integrated for 650 ms. The pre- and post-synaptic membrane potentials show periodic spiking (Figure 2A) which induces post-synaptic spike traces and corresponding weight changes (Figure 2B), according to Equation 1. For the MNIST task, Figure 2C shows a raster plot for an exemplary training and testing protocol. During activity transients after pattern switches, learning is disabled until regular spiking is recovered. This is done, first, to ensure stability during activity transients (see Naud et al. (2008) and references therein) and second, to achieve decorrelation between the activities of subsequent patterns, as needed for stochastic gradient descent (SGD). During the testing period, learning is shut off permanently (see methods section A.4 for more details).

AB

C Training phase

Testing phase
...

106 +
Figure 2: Spiking LIF and STDP dynamics. A Dynamics of the pre- and postsynaptic membrane potentials, spike-traces and the weight value (B) of a toy example with two neurons and one synapse. The weight decreases when the post-trace is above the post-target-trace (c.g. Equation 1 and subsection A.4). Both neurons receive static external input: Iperxet Ipeoxstt   (spiking threshold). C Rasterplot of a network trained on MNIST, where every spike is marked with a dot. The background color indicates the corresponding layers: input (blue, n0 = 100 neurons), hidden (green, nh = 100) and output (red, n2 = 10). Bold vertical lines indicate pattern switches, thin lines indicate ends of transient phases (indicated by semi-transparency), during which learning is disabled. Left: Behaviour at the beginning of the training phase. Right: Testing period (learning off) after 104 iterations (presented patterns), which is 1/6 of an epoch. The output layer has started to learn useful, 1-hot encoded class predictions. A downsampled (12 × 12) version of MNIST was used for improved visibility. Other parameters, see appendix Appendix B.
3.1.2 CLASSIFICATION RESULTS FOR LIF l-RP
When directly trained with the STDP rule in Equation 1 the spiking LIF l-RP model (nh = 5000 hidden units and patch size p = 10) reaches 98.1% test accuracy on MNIST. The corresponding LIF
4

Under review as a conference paper at ICLR 2019
rate model reaches 98.5% test accuracy. Transferring weights learned with the LIF rate model into the spiking LIF model resulted in similar accuracies as the LIF rate model. Table 1 compares the performances of the rate and spiking LIF l-RP models with the reference algorithm l-BP, which is a rate model trained with backpropagation, see subsection 3.2 and subsection 3.3 (for same hidden layer size nh and patch size p). We can see that the spiking LIF model almost reaches the performance of the corresponding rate model. The remaining gap (0.4%) between rate and spiking LIF model presumably stems from transients and the shorter training time of the spiking model (only 106 compared to 107 iterations due to long simulation times). Both, the rate and spiking LIF model of l-RP achieve accuracies close to the backpropagation reference algorithm l-BP and certainly lie in the range of current bio-plausible MNIST benchmarks, i.e. 97-99% test accuracy (see section 2 and Table 8). Based on these numbers we conclude that the spiking LIF model of localized random projections using STDP is capable of learning the MNIST task to a level that is competitive with known benchmarks for spiking networks.
l-RP spiking LIF l-RP rate LIF l-BP 98.1 ± 0.04 98.5 ± 0.16 98.8 ± 0.1
Table 1: Test accuracies (%) on MNIST for nh = 5000 hidden neurons and receptive field size p = 10. The reference algorithm l-BP is a rate model trained with backpropagation, see subsection 3.2 and subsection 3.3. The rate models were trained with 107 iterations (pattern presentations), the spiking LIF model with 106 iterations.
3.2 BENCHMARKING RATE MODELS TRAINED WITH UNSUPERVISED LEARNING AND
BACKPROPAGATION
To justify the design choices of the spiking model, we systematically investigated rate models with different methods to initialize or learn the hidden layer weights W1 (see Figure 1 and methods subsection A.1 for details). To set these hidden layer weights, we use either one of the unsupervised methods Principal Component Analysis (PCA) or Sparse Coding (SC), or train only the readout layer W2 and use fixed Random Projections (RP, as in subsection 3.1) for the hidden layer weights W1 (see Figure 1B). All these methods can be implemented with local, bio-plausible learning rules (Oja, 1982; Olshausen & Field, 1997). As a reference and upper performance bound, we train networks with the same architecture with standard backpropagation (BP, see Figure 1A). As a more bio-plausible approximation of BP, we include Feedback Alignment (FA, Lillicrap et al. (2016)) which uses fixed random feedback weights for error-backpropagation (see methods subsection A.3 for further explanation). A Simple Perceptron (SP) without a hidden layer serves as a simplistic reference, since it corresponds to direct classification of the input.
The hidden-to-output weights W2 are trained with standard stochastic gradient descent (SGD), using a one-hot representation of the class label as target. Since no error-backpropagation is needed for a single layer, the learning rule is local ("delta" or "perceptron"-rule, similar to Equation 3 of the LIF rate model). Therefore the system as a whole is bio-plausible in terms of online learning and synaptic updates using only local variables. For computational efficiency, we train first the hidden layer and then the output layer, however, both layers could be trained simultaneously.
We compared the test errors on the MNIST digit recognition data set for varying numbers of hidden neurons nh (Figure 3). The green PCA curve in Figure 3 ends at the vertical line nh = d = 784 because the number of principal components (PCs), i.e. the number of hidden units nh, is limited by the input dimension d. Since the PCs span the subspace of highest variance, classification performance quickly improves when adding more PCs for small nh and then saturates for larger nh, crossing the (dotted) Simple Perceptron line at nh = 25 PC hidden neurons. This intersection and other measures of effective dimensionality (see methods subsection A.1) suggest that the MNIST dataset lies mostly in a low-dimensional linear subspace with deff  25 d.
SC performance (red curve) starts at a higher test error but improves as quickly with nh as PCA. With overcomplete representations (nh > d), the network achieves a remarkable classification performance of around 96 % test accuracy. This suggests that the sparse representation and the features extracted by SC are indeed useful for classification, especially in the overcomplete case.
5

Under review as a conference paper at ICLR 2019
Figure 3: MNIST classification with rate networks, according to Figure 1. The test error decreases for increasing hidden layer size nh for Principal Component Analysis (PCA), Sparse Coding (SC), fixed Random Projections (RP) and the fully supervised reference algorithms Backpropagation (BP) and Feedback Alignment (FA). The dashed dotted line at 90 % is chance level, the dotted line around 14 % is the performance of a Simple Perceptron without hidden layer. The vertical line marks the input dimension d = 784, i.e. the transition from under- to overcomplete hidden representations. Note the log-log scale.
The performance of RP (blue curve) for small numbers of hidden units (nh < d) is worse than for feature extractors like PCA and SC. Also for large hidden layers, performance improves only slowly with nh, which is in line with theory (Barron, 1993) and findings in the extreme learning field (Huang et al., 2006). However, for large hidden layers sizes, RP outperforms SC. This suggests that the high dimensionality of the hidden layers is more important for reaching high performance than the features extracted by PCA or SC. Tests on the object recognition task CIFAR10 lead to the same conclusion, indicating that this observation is not entirely task specific (see subsection 3.3 for further analysis on CIFAR10). For all tested methods and hidden layer sizes, performance is significantly worse than the one reached with BP (black curve in Figure 3). In line with (Lillicrap et al., 2016), we find that FA (cyan curve) performs as well as BP on MNIST. Universal function approximation theory predicts lower bounds for the squared error that follow a power law with hidden layer size nh for both BP (O(1/nh)) and RP (O(1/nh2/d), where d is the input dimension Barron et al. (1994); Barron (1993)). In the log-log-plot in Figure 3 this would correspond to a factor d/2 = 784/2 = 392 between the slopes of the curves of BP and RP, or at least a factor deff/2  10 using an effective dimensionality of MNIST (see methods A.1). We find a much faster decay of classification error in RP and a smaller difference between RP and BP slopes than suggested by the theoretical lower bounds.
3.3 LOCALIZED RANDOM RECEPTIVE FIELDS
There are good reasons to reduce the connectivity from all-to-all to localized receptive fields (Figure 1C): local connectivity patterns are observed in real neural circuits (Hubel & Wiesel, 1962), proven useful theoretically (Litwin-Kumar et al., 2017) and empirically (Bartunov et al., 2018), and successfully used in convolutional networks (CNNs). Even though this modification seems well justified from both biological and algorithmic sides, it reduces the generality of the algorithm to input data such as images where neighborhood relations between pixels (i.e. input dimensions) are important. For random projections with localized receptive fields (l-RP), the centers of the patches were chosen at random positions in the input space and their weights where randomly fixed (as in subsection 3.1, see Figure 1C). We tested different patch sizes of p × p pixels and found an optimum around p  10 which is more pronounced for large hidden layer sizes nh (see Figure 4A). Note that p = 1 corresponds to resampling the data with random weights, and p = 28 recovers fully connected RP performance. The main finding here is the significant improvement in performance using l-RP: the optimum around p  10 almost reaches BP performance for nh = 5000 hidden neurons (blue arrow in
6

Under review as a conference paper at ICLR 2019
AB
Figure 4: Effect of localized connectivity on MNIST. A Test error for localized Random Projections (l-RP), dependent on receptive field size p for different hidden layer sizes nh. The optimum at p = 10 is more pronounced for large hidden layer sizes. Full connectivity is equivalent to p = 28. Note the log-lin scale. B Localized receptive fields decrease test errors of Sparse Coding (SC), Random Projections (RP) and Backpropagation (BP). The effect is most significant for l-RP, which outperforms l-SC and almost approaches (l-)BP performance for large nh and p = 10 (blue arrow). All other reference lines as in Figure 3. Note the log-log scale.
Figure 4B). As expected l-RP and the LIF rate model of l-RP in subsection 3.1 perform equally well. To achieve a fair comparison BP and SC were also tested with localized receptive fields (lBP, l-SC, see Figure 4B). Also these algorithms seem to benefit from localized connectivity (also with an optimum for patch size p = 10), however, not as much as RP. This makes l-RP a strong competitor of SC (and also FA, see Figure 3) as a bio-plausible algorithm in the regime of large, overcomplete hidden layers nh > d. Since classification performances of l-RP and l-BP are very close for layer sizes above nh = 5000, we investigated the misclassified MNIST digits for both algorithms. We find that 75% of the ( 125) misclassified digits of l-BP (nh = 5000) are contained in the misclassified ones of l-RP (nh = 5000). This means that in roughly 75% of the cases l-RP fails, also the reference algorithm lBP fails, suggesting that these digits are particularly hard to recognize for networks with one hidden layer. We trained networks with up to nh = 100000 hidden neurons to test if (l-)RP can finally reach (l-)BP performance, since the latter saturates for large nh (see Figure 4B). Indeed for simulations with nh = 100000 and p = 10, l-BP and l-RP performance was not significantly different any more, both being at 1.2% test error. To test whether l-RP only works for the relatively simple MNIST data set (centered digits, noninformative margin pixels, no clutter, uniform features and perspective etc.) or generalizes to more difficult tasks, we applied it to the CIFAR10 data set (Krizhevsky, 2013). We first reproduced a typical benchmark performance of a fully connected network with one hidden layer trained with standard BP ( 56% test accuracy, nh = 5000, see also Lin & Memisevic (2016)). Again, l-RP outperforms the unsupervised methods PCA and l-SC in the case of large, overcomplete hidden layers (see Table 2). Furthermore, as on MNIST, classification performance increases for increasing hidden layer size nh and localized receptive fields perform better than full connectivity for all methods. Also on CIFAR10, l-RP comes close to the performance of the reference algorithm l-BP, however, the difference between l-RP and l-BP is larger than on MNIST. Given that state-of-the-art performance on the CIFAR10 dataset with deep convolutional neural networks is close to 98% (e.g. Real et al. (2018)), the limitations of l-RP and the difference in difficulty between MNIST and CIFAR10 become apparent.
4 DISCUSSION
The rules that govern plasticity of synapses deep in the brain remain elusive. In contrast to bioplausible deep learning based on approximations of the backpropagation algorithm, we focused
7

Under review as a conference paper at ICLR 2019

MNIST CIFAR10

PCA l-SC l-RP l-BP
90.3 ± 0.02 97.3 ± 0.03 98.4 ± 0.1 98.8 ± 0.1 22.6 ± 0.003 35.3 ± 0.004 52.0 ± 0.004 58.3 ± 0.002

Table 2: Test accuracies (%) on MNIST and CIFAR10. PCA uses full connectivity and 700 (2500)
PCs for MNIST (CIFAR10). All other methods use nh = 5000 hidden neurons and receptive field size p = 10. Note that CIFAR10 has d = 32×32×3 = 3072 input channels (the third factor is due to the color channels), MNIST only d = 28×28 = 784. The models were trained for 107 iterations (
167 epochs).

here on training a readout layer with a supervised, local learning rule combined with a single hidden layer with either fixed random weights or trained with unsupervised, local learning rules.
To our surprise, randomly initialized fixed weights (RP) of large hidden layers lead to better classification performance than training them with unsupervised methods like PCA or sparse coding (SC). This implies that the inductive bias of PCA and sparse coding is not well suited for the task of digit classification and object recognition. It may be interesting to search for alternative unsupervised, local learning rules with a stronger inductive bias.
Replacing all-to-all connectivity with localized input filters is such an inductive bias that was already seen to be useful in other models (Bartunov et al., 2018) and proved to be particularly useful in conjunction with randomly initialized static weights. Already for a hidden layer size of 5000 neurons the performance of l-RP almost reaches the performance of backpropagation on MNIST. Furthermore, performance scaling with the number of hidden units nh was found to be orders of magnitudes better than the lower bound suggested by universal function approximation theory (Barron, 1993).
Since we wanted to keep our models as simple as possible, we used online (no mini-batches) stochastic gradient descent (SGD) with a constant learning rate in all our experiments. There are many known ways to further tweak the final performance, e.g. with adaptive learning rate schedules or data augmentation, but our goal here was to demonstrate that even the simple model with localized random projections and spike timing dependent plasticity with a constant learning rate achieves results that are comparable with more elaborate approaches that use e.g. convolutional layers with weight sharing (Panda & Roy, 2016), backpropagation approximations (Lee et al., 2016), multiple hidden layers (Lillicrap et al., 2016), dendritic neurons (Sacramento et al., 2017), recurrence (Diehl & Cook, 2015) or conversion from rate to spikes (Diehl et al., 2015).
Above 98% accuracy we have to take into account a saturating effect of the network training: better models will only lead to subtle improvements in accuracy. It is not obvious whether improvements are really a proof of having achieved deep learning or just the result of tweaking the models towards the peculiarities of the MNIST dataset (centered digits, non-informative margin pixels, no clutter, uniform features and perspective etc.). We observed that more challenging data sets such as CIFAR10 clearly highlight the limitations of l-RP and thus are better suited to test deep learning capabilities. We are aware that state-of-the-art deep learning has moved from MNIST to harder datasets, such as ImageNet (Deng et al., 2009), long ago. Yet MNIST seems to be the current reference task for most bio-plausible deep learning models (see section 2 and Table 8).
In this paper we presented a new MNIST benchmark for bio-plausible spiking networks. Using localized random projections (l-RP) and STDP learning, our spiking LIF model reached 98.1% test accuracy on MNIST which lies within the range of current benchmarks for bio-plausible models for deep learning (see section 2 and Table 8). Our network model is particularly simple, i.e. it has only one trainable layer and does not depend on sophisticated architectural or algorithmic features (e.g. to approximate backpropagation). Instead it relies on the properties of high-dimensional localized random projections. We suggest that novel, progressive approaches to bio-plausible deep learning should significantly outperform the benchmark presented here.
REFERENCES
Pierre Baldi, Peter Sadowski, and Zhiqin Lu. Learning in the Machine: Random Backpropagation and the Learning Channel. arXiv Prepr., pp. 1­57, 2016. URL http://arxiv.org/abs/ 1612.02734.
8

Under review as a conference paper at ICLR 2019
Andrew R Barron. Universal Approximation Bounds for Superposition of a Sigmoid Function. IEEE Trans. Inf. Theory, 39(3):930­945, 1993. ISSN 09205691. doi: 10.1007/s11263-010-0390-2.
Andrew R Barron, Barron Brandy, and Stat Yale. Approximation and Estimation Bounds for Artificial Neural Networks. Mach. Learn., 14:115­133, 1994.
Sergey Bartunov, Adam Santoro, Blake A Richards, Geoffrey E Hinton, and Timothy P Lillicrap. Assessing the Scalability of Biologically-Motivated Deep Learning Algorithms and Architectures. arXiv Prepr., 2018. URL https://arxiv.org/abs/1807.04587.
Guillaume Bellec, Darjan Salaj, Anand Subramoney, Robert Legenstein, and Wolfgang Maass. Long short-term memory and learning-to-learn in networks of spiking neurons. arXiv Prepr., pp. 1­17, 2018. URL http://arxiv.org/abs/1803.09574.
Carlos S N Brito and Wulfram Gerstner. Nonlinear Hebbian Learning as a Unifying Principle in Receptive Field Formation. PLoS Comput. Biol., 12(9):1­24, 2016. ISSN 15537358. doi: 10. 1371/journal.pcbi.1005070.
F Crick. The recent excitement about neural networks. Nature, 337(6203):129­32, 1989. ISSN 0028-0836. doi: 10.1038/337129a0. URL https://www.nature.com/articles/ 337129a0.pdf.
H Dale. Pharmacology and Nerve-endings (Walter Ernest Dixon Memorial Lecture): (Section of Therapeutics and Pharmacology). Proc. R. Soc. Med., 28(3):319­332, 1935. ISSN 0035-9157.
Charles B. Delahunt and J. Nathan Kutz. Putting a bug in ML: The moth olfactory network learns to read MNIST. arXiv Prepr., (i):1­16, 2018. URL http://arxiv.org/abs/1802.05405.
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Fei-Fei Li. ImageNet: A large-scale hierarchical image database. IEEE Conf. Comput. Vis. pattern Recognit., pp. 248­255, 2009. ISSN 1063-6919. doi: 10.1109/CVPRW.2009.5206848. URL http://www.image-net. org.
Peter U. Diehl and Matthew Cook. Unsupervised learning of digit recognition using spiketiming-dependent plasticity. Front. Comput. Neurosci., 9(August):1­9, 2015. ISSN 16625188. doi: 10.3389/fncom.2015.00099. URL http://journal.frontiersin.org/ Article/10.3389/fncom.2015.00099/abstract.
Peter U Diehl, Daniel Neil, Jonathan Binas, Matthew Cook, Shih-Chii Liu, and Michael Pfeiffer. Fast-Classifying, High-Accuracy Spiking Deep Networks Through Weight and Threshold Balancing. Int. Jt. Conf. Neural Networks, 2015.
Jordan Guergiuev, Timothy P Lillicrap, and Blake A Richards. Deep learning with segregated dendrites. arXiv Prepr., 1610(00161):1­29, 2016. URL https://arxiv.org/abs/1610. 00161.
Akiko Hayashi-Takagi, Sho Yagishita, Mayumi Nakamura, Fukutoshi Shirai, Yi I. Wu, Amanda L. Loshbaugh, Brian Kuhlman, Klaus M. Hahn, and Haruo Kasai. Labelling and optical erasure of synaptic memory traces in the motor cortex. Nature, 525(7569):333­338, 2015. ISSN 14764687. doi: 10.1038/nature15257.
D O Hebb. The Organization of Behavior, volume 911. 1949. ISBN 0805843000.
Guang Bin Huang, Qin Yu Zhu, and Chee Kheong Siew. Extreme learning machine: Theory and applications. Neurocomputing, 70(1-3):489­501, 2006. ISSN 09252312. doi: 10.1016/j.neucom. 2005.12.126.
D. H. Hubel and T. N. Wiesel. Receptive fields, binocular interaction and functional architecture in the cat's visual cortex. J. Physiol., 160(1):106­154, 1962. ISSN 00223751. doi: 10.1113/ jphysiol.1962.sp006837. URL http://doi.wiley.com/10.1113/jphysiol.1962. sp006837.
9

Under review as a conference paper at ICLR 2019
Shaista Hussain, Shih Chii Liu, and Arindam Basu. Improved margin multi-class classification using dendritic neurons with morphological learning. Proc. - IEEE Int. Symp. Circuits Syst., pp. 2640­2643, 2014. ISSN 02714310. doi: 10.1109/ISCAS.2014.6865715.
Saeed Reza Kheradpisheh, Mohammad Ganjtabesh, Simon J. Thorpe, and Timothe´e Masquelier. STDP-based spiking deep convolutional neural networks for object recognition. Neural Networks, 99:56­67, 2018. ISSN 08936080. doi: 10.1016/j.neunet.2017.12.005. URL http://linkinghub.elsevier.com/retrieve/pii/S0893608017302903.
Adam A. Kohan, Edward A. Rietman, and Hava T. Siegelmann. Error Forward-Propagation: Reusing Feedforward Connections to Propagate Errors in Deep Learning. arXiv Prepr., 2018. URL http://arxiv.org/abs/1808.03357.
Nikolaus Kriegeskorte. Deep Neural Networks: A New Framework for Modeling Biological Vision and Brain Information Processing. Annu. Rev. Vis. Sci., 1(1):417­446, 2015. ISSN 2374-4642. doi: 10.1146/annurev-vision-082114-035447. URL http://www.annualreviews.org/ doi/10.1146/annurev-vision-082114-035447.
Alex Krizhevsky. https://www.cs.toronto.edu/~kriz/cifar.html, 2013. URL https://www.cs. toronto.edu/{~}kriz/cifar.html.
Shruti R Kulkarni and Bipin Rajendran. Spiking neural networks for handwritten digit recognitionSupervised learning and network optimization. Neural Networks, 103:118­127, 2018. ISSN 18792782. doi: S0893608018301126.
Yann LeCun. http://yann.lecun.com/exdb/mnist/, 1998. URL http://yann.lecun.com/ exdb/mnist/.
Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. Nat. Rev., 521:436 ­ 444, 2015. ISSN 0028-0836. doi: 10.1038/nature14539.
Chankyu Lee, Gopalakrishnan Srinivasan, Priyadarshini Panda, and Kaushik Roy. Deep Spiking Convolutional Neural Network Trained with Unsupervised Spike Timing Dependent Plasticity. IEEE Trans. Cogn. Dev. Syst., 8920(c):1­1, 2018. ISSN 2379-8920. doi: 10.1109/TCDS.2018. 2833071. URL https://ieeexplore.ieee.org/document/8354825/.
Dong Hyun Lee, Saizheng Zhang, Asja Fischer, and Yoshua Bengio. Difference target propagation. Lect. Notes Comput. Sci. (including Subser. Lect. Notes Artif. Intell. Lect. Notes Bioinformatics), 9284(3):498­515, 2015. ISSN 16113349. doi: 10.1007/978-3-319-23528-8 31.
Jun Haeng Lee, Tobi Delbruck, and Michael Pfeiffer. Training deep spiking neural networks using backpropagation. Front. Neurosci., 10(NOV), 2016. ISSN 1662453X. doi: 10.3389/fnins.2016. 00508.
Timothy P. Lillicrap, Daniel Cownden, Douglas B. Tweed, and Colin J. Akerman. Random synaptic feedback weights support error backpropagation for deep learning. Nat. Commun., 7:13276, 2016. ISSN 2041-1723. doi: 10.1038/ncomms13276. URL http://www.nature.com/ doifinder/10.1038/ncomms13276.
Zhouhan Lin and Roland Memisevic. How Far Can We Go Without Convolution : Improving Fully - Connected Networks. In Work. track - ICLR 2016, pp. 1­10, 2016.
Ashok Litwin-Kumar, Kameron Decker Harris, Richard Axel, Haim Sompolinsky, and L. F. Abbott. Optimal Degrees of Synaptic Connectivity. Neuron, 93(5):1153­1164.e7, 2017. ISSN 10974199. doi: 10.1016/j.neuron.2017.01.030. URL http://dx.doi.org/10.1016/j. neuron.2017.01.030.
D. Liu and S. Yue. Event-Driven Continuous STDP Learning With Deep Structure for Visual Pattern Recognition. IEEE Trans. Cybern., pp. 1­14, 2018. ISSN 21682267. doi: 10.1109/TCYB.2018. 2801476.
Jiqian Liu and Yunde Jia. A Lateral Inhibitory Spiking Neural Network for Sparse Representation in Visual Cortex. Adv. Brain Inspired Cogn. Syst., 7366:259­267, 2012. doi: 10.1007/ 978-3-642-31561-9.
10

Under review as a conference paper at ICLR 2019
Qian Liu, Garibaldi Pineda-Garcia, Evangelos Stromatias, Teresa Serrano-Gotarredona, and Steve B. Furber. Benchmarking spike-based visual recognition: A dataset and evaluation. Front. Neurosci., 10(NOV), 2016. ISSN 1662453X. doi: 10.3389/fnins.2016.00496.
Adam Henry Marblestone, Greg Wayne, and Konrad P Kording. Towards an integration of deep learning and neuroscience. Front. Comput. Neurosci., 10(September):1­61, 2016. ISSN 16625188. doi: 10.1101/058545. URL http://biorxiv.org/lookup/doi/10.1101/ 058545.
Richard Naud, Nicolas Marcille, and Claudia Clopath. Firing patterns in the adaptive exponential integrate-and-fire model. Biol. Cybern., pp. 335­347, 2008. doi: 10.1007/s00422-008-0264-7.
Robert A. Nawrocki, Richard M. Voyles, and Sean E. Shaheen. A Mini Review of Neuromorphic Architectures and Implementations. IEEE Trans. Electron Devices, 63(10):3819­3829, 2016. ISSN 00189383. doi: 10.1109/TED.2016.2598413.
Emre Neftci, Srinjoy Das, Bruno Pedroni, Kenneth Kreutz-Delgado, and Gert Cauwenberghs. Event-driven contrastive divergence for spiking neuromorphic systems. Front. Neurosci., 7(8 JAN):1­14, 2014. ISSN 1662453X. doi: 10.3389/fnins.2014.00272.
Emre O. Neftci, Charles Augustine, Somnath Paul, and Georgios Detorakis. Event-driven random back-propagation: Enabling neuromorphic deep learning machines. Front. Neurosci., 11(JUN): 1­18, 2017. ISSN 1662453X. doi: 10.3389/fnins.2017.00324.
Arild Nøkland. Direct Feedback Alignment Provides Learning in Deep Neural Networks. NIPS, 2016.
Peter O'Connor, Daniel Neil, Shih Chii Liu, Tobi Delbruck, and Michael Pfeiffer. Real-time classification and sensor fusion with a spiking deep belief network. Front. Neurosci., 7(7 OCT):1­13, 2013. ISSN 16624548. doi: 10.3389/fnins.2013.00178.
Peter O'Connor, Efstratios Gavves, and Max Welling. Temporally Efficient Deep Learning with Spikes. arXiv Prepr., (NIPS), 2017. URL http://arxiv.org/abs/1706.04159.
Erkki Oja. A simplified neuron model as a principal component analyzer. J. Math. Biol., 1:267­273, 1982.
Bruno A. Olshausen and David J. Field. Sparse coding with an overcomplete basis set: A strategy employed by V1? Vision Res., 37(23):3311­3325, 1997. ISSN 00426989. doi: 10.1016/S0042-6989(97)00169-7.
Priyadarshini Panda and Kaushik Roy. Unsupervised Regenerative Learning of Hierarchical Features in Spiking Deep Networks for Object Recognition. arXiv Prepr., 2016. URL https: //arxiv.org/abs/1602.01510.
Cengiz Pehlevan and Dmitri B. Chklovskii. A Hebbian/Anti-Hebbian network derived from online non-negative matrix factorization can cluster and discover sparse features. Conf. Rec. - Asilomar Conf. Signals, Syst. Comput., 2015-April:769­775, 2015. ISSN 10586393. doi: 10.1109/ACSSC. 2014.7094553.
Damien Querlioz, Olivier Bichler, Philippe Dollfus, and Christian Gamrat. Immunity to device variations in a spiking neural network with memristive nanodevices. IEEE Trans. Nanotechnol., 12(3):288­295, 2013. ISSN 1536125X. doi: 10.1109/TNANO.2013.2250995.
Esteban Real, Alok Aggarwal, Yanping Huang, and Quoc V. Le. Regularized evolution for image classifier architecture search. CoRR, abs/1802.01548, 2018. URL http://arxiv.org/abs/ 1802.01548.
Jaldert O. Rombouts, Sander M. Bohte, and Pieter R. Roelfsema. How Attention Can Create Synaptic Tags for the Learning of Working Memories in Sequential Tasks. PLoS Comput. Biol., 11(3): 1­34, 2015. ISSN 15537358. doi: 10.1371/journal.pcbi.1004060.
11

Under review as a conference paper at ICLR 2019
Christopher J Rozell, Don H Johnson, Richard G Baraniuk, and Bruno A Olshausen. Sparse coding via thresholding and local competition in neural circuits. Neural Comput., 20(10):2526­63, 2008. ISSN 08997667. doi: 10.1162/neco.2008.03-07-486.
David E. Rumelhart, Geoffrey E. Hinton, and Ronald J. Williams. Learning representations by backpropagating errors. Nature, 323(6088):533­536, 1986. ISSN 0028-0836. doi: 10.1038/323533a0. URL http://www.nature.com/doifinder/10.1038/323533a0.
Joa~o Sacramento, Rui Ponte Costa, Yoshua Bengio, and Walter Senn. Dendritic error backpropagation in deep cortical microcircuits. arXiv Prepr., pp. 1­37, 2017. URL http://arxiv.org/ abs/1801.00062.
Arash Samadi, Timothy P. Lillicrap, and Douglas B. Tweed. Deep Learning with Dynamic Spiking Neurons and Fixed Feedback Weights. Neural Comput., 29:578­602, 2017. ISSN 1530888X. doi: 10.1162/NECO.
T D Sanger. Optimal unsupervised learning in a single-layered linear feedforward network. Neural Networks, 2:459­473, 1989.
Benjamin Scellier and Yoshua Bengio. Equilibrium Propagation: Bridging the Gap Between Energy-Based Models and Backpropagation. Front. Comput. Neurosci., 11(May):1­13, 2017. ISSN 1662-5188. doi: 10.3389/fncom.2017.00024.
Courtney J. Spoerer, Patrick McClure, and Nikolaus Kriegeskorte. Recurrent convolutional neural networks: A better model of biological object recognition. Front. Psychol., 8(SEP):1­14, 2017. ISSN 16641078. doi: 10.3389/fpsyg.2017.01551.
Amirhossein Tavanaei and Anthony S. Maida. Bio-Inspired Spiking Convolutional Neural Network using Layer-wise Sparse Coding and STDP Learning. arXiv Prepr., (1611.03000v2):1­20, 2016. URL http://arxiv.org/abs/1611.03000.
Johannes Christian Thiele, Olivier Bichler, and Antoine Dupret. Event-based, timescale invariant unsupervised online deep learning with STDP. Front. Comput. Neurosci., 12(June):46, 2018. ISSN 1662-5188. doi: 10.3389/FNCOM.2018.00046. URL https://www.frontiersin. org/articles/10.3389/fncom.2018.00046/abstract.
Robert Urbanczik and Walter Senn. Learning by the dendritic prediction of somatic spiking. Neuron, 81(3):521­528, 2014. URL http://dx.doi.org/10.1016/j.neuron.2013.11. 030.
James C.R. Whittington and Rafal Bogacz. An Approximation of the Error Backpropagation Algorithm in a Predictive Coding Network with Local Hebbian Synaptic Plasticity. Neural Comput., 29:1229­1262, 2017. ISSN 1530888X. doi: 10.1162/NECO.
Yujie Wu, Lei Deng, Guoqi Li, Jun Zhu, and Luping Shi. Direct Training for Spiking Neural Networks: Faster, Larger, Better. arXiv Prepr., 2018. URL http://arxiv.org/abs/1809. 05793.
Daniel L.K. Yamins and James J. DiCarlo. Using goal-driven deep learning models to understand sensory cortex. Nat. Neurosci., 19(3):356­365, 2016. ISSN 15461726. doi: 10.1038/nn.4244.
Bo Zhao, Ruoxi Ding, Shoushun Chen, Bernabe Linares-Barranco, and Huajin Tang. Feedforward Categorization on AER Motion Events Using Cortex-Like Features in a Spiking Neural Network. IEEE Trans. Neural Networks Learn. Syst., 26(9):1963­1978, 2015. ISSN 21622388. doi: 10. 1109/TNNLS.2014.2362542.
Joel Zylberberg, Jason Timothy Murphy, and Michael Robert DeWeese. A sparse coding model with synaptically local plasticity and spiking neurons can account for the diverse shapes of V1 simple cell receptive fields. PLoS Comput. Biol., 7(10), 2011. ISSN 1553734X. doi: 10.1371/ journal.pcbi.1002250.
12

Under review as a conference paper at ICLR 2019

A METHODS
A.1 RATE NETWORK MODEL
We use a 3-layer (input l0, hidden l1 = lh and output l2) feed-forward rate-based architecture with layer sizes (n0 for input), n1 (hidden) and n2 (output, with n2 = # classes). The layers are connected via weight matrices W1  Rn1×n0 and W2  Rn2×n1 and each neuron receives bias from the bias vectors b1  Rn1 and b2  Rn2 respectively (see Figure 1). The neurons themselves are nonlinear units with an element-wise, possibly layer-specific, nonlinearity ai = l(ui). The feed-forward pass of this model thus reads

ul+1 = Wl+1ul + bl+1 al+1 = l+1(ul+1).

(4)

The simple perceptron (SP) only consists of one layer (l2, W2  Rn2×n0 , b2  Rn2 ). The sparse coding (SC) model assumes recurrent inhibition within the hidden layer l1. This inhibition is not modeled by an explicit inhibitory population, as required by Dale's principle (Dale, 1935), but direct, plastic, inhibitory synapses V1  Rn1×n1 are assumed between neurons in l1. Classification error variances in Figure 3 & Figure 4 are displayed as shaded, semi-transparent areas with the
same colors as the corresponding curves. Their lower and upper bounds correspond to the 25% and
75% percentiles of at least 10 independent runs.

An effective dimensionality deff of the MNIST data set can be obtained, e.g. via eigen-spectrum analysis, keeping 90% of the variance. We obtain values around deff  20. The measure proposed in Litwin-Kumar et al. (2017) gives the same value deff  20. Another measure is the crossing of the PCA curve with the Simple Perceptron line in Figure 3 at nh = 25(= deff). We checked that training a perceptron (1 hidden layer, nh = 1000, 107 iterations, ReLU, standard BP) on the first 25 PCs of MNIST leads to 1.7% test error (vs 1.5% test error on the full MNIST data). Together,
these findings suggest that the MNIST dataset lies mostly in a low-dimensional linear subspace with deff  25 d. The MNIST (& CIFAR10) data was rescaled to values in [0,1] and mean centered, which means that the pixel-wise average over the data was subtracted from the pixel values of every
image. The code for the implementation of our rate network model will be available online upon
acceptance.

A.2 UNSUPERVISED TECHNIQUES
A.2.1 PRINCIPAL COMPONENT ANALYSIS (PCA)
In this paper we do not implement PCA learning explicitly as a neural learning algorithm but by a standard PCA algorithm (https://github.com/JuliaStats/MultivariateStats. jl). For d-dimensional data such algorithms output the values of the n  d first principal components as well as the principal subspace projection matrix P  Rn×d. This matrix can directly be used as feedforward matrix W1 in our network since the lines of P correspond to the projections of the data onto the single principal components. In other words each neuron in the hidden layer l1 extracts another principal component of the data.

Since PCA is a linear model, biases b1 were set to 0 and the nonlinearity was chosen linear, i.e. 1(u) = u. With this, we can write the (trained) feed-forward pass of the first layer of our PCA model as follows:

a1 = u1 = W1 · a0 with W1 = P

(5)

Since the maximum number of PCs that can be extracted is the dimensionality of the data,
nmax = d, the number of neurons in the hidden layer n1 is limited by d. This makes PCA unusable for overcomplete hidden representations as investigated for SC and RP.

13

Under review as a conference paper at ICLR 2019

Consistency between the used standard algorithm and neural implementations of PCA ("Sanger's" rule Sanger (1989)) was checked by comparing the extracted PCs and visualizing the learned projections (lines of P) for the case of 30 extracted PCs, i.e. n = 30.
A.2.2 SPARSE CODING (SC)
For d-dimensional data, SC aims at finding a dictionary W  Rh×d of features that lead to an optimal representation a1  Rh which is sparse, i.e. has as few non-zero elements as possible. The corresponding optimization problem reads:

Wopt, a1opt = argmin L(W, a1)

L(W, a1)

=

1 2

a0 - W

a1

2 2

+



a1

1.

(6)

Since this is a nonlinear optimization problem with latent variables (hidden layer) it cannot be solved directly. Usually an iterative two step procedure is applied (akin to the expectation-maximization algorithm) until convergence: First optimize with respect to the activities a with fixed weights W. Second, assuming fixed activities, perform a gradient step w.r.t to weights.

We implement a biologically plausible SC model using a 2-layer network with recurrent inhibition and local plasticity rules similar to the one in Brito & Gerstner (2016). For a rigorous motivation (and derivation) that such a network architecture can indeed implement sparse coding we refer to Olshausen & Field (1997); Zylberberg et al. (2011); Pehlevan & Chklovskii (2015); Brito & Gerstner (2016). We apply the above mentioned two step optimization procedure to solve the SC problem given our network model. The following two steps are repeated in alternation until convergence of the weights:

1. Optimizing the hidden activations:
We assume given and fixed weights W1 and V1 and ask for optimal hidden activations a1. Because of the recurrent inhibition V1 the resulting equation for the hidden activities a1 is nonlinear and implicit. To solve this equation iteratively, we simulate the dynamics of a neural model with time-dependent internal and external variables u1(t) and a1(t) respectively. The dynamics of the system is then given by Zylberberg et al. (2011); Brito &
Gerstner (2016):

u

du1(t) dt

=

-u1(t) + (W1a0(t) - V1a1(t))

a1(t) = (u1(t))

(7)

In practice the dynamics is simulated for Niter = 50 iterations, which leads to satisfying convergence (change in hidden activations < 5%).
2. Optimizing the weights: Now the activities a1 are kept fixed and we want to update the weights following the gradient of the loss function. The weight update rules are Hebbian-type local learning rules (Brito & Gerstner, 2016):

W1,ji = w · a0,i · a1,j V1,jk = v · a1,k · (a1,j - a1,j )

(8)

· is a moving average (low-pass filter) with some time constant mav. At the beginning of the simulation (or after a new pattern presentation) mav is increased starting from 0 to mav during the first mav. The values of the lines of W1 are normalized after each update, however this can also be achieved by adding a weight decay term. Additionally the values
of V1 are clamped to positive values after each update to ensure that the recurrent input is inhibitory. Also the diagonal of V1 is kept at zero to avoid self-inhibition.

During SC learning, at every iteration, the variabes u1(t) and a1(t) are reset (to avoid transients) before an input is presented. Then for every of the N iterations, equation 7 is iterated for Niter steps

14

Under review as a conference paper at ICLR 2019

and the weights are updated according to equation 8.

For comparison with localized RP (l-RP, see subsubsection A.2.3), a localized version of SC was implemented with the same initialization of W1 as in l-RP. The usual SC learning rule equation 8 is applied and the localized connectivity is kept by clamping weights outside the receptive fields to zero. Lateral inhibition weights V1 are initialized and learned as in normal SC (full competition is kept). For a detailed parameter list, see Table 3.

A.2.3 RANDOM PROJECTIONS (RP)

For RP, the weight matrix W1 between input and hidden layer is initialized randomly W1  N (0, 2) with variance-preserving scaling: 2  1/n0. The biases b1 are initialized by sampling from a uniform distribution U([0, 0.1]) between 0 and 0.1. In practice we used the specific
initialization

W1



N (0, 2) 2 = 1 100 n0

b1  U ([0, 0.1])

(9)

for RP (keeping weights fixed), SC, SP and also BP & RF (both layers with W2, b2 and n1 respectively). The initialization of the biases b was found to be uncritical in the range of [0,0.1]

For localized RP (l-RP), neurons in the hidden layer receive input only from a fraction of the input units called a receptive field. Receptive fields are chosen to form a compact patch over neighbouring pixels in the image space. For each hidden neuron a receptive field of size p × p (p  N) input neurons is created at a random position in the input space. The weight values for each receptive field (rf) and the biases are initialized as:

W1,rf



N (0, r2f)

r2f

=

c 100

p

(10)

b1  U ([0, 0.1])

(11)

were the optimization factor c = 3 was found empirically through a grid-search optimization of classification performance. For exact parameter values, see Table 4.

A.3 CLASSIFIER & SUPERVISED REFERENCE ALGORITHMS

The connections W2 from hidden to output layer are updated by a simple delta-rule which is equivalent to BP in a single-layer network and hence is bio-plausible. For having a reference for our bio-plausible models (Figure 1B), we compare it to networks with the same architecture (number of layers, neurons, connectivity) but trained in a fully supervised way with standard backpropagation (Figure 1A). The forward pass of the model reads:

ul+1 = Wl+1ul + bl+1 al+1 = l+1(ul+1)

(12) (13)

The error ~eL is calculated from the comparison of activations in the last layer aL with the (one-hot encoded) target activations tgt, with respect to the chosen loss function: mean squared error (MSE),

~eL = tgt - aL

LMSE

=

1 2

tgt - aL

2 2

or softmax/cross-entropy loss (CE),

(14) (15)

p = softmax (aL)
~eL = tgt - p
nL
LCE = - tgti · log (pi)
i=1

(16) (17)
(18)

15

Under review as a conference paper at ICLR 2019

Classification results (on the test set) for MSE- and CE-loss were found to be not significantly different. Rectified linear units (ReLU) were used as nonlinearity (ul) for all layers (MSE-loss) or for the first layer only (CE-loss).

In

BP

the

weight

and

bias

update

is

obtained

by

stochastic

gradient

descent,

i.e.

Wl,ij



.L
 Wl,ij

The full BP algorithm for deep networks reads (Rumelhart et al., 1986):

eL = L(uL) ~eL
el-1 = l-1(ul) Wl el Wl =  · el  al-1 bl =  · el

(19)

where stands for element-wise multiplication,  is the outer (dyadic) product, l(·) is the derivative of the nonlinearity and  is the learning rate. FA (Lillicrap et al., 2016) uses a fixed random
matrix Rl instead of the transpose of the weight matrix Wl for the error backpropagation step in equation 19.

To allow for a fair comparison with l-RP, BP and FA were implemented with full connectivity and with localized receptive fields with the same initialization as in l-RP. During training with BP (or FA), the usual weight update equation 19 was applied to the weights in the receptive fields, keeping all other weights at zero. The exact parameter values can be found in Table 5.

A.4 SPIKING IMPLEMENTATION

A.4.1 LIF MODEL

The spiking simulations were performed with a custom-made event-based leaky integrate-and-fire (LIF) integrator written in the Julia-language. For large network sizes, the exact, event-based integration can be inefficient due to a large frequency of events. To alleviate dramatic slow-down, an Euler-forward integration was added to the framework. For sufficiently small time discretization (e.g. t  5 · 10-2 ms for the parameters given in Table 6) the error of this approximate integration does not have negative consequences on the learning outcome. Consistent results were obtained using event-based and Euler-forward integration. The code of this framework will be available online upon acceptance.

The dynamics of the LIF network is given by:

m

dui(t) dt

=

-ui(t) + RIi(t)

with Ii(t) = Iiff (t) + Iiext(t) = wij

j,f

and the spiking condition:

if ui(t)  i: ui  ureset

t - tfj + Iiext(t)

(20)

where ui(t) is the membrane potential, m the membrane time-constant, R the membrane resistance, wij are the synaptic weights, (t) = (t)/m (with m in seconds) is the post-synaptic potential evoked by a pre-synaptic spike arrival, i is the spiking threshold and ureset the reset potential after a spike. The input is split into a feed-forward (Iff (t)) and an external (Iext(t)) contribution. Each neuron in the input layer l0 (n0 = d) receives only external input Iext proportional to one pixel value in the data. To avoid synchrony between the spikes of different neurons, the starting potentials
and parameters (e.g. thresholds) for the different neurons are drawn from a (small) range around
the respective mean values.

We implement STDP using post-synaptic spike-traces tri(t) and a post-synaptic target-trace tgti(t).

tr

dtri(t) dt

=

-tri(t) +

 t - tif

f

wij = g tripost(t), tgtpiost(t)  t - tjf

(21)

16

Under review as a conference paper at ICLR 2019

with the plasticity function

g trpiost(t), tgti(t) =  · tgtpiost(t) - trpiost(t) .

(22)

To train the network, we present patterns to the input layer and a target-trace to the output layer. The
MNIST input is scaled by the input amplitude ampinp, the targets tgt(t) of the output layer are the one-hot-coded classes, scaled by the target amplitude amptgt. Additionally, every neuron receives a static bias input Ibeixats   to avoid silent units in the hidden layer. Every pattern is presented as fixed input for a time Tpat and the LIF dynamics as well as the learning evolves according to equation 20 and equation 21 respectively. To ensure stability during transients (see Naud et al.
(2008) and references therein), learning is disabled after pattern switches for a duration of about
Ttrans = 4m. With the parameters we used for the simulations (see Table 6), firing rates of single neurons in the whole network stayed below 1 kHz which was considered as a bio-plausible regime.
For the toy example in Figure 2A& B we used static input and target with the parameters ampinp = 40, amptgt = 5 (i.e. target trace = 0.005), mean = 20, = 0, m = 50,  = 1.2 · 10-5. For the raster plot in Figure 2C we used ampinp = 300, amptgt = 300, mean = 20, = 0, m = 50,  = 1.2 · 10-5 Tpat = 50 ms, Ttrans = 100 ms.

A.4.2 LIF RATE MODEL

The LIF dynamics can be mapped to a rate model described by the following equations:

ul = Wlul-1 + RIext
al = LIF (ul) wij = g~ apjre, apiost, tgtipost

(23)

with the (element-wise) LIF-activation function LIF(·) and the modified plasticity function g~(·):

LIF (uk) =

abs - m ln

1 - k uk

g~ ajpre, aipost, tgtpiost = ~ · ajpre · tgtipost - apiost

-1

(24) (25)

The latter can be obtained by integrating the STDP rule Equation 21 and taking the expectation.

Most of the parameters of the spiking- and the LIF rate models can be mapped to each other directly

(see Tabs. 6 & 7). The learningrate  must be adapted since the LIF weight change depends on the

presentation time of a pattern Tpat. In the limit of long pattern presentation times (Tpat m, tr),

the transition from the learning rate of the LIF rate model (~) to the one of the spiking LIF model

() is

 = 1000 ms · 1000 · ~, Tpat [ms]

(26)

where the second factor comes from a unit change from Hz to kHz. It is also possible to train weight matrices computationally efficient in the LIF rate model and plug them into the spiking LIF model afterwards (as in e.g. Diehl et al. (2015)). The reasons for the remaining difference in performance presumably lie in transients and single-spike effects that cannot be captured by the rate model. Also, the spiking network was only trained with 106 image presentations (compared to 107 for the rate model) due to long simulation times.

B PARAMETER TABLES
In the following tables we use scientific E-notation XeY = X · 10Y for better readability. For all simulations, we scaled the learning rate proportional to 1/nh for nh > 5000 to ensure convergence.

17

Under review as a conference paper at ICLR 2019

Parameter
nh = n1 p
w v c 
S
mav u Niter N
Nc Ninits Wilnit Vi1nit bi1nit 1(·) 2(·)

Description
Number of hidden units Rec. field sizes (edge length) in units
Learning rate for W1 Learning rate for V1 Learning rate of classifier Sparsity parameter Resulting sparsity (fraction of 0-elements in l1) Time constant of the moving average Time constant of inner variable u1(t) Number of iterations solving eq. equation 7 Number of iterations for SC Num. of iterations for classifier training Number of trials for classifier
Feed-forward weight initialization
Reccurent weight initialization
Bias initialization nonlinearity of hidden SC units
nonlinearity of classifier

Value
[10,25,50,100,250,500,1000,2500,5000] [1,5,10,15,20,25,28] 1e-3 1e-2 1e-2
[1e-4,1e-3,1e-2,1e-1,1e-0] 90 - 99% (dependent on nh)
1e-2 [1/iterations] 1e-1 [1/iterations]
50 1e5 1e7 ( 167 epochs) Wl,ij  N (0,51)/(10nl-1)
0
0 (and kept fixed) ReLU max(0, · - )
ReLU

Table 3: (Hyper-)Parameters for SC. Best performing parameters in bold.

Parameter
nh = n1 p
l N
Ninits Wilnit b1init

Description Number of hidden units Rec. field sizes (edge length) in units
Learning rate Number of iterations
Number of trials
Feed-forward weight initialization
Bias initialization

Value

[10,25,50,100,250,500,1000,2500,5000]

[1,5,10,15,20,25,28]

5e-3

1e7 ( 167 epochs)

Wl,ij



N

5 (0, 1)/(10 nl-1

)

bl,i  U ([0, 1]) /10

Table 4: (Hyper-)Parameters for RP. Best performing parameters in bold.

Parameter
nh = n1 p
l N
Ninits Wilnit b1init

Description Number of hidden units Rec. field sizes (edge length) in units Learning rate (per layer)
Number of iterations Number of trials
Feed-forward weight initialization
Bias initialization

Value [10,25,50,100,250,500,1000,2500,5000]
[1,5,10,15,20,25,28] [5e-3,5e-3] (BP,FA) or 1e-2 (SP)
1e7 ( 167 epochs) Wl,ij  N (0,51)/(10nl-1)
bl,i  U ([0, 1]) /10

Table 5: (Hyper-)Parameters for BP, FA and SH. Best performing parameters in bold.

18

Under review as a conference paper at ICLR 2019

Parameter
nh = n1 p
m R
abs i mean  ampinp amptgt Ibeixats tr ureset 
N Wilnit Tpat Ttrans t

Description Number of hidden units Rec. field sizes (edge length) in units Membrane time constant
Membrane resistance Absolute refractory period
Spiking thresholds Mean spiking threshold Variance of spiking thresholds
Input amplitude
Target amplitude
External bias input to all neurons Spike trace time constant Reset potential Learning rate Number of iterations
Feed-forward weight initialization Duration of pattern presentation Duration of the transient without learning Time step for Euler integrator

Value [10,25,50,100,250,500,1000,2500,5000]
[1,10,28] 25 ms 1 0 ms
i  N (mean, ) 20 mV 1 mV 500 mA
500 mA
mean/R 20 ms 0 mV 2e-4 (nh = 5000, 5e-4 for Euler forward) Wl,ij1e6N((01,71)ep· o2c0h/s) nl-1 50 ms (train, 200 ms during testing) 100 ms  5e-2 ms

Table 6: (Hyper-)Parameters for the spiking LIF l-RP model. Input and target amplitudes are implausibly high due to the arbitrary convention R = 1 . Best performing parameters in bold.

Parameter
nh = n1 p
m R
abs i mean  ampinp amptgt Ibeixats ureset ~
N Wilnit

Description Number of hidden units Rec. field sizes (edge length) in units Membrane time constant
Membrane resistance Absolute refractory period
Spiking thresholds Mean spiking threshold Variance of spiking thresholds
Input amplitude
Target amplitude
External bias input to all neurons Reset potential Learning rate
Number of iterations
Feed-forward weight initialization

Value

[10,25,50,100,250,500,1000,2500,5000]

[1,10,28]

25 ms

1

0 ms

i  N (mean, ) 20 mV

1 mV

500 mA

500 mA

mean/R 0 mV

1e-8 (for nh = 5000)

1e7 Wl,ij 

N((01,617)e·p2o0c/hs)nl-1

Table 7: (Hyper-)Parameters for the LIF rate l-RP model. Parameters are the same as in the spiking model; only ~ was converted from  according to Equation 26. 107 iterations were used for training the rate model (compared to 106 in the spiking model). Input and target amplitudes are implausibly
high due to the arbitrary convention R = 1 . Best performing parameters in bold.

19

Under review as a conference paper at ICLR 2019

C BIO-PLAUSIBLE MNIST BENCHMARKS

Model
Conv. SNN (Wu et al., 2018) Conv. SNN (Diehl et al., 2015)
Conv. Spiking AE (Panda & Roy, 2016) l-FA (Bartunov et al., 2018)
(& this paper) SNN
(Lee et al., 2016) (Stoch.) Diff. Target Prop.
(Lee et al., 2015) LIF rate l-RP
(this paper)
l-RP (this paper)
Conv. SNN (Kheradpisheh et al., 2018)
(O'Connor et al., 2017)
(Nøkland, 2016) Spiking FA
(Lillicrap et al., 2016) spiking LIF l-RP (this paper)
Forward propagation (FP) (Kohan et al., 2018)
Spiking FA (Neftci et al., 2017) Predictive coding
(Whittington & Bogacz, 2017) Spiking CNN
(Tavanaei & Maida, 2016) Equilibrium Prop.
(Scellier & Bengio, 2017) Dendr. BP
(Sacramento et al., 2017)
l-SC (this paper)
Spiking FA (Samadi et al., 2017)
Sparse/Skip FA (Baldi et al., 2016)
Spiking CNN (Thiele et al., 2018)
Spiking FA (Guergiuev et al., 2016)
2 layer network (Diehl & Cook, 2015) Spiking RBM/DBN (O'Connor et al., 2013)
2 layer network (Querlioz et al., 2013) Spiking HMAX/CNN
(Liu & Yue, 2018) Spiking RBM/DBN (Neftci et al., 2014) Spiking RBM/DBN (Neftci et al., 2014)
Spiking CNN (Zhao et al., 2015) Dendritic neurons (Hussain et al., 2014)
PCA + class. (this paper)
SP (this paper)

Neural coding Spikes Rate Spikes Rate Spikes Rate Rate Rate Spikes
Pseudo-spike Rate Spikes Spikes Rate Spikes Rate Rate/ Spikes Rate Spikes Rate Spikes Rate Spikes Spikes Spikes Rate Spikes Spikes Rate Spikes Spike Rate Rate Rate

Learning type Supervised Supervised
Un/Supervised Supervised Supervised Supervised Supervised Supervised
Unsupervised Supervised Supervised Supervised Supervised Supervised Supervised Supervised
Unsupervised Supervised Supervised
Un/Supervised Supervised Supervised
Unsupervised Supervised
Unsupervised Supervised
Unsupervised Supervised Supervised Supervised Supervised Supervised
Un/Supervised Supervised

Learning rule BP-variant BP
membr.-potential based BP FA
membr. pot. based BP
Targ. Prop.
rate STDP
Delta-rule
STDP
Pseudo-STDP direct FA FA
STDP
FP & direct FA FA
Local Hebbian
SC, STDP
EquiProp Bio-plausible
BP SC/delta-rule
FA
FA
STDP Bio-plausible
BP STDP Contrastive Divergence STDP event-driven cont. STDP Contrastive Divergence Contrastive Divergence Tempotron rule Morphology learning PCA-algorithm delta-rule Delta-rule

Comments
5 conv. layers, Spatio-Temporal BP Conversion: rate  spike
Stacked conv. AE, weight sharing BP + sym. weights used inside AE
FA with localized rec. fields BP approx.
weights symmetry
Layer-wise AE
Only output layer learned Only output layer learned 3 Conv. layers, external SVM Sparse, discrete
activities Many hidden layers
3 hidden layers
Only output layer learned
FP: BP approximation
Direct FA BP approximation by predictive coding
semi-online SVM
1 - 3 hidden layers
Dendr. computation for BP approx. SC for 1. layer delta-rule for 2.
3 hidden layers
Sparse- & Skip-FA Lim. prec. FA Recurren Inhib.
Purely unsuperv. Dendr. computation
for BP approx. Recurrent Inhib. Purely unsuperv.
Conversion rate  spike Memristive
device mod. HMAX model
for preprocess.
Neural sampling
Neural sampling
Dynamic Vision Sensor MNIST Nonlin. dendrites Neuromorphic appl.
PCs as features
Direct class. on MNIST data

Test accuracy (%) 99.3 99.1 99.1 98.7 98.7 98.5 98.5 98.4 98.4 98.3 98.3 98.2 98.1 98.1 98 98 98
97 - 98 97.5 97.4 97
96 - 97 96.6 96.3 95 94.1 93.5 93 92.6 91.9 91.3 90.3 90.3 85

Table 8: MNIST benchmarks for bio-plausible models of deep learning compared with models in this paper (bold). Models are ranked by accuracy (rightmost column). Accuracy refers to the classification accuracy on the MNIST test set. Parts of this table are taken from (Diehl & Cook, 2015) and (Kheradpisheh et al., 2018). Models involving convolutional/pooling layers are marked in blue. Note that the simple models in the l-RP class (l-RP, LIF rate & spiking l-RP), marked in red, perform better than several more elaborate models. For conventional ANN/DNN/CNN MNIST benchmarks see Table at http://yann.lecun.com/exdb/mnist/).

20

