Under review as a conference paper at ICLR 2019
AN ADVERSARIAL LEARNING FRAMEWORK FOR A PERSONA-BASED MULTI-TURN DIALOGUE MODEL
Anonymous authors Paper under double-blind review
ABSTRACT
In this paper, we extend the persona-based sequence-to-sequence (Seq2Seq) neural network conversation model to a multi-turn dialogue scenario by modifying the state-of-the-art hredGAN architecture to simultaneously capture utterance attributes such as speaker identity, dialogue topic, speaker sentiments and so on. The proposed system, phredGAN has a persona-based HRED generator (PHRED) and a conditional discriminator. We also explore two approaches to accomplish the conditional discriminator: (1) phredGANa, a system that passes the attribute representation as an additional input into a traditional adversarial discriminator, and (2) phredGANd, a dual discriminator system which in addition to the adversarial discriminator, collaboratively predicts the attribute(s) that generated the input utterance. To demonstrate the superior performance of phredGAN over the persona SeqSeq model, we experiment with two conversational datasets, the Ubuntu Dialogue Corpus (UDC) and TV series transcripts from the Big Bang Theory and Friends. Performance comparison is made with respect to a variety of quantitative measures, including BLEU, ROUGE, and perplexity scores. We also explore the trade-offs from using either variant of phredGAN on datasets with many but weak attribute modalities (such as with Big Bang Theory and Friends) and ones with few but strong attribute modalities (customer-agent interactions in Ubuntu dataset).
1 INTRODUCTION
Recent advances in machine learning especially with deep neural networks has lead to tremendous progress in natural language processing and dialogue modeling research (Sutskever et al., 2014; Vinyals & Le, 2015; Serban et al., 2016). Nevertheless, developing a good conversation model capable of fluent interaction between a human and a machine is still in its infancy stage. Most existing work relies on limited dialogue history to produce response with the assumption that the model parameters will capture all the modalities within a dataset. However, this is not true as dialogue corpora tend to be strongly multi-modal and practical neural network models find it difficult to disambiguate characteristics such as speaker personality, location and sub-topic in the data.
Most work in this domain has primarily focused on optimizing dialogue consistency. For example, Serban et al. (Serban et al., 2016; 2017b;a) and Xing et al. (2017) introduced a Hierarchical Recurrent Encoder-Decoder (HRED) network architecture that combines a series of recurrent neural networks to capture long-term context state within a dialogue. However, the HRED system suffers from lack of diversity and does not have any guarantee on the generator output since the output conditional probability is not calibrated. Olabiyi et al. (2018) tackles these problems by training a modified HRED generator alongside an adversarial discriminator in order to increase diversity and provide a strong and calibrated guarantee to the generator's output. While the hredGAN system improves upon response quality, it does not capture speaker and other attributes modality within a dataset and fails to generate persona specific responses in datasets with multiple modalities.
On the other hand, there has been some recent work on introducing persona into dialogue models. For example, Li et al. (2016b) integrates attribute embeddings into a single turn (Seq2Seq) generative dialogue model. In this work, Li et al. consider persona models one with Speaker-only representation and the other with Speaker and Addressee representations (Speaker-Addressee model), both of which capture certain speaker identity and interactions. Nguyen et al. (2018) continue along the
1

Under review as a conference paper at ICLR 2019
Figure 1: The PHRED generator with local attention - The attributes C, allows the generator to condition its response on the utterance attributes such as speaker identity, subtopics and so on.
same line of thought by considering a Seq2Seq dialogue model with Responder-only representation. In both of these cases, the attribute representation is learned during the system training. Zhang et al. (2018) proposed a slightly different approach. Here, the attributes are a set of sentences describing the profile of the speaker. In this case, the attributes representation is not learned. The system however learns how to attend to different parts of the attributes during training. Still, the above persona-based models have limited dialogue history (single turn); suffer from exposure bias worsening the trade-off between personalization and conversation quality and cannot generate multiple responses given a dialogue context. This is evident in the relatively short and generic responses produced by these systems, even though they generally capture the persona of the speaker. In order to overcome these limitations, we propose two variants of an adversarially trained persona conversational generative system, phredGAN , namely phredGANa and phredGANd. Both systems aim to maintain the response quality of hredGAN and still capture speaker and other attribute modalities within the conversation. In fact, both systems use the same generator architecture (PHRED generator), i.e., an hredGAN generator (Olabiyi et al., 2018) with additional utterance attribute representation at its encoder and decoder inputs as depicted in Figure 1. Conditioning on external attributes can be seen as another input modality as is the utterance into the underlying system. The attribute representation is an embedding that is learned together with the rest of model parameters similar to Li et al. (2016b). Injecting attributes into a multi-turn dialogue system allows the model to generate responses conditioned on particular attribute(s) across conversation turns. Since the attributes are discrete, it also allows for exploring different what-if scenarios of model responses. The difference between the two systems is in the discriminator architecture based on how the attribute is treated. We train and sample both variants of phredGAN similar to the procedure for hredGAN (Olabiyi et al., 2018). To demonstrate model capability, we train on a customer service related data such as the Ubuntu Dialogue Corpus (UDC) that is strongly bimodal between question poser and answerer, and transcripts from a multi-modal TV series The Big Bang Theory and Friends with quantitative and qualitative analysis. We examine the trade-offs between using either system in bi-modal or multi-modal datasets, and demonstrate system superiority over state-of-the-art persona conversational models in terms of dialogue response quality and quantitatively with perplexity, BLEU, ROUGE and distinct n-gram scores.
2 MODEL ARCHITECTURE
In this section, we briefly introduce the state-of-the-art hredGAN model and subsequently show how we derive the two persona versions by combining it with the distributed representation of the dialogue speaker and utterance attributes, or with an attribute discrimination layer at the end of the model pipeline.
2

Under review as a conference paper at ICLR 2019

Figure 2: The phredGANd dual discriminator - Left: Dadv is a word-level discriminator used by both phredGANa and phredGANd to judge normal dialogue coherency as in hredGAN . Right: Datt, an utterance-level attribute discriminator is used only in phredGANd to predict the likelihood a given utterance was generated from a particular attribute.

2.1 hredGAN : ADVERSARIAL LEARNING FRAMEWORK

Problem Formulation: The hredGAN (Olabiyi et al., 2018) formulates multi-turn dialogue re-
sponse generation as: given a dialogue history of sequence of utterances, Xi = X1, X2, · · · , Xi ,
where each utterance Xi = Xi1, Xi2, · · · , XiMi contains a variable-length sequence of Mi word tokens such that Xij  V for vocabulary V , the dialogue model produces an output Yi = Yi1, Yi2, · · · , YiTi , where Ti is the number of generated tokens. The framework uses conditional GAN structure to learn a mapping from an observed dialogue history to a sequence of output
tokens. The generator, G, is trained to produce sequences that cannot be distinguished from the
ground truth by an adversarially trained discriminator, D akin to a two-player min-max optimiza-
tion problem. The generator is also trained to minimize the cross-entropy loss LMLE(G) between the ground truth Xi+1, and the generator output Yi. The following objective summarizes both goals:

G, D = arg min max GLcGAN (G, D) + M LMLE(G) .
GD

(1)

where G and M are training hyperparamters and LcGAN (G, D) and LMLE(G) are defined in Eqs. (5) and (7) of Olabiyi et al. (2018) respectively. Please note that the generator G and discriminator
D share the same encoder and embedding representation of the word tokens.

2.2 phredGAN : PERSONA ADVERSARIAL LEARNING FRAMEWORK
The proposed architecture of phredGAN is very similar to that of hredGAN (Olabiyi et al., 2018). The only difference is that the dialogue history is now Xi = (X1, C1), (X2, C2), · · · , (Xi, Ci) where Ci is additional input that represents the speaker and/or utterance attributes. Please note that Ci can either be a sequence of tokens or single token such that Cij  V c for vocabulary V c. Also, at the ith turn, Ci and Ci+1 are the source/input attribute and target/output attribute to the generator respectively. The embedding for attribute tokens is also learned similar to that of word tokens.
Both versions of phredGAN shares the same generator architecture (PHRED) but different discriminators. Below is the highlight of how they are derived from the hredGAN architecture.
Encoder: The context RNN, cRN N takes the source attribute Ci as an additional input by concatenating its representation with the output of eRN N as in Figure 1. If the attribute Ci is a sequence of tokens, then an attention (using the output of eRN N ) over the source attribute representations is concatenated with the output of eRN N . This output is used by the generator to create a context state for a turn i.
Generator: The generator decoder RNN, dRN N takes the target attribute Ci+1 as an additional input as in Fig. 1. If the attribute Ci+1 is a sequence of tokens, then an attention (using the output of dRN N ) over the attribute representations is concatenated with the rest of the decoder inputs. This forces the generator to draw a connection between the generated responses and the utterance attributes such as speaker identity.
Noise Injection: As in Olabiyi et al. (2018), we also explore different noise injection methods.

3

Under review as a conference paper at ICLR 2019

Objective: For phredGAN , the optimization objective in eq. (1) can be updated as:

G, Dadv, Datt

=

arg

min
G

max
Dadv

Gadv

LcaGdvAN

(G,

Dadv

)

+

min
Datt

Gatt

LacGttAN

(G,

Datt)

+

M

LM

LE

(G)

.

(2)

where LcaGdvAN (G, Dadv) and LacGttAN (G, Datt) are the traditional adversarial and attribute prediction loss respectively and dependent on the architectural variation. It is worth to point out that while the

former is adversarial, the later is collaborative in nature. The MLE loss is common and can be

expressed as:

LMLE (G) = EXi+1 [-log PG Xi+1|Xi, Ci+1, Zi ].

(3)

where Zi the noise sample and depends on the choice of either utterance-level or word-level noise input into the generator (Olabiyi et al., 2018).

2.3 phredGANa: ATTRIBUTES AS A DISCRIMINATOR INPUT

phredGANa shares the same discriminator architecture as the hredGAN but with additional input, Ci+1. Since it does not use attribute prediction, Gatt = 0.

The adversarial loss, LacGdvAN (G, D) can then be expressed as:

LacGdvAN (G, Dadv) = EXi,Ci+1,Xi+1 [log Dadv(Xi, Ci+1, Xi+1)] + EXi,Ci+1,Zi [1 - log Dadv(Xi, Ci+1, G(Xi, Ci+1, Zi))]

(4)

The addition of speaker or utterance attributes allows the dialogue model to exhibit personality traits given consistent responses across style, gender, location, and so on.

2.4 phredGANd: ATTRIBUTES AS A DISCRIMINATOR TARGET

phredGANd does not take the attribute representation at its input but rather use the attributes as the target of an additional discriminator Datt. The adversarial and the attribute prediction losses can be respectively expressed as:

LacGdvAN (G, Dadv) = EXi,Xi+1 [log Dadv(Xi, Xi+1)] + EXi,Zi [1 - log Dadv(Xi, G(Xi, Ci+1, Zi))]

(5)

LacGttAN (G, Datt) = ECi+1 [log Datt(Ci+1|Xi, Xi+1)] + ECi+1 [log Datt(Ci+1|Xi, G(Xi, Ci+1, Zi))]

(6)

Attribute Discriminator: In addition to the existing word-level adversarial discriminator Dadv from hredGAN , we add an attribute discriminator, Datt, that discriminates on an utterance level to capture attribute modalities since attributes are assigned at utterance level. The discriminator uses
a unidirectional RNN (DattRNN ) that maps the input utterance to the particular attribute(s) that generated it. The attributes can be seen as hidden states that inform or shape the generator outputs.
The attribute discriminator can be expressed as:

Datt(Ci+1|Xi, ) = DattRNN (hi, E())

(7)

where E(.) is the word embedding lookup (Olabiyi et al., 2018),  = Xi+1 for groundtruth and  = Yi for the generator output.

3 MODEL TRAINING AND INFERENCE
3.1 MODEL TRAINING
We train both the generator and the discriminator (with shared encoder) of both variants of phredGAN using the training procedure in Algorithm 1 (Olabiyi et al., 2018). For both variants, Gadv = M = 1, and for phredGANa and phredGANd, Gatt = 0 and Gatt = 1 respectively. Since the encoder, word embedding and attribute embedding are shared, we are able to train the system end-to-end with back-propagation.

4

Under review as a conference paper at ICLR 2019

Table 1: phredGAN vs. Li et al. (2016b) on BBT Friends TV Transcripts.

Metric

SM SAM phred phredGANa phredGANd

TV Series

Perplexity 25.4 25.0 30.94 25.10

BLEU

1.90 % 1.88 % 2.41 % 3.07 %

ROUGE-2(F1) NA NA 14.03 % 30.47 %

DISTINCT-1 NA NA 0.66 % 2.19 %

DISTINCT-2 NA NA 2.54 % 19.02 %

NASL

NA NA 1.216 1.218

28.19 2.76 % 14.68 % 0.70 % 4.76 % 1.163

Encoder: The encoder RNN, eRN N , is bidirectional while cRRN is unidirectional. All RNN units are 3-layer GRU cell with hidden state size of 512. We use word vocabulary size, V = 50, 000 with word embedding size of 512. The number of attributes, V c is dataset dependent but we use an attribute embedding size of 512. In this study, we only use one attribute per utterance so that is no need to use attention to combine the attribute embeddings.
Generator: The generator decoder RNN, dRN N is also a 3-layer GRU cell with hidden state size of 512. The aRN N outputs are connected to the dRN N input using an additive attention mechanism (Bahdanau et al., 2015).
Adversarial Discriminator: The word-level discriminator RNN, DRNN is a bidirectional RNN, each 3-layer GRU cell with hidden state size of 512. The output of both the forward and the backward cells for each word are concatenated and passed to a fully-connected layer with binary output. The output is the probability that the word is from the ground truth given the past and future words of the sequence, and in the case of phredGANa, the responding speaker's embedding.
Attribute Discriminator: The attribute discriminator RNN, DattRNN is a unidirectional RNN with a 3-layer GRU cell, each of hidden state size 512. A softmax layer is then applied to project the final hidden state to a prespecified number of attributes, Vc. The output is the probability distribution over the attributes.
Others: All parameters are initialized with Xavier uniform random initialization (Glorot & Bengio, 2010). Due to the large word vocabulary size, we use sampled softmax loss (Jean et al., 2015) for MLE loss to expedite the training process. However, we use full softmax for model evaluation. For both systems, parameters updates are conditioned on the word-level discriminator accuracy performance as in Olabiyi et al. (2018) with accDathdv = 0.99 and accGth = 0.75. The model is trained end-to-end using the stochastic gradient descent algorithm. Finally, the model is implemented, trained, and evaluated using the TensorFlow deep learning framework.
3.2 MODEL INFERENCE
We use an inference strategy similar to the approach in Olabiyi et al. (2018).
For the modified noise sample, we perform a linear search for  with sample size L = 1 based on the average word-level discriminator loss, -logDadv(G(.)) (Olabiyi et al., 2018) using trained models run in autoregressive mode to reflect performance in actual deployment. The optimum  value is then used for all inferences and evaluations. During inference, we condition the dialogue response generation on the encoder outputs, noise samples, word embedding and the attribute embedding of the intended responder. With multiple noise samples, L = 64, we rank the generator outputs by the discriminator which is also conditioned on encoder outputs, and the intended responder's attribute embedding. The final response is the response ranked highest by the discriminator. For phredGANd, we average the confidences produced by Dadv and Datt.
4 EXPERIMENTS AND RESULTS
In this section, we explore the performance of PHRED, phredGANa and phredGANd on two conversational datasets and compare its performance to non-adversarial persona Seq2seq models Li et al. (2016b) as well as to the adversarial hredGAN (Olabiyi et al., 2018) with no explicit persona.

5

Under review as a conference paper at ICLR 2019

Table 2: phredGAN model performances on UDC.

METRIC

hredGAN phred phredGANa phredGANd

UDC

PERPLEXITY 48.18

BLEU-2

2.16 %

BLEU-4

 0%

ROUGE-2(F1) 11.68 %

DISTINCT-1 5.16%

DISTINCT-2 18.21%

NASL

1.098

34.67 31.25 0.16% 1.94%  0%  0% 7.41% 19.15% 0.56% 1.05% 1.44% 5.28% 0.397 1.520

28.74 2.02% 0.10% 16.82% 1.38% 5.77% 1.387

4.1 DATASETS
TV Series Transcripts dataset (Serban et al., 2016). We train all models on transcripts from the two popular TV drama series, Big Bang Theory and Friends. Following a similar preprocessing setup in Li et al. (2016b), we collect utterances from the top 12 speakers from both series to construct a corpus of 5,008 lines of multi-turn dialogue. We split the corpus into training, development, and test set with a 94%, 3%, and 3% proportions, respectively, and pair each set with a corresponding attribute file that maps speaker IDs to utterances in the combined dataset.
Due to the small size of the combined transcripts dataset, we first train our model on the larger Movie Triplets Corpus (MTC) by Banchs (2012) which consists of 240,000 dialogue triples. We pre-train our model on this dataset to initialize our model parameters to avoid overfitting on a relatively small persona TV series dataset. After pre-training on MTC, we reinitialize the attribute embeddings in the generator from a uniform distribution following a Xavier initialization (Glorot & Bengio, 2010) for training on the combined person TV series dataset.
Ubuntu Dialogue Corpus (UDC) dataset (Serban et al., 2017b). We train our model on 1.85 million conversations of multi-turn dialogue from the Ubuntu community hub, with an average of 5 utterances per conversation. We assign two types of speaker IDs to utterances in this dataset: questioner and helper. We follow a similar training, development, and test split as the UDC dataset in Olabiyi et al. (2018), with 90%, 5%, and 5% proportions, respectively, and pair each set with a corresponding attribute file that maps speaker IDs to utterances in the combined dataset
While the overwhelming majority of utterances in UDC follow two speaker types, the dataset does include utterances that do not classify under either a questioner or helper speaker type. In order to remain consistent, we assume that there are only two speaker types within this dataset and that the first utterance of every dialogue is from a questioner. This simplifying assumption does introduce a degree of noise into each persona model's ability to construct attribute embeddings. However, our experiment results demonstrate that both phredGANa and phredGANd is still able to differentiate between the larger two speaker types in the dataset.

4.2 EVALUATION METRICS
We use similar evaluation metrics as in Olabiyi et al. (2018) including perplexity, BLEU (Papineni et al., 2002), ROUGE (Lin, 2014), distinct n-gram (Li et al., 2016a) and normalized average sequence length (NASL) scores.

4.3 BASELINE
We compare the non-adversarial persona HRED model, PHRED with the adversarially trained ones, i.e. hredGAN , phredGANa and phredGANd, to demonstrate the impact of adversarial training. Please note that no noise was added to the PHRED model.
We also compare the persona models to Li et al.'s work (Li et al., 2016b) which uses a Seq2Seq framework in conjunction with learnable persona embeddings. Their work explores two persona models in order to incorporate vector representations of speaker interaction and speaker attributes into the decoder of their Seq2Seq model i.e., Speaker model (SM) and Speaker-Addressee model (SAM). Our quantitative comparison with Li et al. (2016b) uses perplexity and BLEU scores as those

6

Under review as a conference paper at ICLR 2019

Table 3: phredGANa vs phredGANd vs Li et al. (2016b) on TV Transcripts

Model

Speaker Response

Big Bang Theory TV Series

Context 0

Sheldon Do you like me?

phredGANa Leonard
phredGANd Leonard phredGANa Penny
phredGANd Penny phredGANa Howard
phredGANd Howard phredGANa Raj
phredGANd Raj (Li et al. 2016b) Penny

Yes ? You can ' t do that ? ! No , you don ' t understand . You ' re an idiot . You ' re right . . . Well , I don ' t know what to say . This is the part I ' ve ever seen . You ' re right , you ' re just gonna go with this guy . Well , you know , we could be a little more than my friends ' s friends . You know , I can ' t can ' t do I can ' go , I can ' t do that . . . (Addressee: Emily) Of course, I love you, Emily.

Context 0

Howard We can't go home.

Context 1

Leonard Alright, I'll be right back.

phredGANa Howard Okay , well , before you and Penny get out and get married with Penny just get married. phredGANd Howard You ' ll see , I ' ll just go .

Context 0

Amy

Context 1

Penny

Context 2

Amy

phredGANa Penny

phredGANd Penny

Spent a lot of my childhood throwing coins into wishing wells hoping for friends. Whoa, whoa, give me a second to catch up here. Hold on. That'd be my boyfriend. Happier playing his dopey Star Trek game with his friends than hanging out with me. You know , when you ' re being so nice about Sheldon and I want to take him to like his own girlfriend You , I ' m sorry , I didn ' t have it . d be back in the bathroom . .

Context 0

Sheldon

phredGANa Howard phredGANd Howard

I recently read that during World War Two, Joseph Stalin had a research program to create supersoldiers by having women impregnated by gorillas. You ' re right . I don ' t know what you ' re talking about , Sheldon . You ' re kidding . .

Friends TV Series

Context 0

Rachel

phredGANa Joey

phredGANd Joey phredGANa Ross

phredGANd Ross phredGANa Monica

phredGANd Monica phredGANa Chandler

phredGANd Chandler (Li et al. 2016b) Chandler

Do you like me? Yeah . You ' re right . . . . Well , no , no , no . I mean , I just , I don ' t know . . . You ' want to know sex . . Well , I do . And I ' m not gonna tell you another guy . You ' re a , you ' re really good . . . . No , I do not . You are a mean little man . . You ' re right , I can ' t do that . Of course I love you.

are the ones reported in Li et al. (2016b). In addition, we also measure our models' performance in terms of ROGUE, distinct n-gram, and NASL scores for the purpose of completion. For fair comparison, we use the same TV drama series dataset used in their study.

4.4 HYPERPARAMETER SEARCH
For both phredGANa and phredGANd, we determine the noise injection method and the optimum noise variance  that allows for the best performance on both datasets. We find that phredGANd performs optimally with word-level noise injection on both Ubuntu and TV transcripts, while phredGANa performs the best with utterance-level noise injection on TV transcripts and word-level injection on UDC. For all phredGAN models, we perform a linear search for optimal noise variance values between 1 and 30 at an increment of 1, with a sample size of L = 1. For phredGANd, we obtain an optimal  of 4 and 6 for the UDC and TV Transcripts respectively. For phredGANa, we obtain an optimal value of 2 and 5 for the combined TV series dataset and the much larger UDC respectively.

4.5 RESULTS
We will now present our assessment of performance comparisons of phredGAN against the baselines, PHRED, hredGAN and Li et al.'s persona Seq2Seq models.

4.6 QUANTITATIVE ANALYSIS
We first report the performance on TV series transcripts in table 1. Some of our models actually performs slightly worse than both variations of the Speaker Model and Speaker-Addressee systems in Li et al. (2016b) terms of the perplexity measure. This is not surprising because, the entropy of multiturn dialogue is higher than that of single turn. Similar observation has been made by Serban et al. (2016) about seq2seq and HRED dialogue models. However, PHRED and phredGAN variants reports a significantly larger BLEU score than both Speaker and Speaker-Addressee models with phredGANd performing best. We attribute this improvement to (i) the multi-turn dialogue context,

7

Under review as a conference paper at ICLR 2019
(ii) training in an adversarial framework, which forces the model to produce longer, more informative, and diverse responses that have high topic relevance even with a limited dataset. Also, unlike Speaker-Addressee model that suffers from lower response quality due to persona conditioning, we note that conditioning the generator and discriminator of phredGAN on speaker embeddings does not compromise the systems ability to produce diverse responses. This problem might have been alleviated by the adversarial training too.
We also compare hredGAN , PHRED and variants of phredGAN on the UDC. The evaluation result is summarized in Table 2. We note an improvement of phredGAN variants over the hredGAN in a variety of evaluation metrics including perplexity, ROUGE with the exception of distinct ngrams. This is expected as phredGAN should be generally less diverse than hredGAN since the number of distinct data distribution modes is more for phredGAN dataset due to the persona attributes. However, this leads to better response quality with persona, something not achievable with hredGAN . Also, the much better ROUGE(f1) score indicates that phredGAN is able to strike a better balance between diversity and precision while still capturing the characteristics of the speaker attribute modality in the UDC dataset. Within the phredGAN variants, phredGANd seems to perform better. This is not surprising as speaker classification is mush easier on UDC than on TV series. The attribute discriminator, Datt is able to provide more informative feedback on UDC than on TV series where it is more difficult accurately predict the speaker. Therefore, we recommend phredGANa for datasets with weak attribute distinction and phredGANd for strong attribute distinction.
4.7 QUALITATIVE ANALYSIS
A qualitative assessment of these results are in Table 3 with responses from several characters in the TV series dataset and the two characters in UDC.
We see that for TV drama series, phredGAN responses are comparatively more informative than that of the Speaker-Addressee model of Li et al. (2016b). For example, with Speaker-Addressee model, nearly all the characters in the TV series respond with "Of course I love you." to the dialogue context, "Do you love me?" despite the fact that some of the responders sometimes have unfriendly relationship with the addressee. Many of the novel situation explored by phredGAN are unachievable with the Speaker-Addressee model due to lack of informative responses. For example, by conditioning as Sheldon from The Big Bang Theory and asking "Do you like me?", our model responds with annoyance if conditioned as Penny ("No, you don't understand. You're an idiot"), brevity with Leonard ("Yes?") and sarcasm with Raj ("Well , you know , we could be a little more than my friend's friends.") The wide range of responses indicate our model's ability to construct distinct attribute embeddings for each character even from a limited dataset. The other interesting responses in Table 3 indicate phredGAN 's ability to infer not only the context of the conversation but important character information about the addressee.
We also see similar results with our model's output on UDC. We demonstrate that by conditioning as either a helper or questioner from the UDC dataset, phredGAN models are able to respond differently to input utterances as well as stay close to the context of the conversation.
5 CONCLUSION AND FUTURE WORK
In this paper, we improve upon state-of-the-art persona-based response generation models by exploring two persona conversational models: phredGANa which passes the attribute representation as an additional input into a traditional adversarial discriminator, and phredGANd a dual discriminator system which in addition to the adversarial discriminator from hredGAN , collaboratively predicts the attribute(s) that are intrinsic to the input utterance. Both systems demonstrate quantitative improvements upon state-of-the-art persona conversational systems such as the work from Li et al. (2016b) with respect to BLEU and perplexity scores, and the value of an adversarial system is seen from comparing the performance of both phredGAN systems to a baseline phred and hredGAN models.
Our analysis also demonstrates how both variants of phredGAN perform differently on datasets with weak and strong modality. One of our future direction is to take advantage of phredGANd's ability to predict utterance attribute such as speaker identity from just the utterance. We believe its
8

Under review as a conference paper at ICLR 2019
performance can be improved even with weak modality by further conditioning adversarial updates on both the attribute and adversarial discriminator accuracies. Overall, this paper demonstrates clear benefits from adversarial training of persona generative dialogue system and leaves the door open for more interesting work to be accomplished in this domain.
REFERENCES
D. Bahdanau, K. Cho, and Y. Bengio. Neural machine translation by jointly learning to align and translate. In Proceedings of International Conference of Learning Representation (ICLR 2015), 2015.
R. E. Banchs. Movie-dic: A movie dialogue corpus for research and development. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pp. 203­207, 2012.
X. Glorot and Y. Bengio. Understanding the difficulty of training deep feedforward neural networks. In International conference on artificial intelligence and statistics, 2010.
S. Jean, K. Cho, R. Memisevic, and Y. Bengio. On using very large target vocabulary for neural machine translation. In arXiv preprint arXiv:1412.2007, 2015.
J. Li, M. Galley, C. Brockett, J. Gao, and B. Dolan. A diversity-promoting objective function for neural conversation models. In Proceedings of NAACL-HLT, 2016a.
J. Li, M. Galley, C. Brockett, G. Spithourakis, J. Gao, and B. Dolan. A persona-based neural conversation model. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pp. 994­1003, 2016b.
C. Y. Lin. Rouge: a package for automatic evaluation of summaries. In Proceedings of the Workshop on Text Summarization Branches Out, 2014.
H. Nguyen, D. Morales, and T. Chin. A neural chatbot with personality. In Stanford NLP Course website: https://web.stanford.edu/class/cs224n/reports/2761115.pdf, 2018.
O. Olabiyi, A. Salimov, A. Khazane, and E. Mueller. Multi-turn dialogue response generation in an adversarial learning framework. In arXiv preprint arXiv:1805.11752, 2018.
K. Papineni, S. Roukos, T. Ward, and W. Zhu. Bleu: A method for automatic evalution of machine translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pp. 311­318, 2002.
I. Serban, A. Sordoni, Y. Bengio, A. Courville, and J. Pineau. Building end-to-end dialogue systems using generative hierarchical neural network models. In Proceedings of The Thirtieth AAAI Conference on Artificial Intelligence (AAAI 2016), pp. 3776­3784, 2016.
I. V. Serban, T. Klinger, G. Tesauro, K. Talamadupula, B. Zhou, Y. Bengio, and A. Courville. Multiresolution recurrent neural networks: An application to dialogue response generation. In Proceedings of The Thirty-first AAAI Conference on Artificial Intelligence (AAAI 2017), 2017a.
I. V. Serban, A. Sordoni, R. Lowe, L. Charlin, J. Pineau, A. Courville, and Y. Bengio. A hierarchical latent variable encoder-decoder model for generating dialogue. In Proceedings of The Thirty-first AAAI Conference on Artificial Intelligence (AAAI 2017), 2017b.
I. Sutskever, O. Vinyals, and Q. Le. Sequence to sequence learning with neural networks. In Proceedings of Advances in Neural Information Processing Systems (NIPS), pp. 3104­3112, 2014.
O. Vinyals and Q. Le. A neural conversational model. In Proceedings of ICML Deep Learning Workshop, 2015.
C. Xing, W. Wu, Y. Wu, M. Zhou, Y. Huang, and W. Ma. Hierarchical recurrent attention network for response generation. In arXiv preprint arXiv:1701.07149, 2017.
S. Zhang, E. Dinan, J. Urbanek, A. Szlam, D. Kiela, and J. Weston. Personalizing dialogue agents: I have a dog, do you have pets too? In arXiv preprint arXiv:1801.07243v3, 2018.
9

Under review as a conference paper at ICLR 2019

APPENDIX

Algorithm 1 Adversarial Learning of phredGAN

Require: A generator G with parameters G.

Require: An adversarial discriminator Dadv with parameters Dadv . Require: An attribute discriminator Datt with parameters Datt . Require: Training hyperparameters, isT arget, Gatt , Gadv , and M .
for number of training iterations do

Initialize cRN N to zero state, h0 Sample a mini-batch of conversations, X = {Xi}Ni=1, Xi = (X1, X2, · · · , Xi) with N utterances. Each utterance mini batch i contains Mi word tokens.
for i = 1 to N - 1 do

Update the context state.

hi = cRN N (eRN N (E(Xi)), hi-1)

Compute the generator output using Eq. (11) in Olabiyi et al. (2018).

PG Yi|, Zi, Xi = PG Yij |Xi1+:j1-1, Zij , Xi

Mi+1 j=1

Sample a corresponding mini batch of utterance Yi.

Yi  PG Yi|, Zi, Xi

end for

Compute the adversarial discriminator if Daadccv < accDathdv then

accuracy

Daadccv

over

N

-

1

utterances

{Yi }iN=-11

and

{Xi+1 }Ni=-11

if isT arget then

Update phredGANd's Dadv and Datt . i [Dadv log Dadv (hi, Xi+1) + Dadv log 1 - Dadv (hi, Yi) + Datt log Datt(Ci+1|hi, Xi+1) +

Datt log Datt(Ci+1|hi, Yi) ] else

Update phredGANa's Dadv with gradient of the discriminator loss. i [Dadv log Dadv (hi, Ci+1, Xi+1) + Dadv log 1 - Dadv (hi, Ci+1, Yi) ] end if

end if if Dadv acc < accGth then
Update G with the generator's MLE loss only.
[G log PG Yi|, Zi, Xi ]
i
else

Update G with attribute, adversarial and MLE losses. [Gatt G log Datt(hi, Yi) + Gadv G log Dadv (hi, Ci+1, Yi) + M G log PG Yi|, Zi, Xi ]
i
end if

end for

6 RESULTS - DISCRIMINATOR
After training both phredGAN models on the TV series and UDC datasets, we ran inference on some example dialogue contexts. The responses and their discriminator scores from phredGAN s are listed in Tables 5, and 6. The tables shows that phredGAN (i) can handle multi-turn dialogue context with utterances and corresponding persona attributes; (ii) generates responses conditioned on a persona attribute; (iii) generates multiple responses per dialogue context and score their human likelihood by the discriminator; and (iv) in case of phredGANd, can predict the attribute such as speaker identity that might have produced the utterance. We observe that the discriminator score(s) is/are generally reasonable with longer, more informative and more persona-related responses receiving higher scores. It worth to note that this behavior, although similar to the behavior of a human judge is learned without supervision. More so, we observe that phredGAN responses retain contextual consistency sometimes referencing background information that is inherent in the conversation between two speakers. For example, in the second sample of the TV series in Table 5, phredGANa generator, conditioned on Leonard refers to Sheldon by name who is the second interlocutor. Also, in the third sample, phredGANa, conditioned on Raj refers to Penny when responding to Leonard who happens to be Penny's boy friend. We see similar persona-based response generation for the UDC dataset with distinct communication style between the asker and the helper. For example, in Table 6, when the asker could not hear some music, phredGANd, conditioned on helper suggested the asker might not be using the right driver. For the purpose of completion, we also show some samples from PHRED generator on both UDC and TV series dataset in Table 4.

10

Under review as a conference paper at ICLR 2019

Table 4: Sample of PHRED outputs on UDC and TV Series

Source Speaker Utterance
Big Bang Theory and Friends TV Series Context 0 Howard Okay, you have to understand something, we're in a hospital right now. Response 0 Penny Oh , I ' m sorry . I was just trying to be a girl .

Context 0 Sheldon Did I? Well, that can't be right. No one's ever done that before. Except me, because I just did it. Sheldon and his brain, yeah Response 0 Leonard I ' m sorry . I just don ' t want to be a man who ' s going to be my girlfriend .

Context 0 Leonard She's gotten really hooked on Age of Conan, she's playing non-stop.

Response 0 Raj

Oh , I ' m sorry . I ' m sorry . I ' m sorry . I ' m sorry . I ' m

UDC Context 0 asker Context 1 helper Context 2 asker Response 0 helper

all i need some quick amarok help. i cant hear my music is amarok muted? no you can try to install the UNK package

Context 0 asker Context 1 helper Response 0 asker

anyone had problems with the kernel update from today? giving me a kernel panic you can select previous kernels at the bootloader (grub) menu on booth. you can try to install the drivers from the live cd

Context 0 asker how do I install Ubuntu? Response 0 helper yes

Table 5: Ranked phredGANa outputs according to adversarial word-level discrimination score

Source

Speaker Dadv (G(.)) Utterance

Big Bang Theory and Friends TV Series

Context 0 Howard NA

Okay, you have to understand something, we're in a hospital right now.

Response 0 Penny 0.1705

Okay, I'm sorry. I'm not really even like that.

Response 1 Penny 0.1426

Okay, I'm sorry, I'm sorry.

Response 2 Penny 0.0688

Okay.

Context 0 Sheldon NA Response 0 Leonard 0.3976 Response 1 Leonard 0.3503

Did I? Well, that can't be right. No one's ever done that before. Except me, because I just did it. Sheldon and his brain, yeah Sheldon , what are you doing ? Sheldon ?

Context 0 Leonard NA

Response 0 Raj

0.4890

Response 1 Raj

0.3586

Response 2 Raj

0.1113

UDC Context 0 asker Context 1 helper Context 2 asker Response 0 helper Response 1 helper Response 2 helper

NA NA NA 0.3079 0.1283 0.0725

She's gotten really hooked on Age of Conan, she's playing non-stop. Okay , so we know , what about you and Penny doing here ? Okay , so we would have to say that about people ? Okay , let ' s go .
all i need some quick amarok help. i cant hear my music is amarok muted? no use the UNK drivers , and then run the " UNK " command to get the UNK what is the error message ? what version of ubuntu ?

Context 0 asker Context 1 helper Response 0 asker Response 1 asker Response 2 asker

NA NA 0.3665 0.3195 0.0186

anyone had problems with the kernel update from today? giving me a kernel panic you can select previous kernels at the bootloader (grub) menu on booth. it says that it is not installed . . . i'm not sure what i can find . . . it's a UNK , I'm not sure of the way .

Context 0 asker Response 0 helper Response 1 helper Response 2 helper

NA 0.5797 0.1984 0.0131

how do I install Ubuntu? use the alternate cd , it should be in the repos , it's a good place to get the source of the kernel use the UNK package , it should work . . . use the UNK

11

Under review as a conference paper at ICLR 2019

Table 6: Sample of phredGANd outputs with dual discriminator scores

Source Speaker Dadv (G(.)) Prediction Datt(G(.)) Utterance

Big Bang Theory TV Series Context 0 Howard NA Response 0 Penny 0.7389 Response 1 Penny 0.5324 Response 2 Penny 0.4394

NA Rachel Rachel Rachel

NA 0.3101 0.3101 0.3101

Okay, you have to understand something, were in a hospital right now. You can ' believe me , you can ' t can ' t do it . . You ' re right , I'm sorry , I ' go , I can ' t do that . . . You ' re right .

Context 0 Sheldon NA
Response 0 Leonard 0.7028 Response 1 Leonard 0.5998 Response 2 Leonard 0.4384

NA NA

Rachel Rachel Rachel

0.3805 0.3805 0.3805

Did I? Well, that cant be right. No ones ever done that before. Except me,because I just did it. Sheldon and his brain, yeah. You ' re really good . You know , I can ' t believe you can ' to do that . You ' re right .

Context 0 Leonard NA Response 0 Raj 0.6707 Response 1 Raj 0.6451 Response 2 Raj 0.4138

UDC Context 0 asker Context 1 helper Context 2 asker Response 0 helper Response 1 helper Response 2 helper

NA NA NA 0.4489 0.2312 0.1381

NA Rachel Rachel Rachel

NA 0.2867 0.2867 0.2867

NA NA NA helper helper helper

NA NA NA 0.8582 0.8582 0.8582

Shes gotten really hooked on Age of Conan, shes playing non-stop. You know , I , I just want to be friends with you . You ' want on to do that ? You okay ?
all i need some quick amarok help. i cant hear my music is amarok muted? no ok , so you ' re not using the right driver for the network card , you ' re using the UNK ? ok , so you ' re not using the right driver , right ? ok , so you are you using the UNK ?

Context 0 asker Context 1 helper Response 0 asker Response 1 asker Response 2 asker

NA NA 0.3431 0.2518 0.1005

NA NA asker asker asker

NA NA 0.8126 0.8126 0.8126

anyone had problems with the kernel update from today? giving me a kernel panic you can select previous kernels at the bootloader (grub) menu on booth. ok , so i ' ll have to reinstall the new kernel , i ' ll try that . ok , so i ' just reinstall the ubuntu version ? ok , thanks :)

Context 0 asker Response 0 helper Response 1 helper Response 2 helper

NA 0.4306 0.3783 0.1618

NA helper helper helper

NA 0.8540 0.8540 0.8540

how do I install Ubuntu? ok , so you have to reinstall the kernel from the CD , and you can ' t install the iso to the CD ok , so you have to go to the ubuntu site and see if you have the same version ? ok , so are you using the ubuntu version ? ?

12

