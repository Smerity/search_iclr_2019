Under review as a conference paper at ICLR 2019

SIGNSGD VIA ZEROTH-ORDER ORACLE

Anonymous authors Paper under double-blind review

ABSTRACT

In this paper, we design and analyze a new zeroth-order (ZO) stochastic optimization algorithm, ZO-signSGD, which enjoys dual advantages of gradient-free operations and signSGD. The latter requires only the sign information of gradient estimates but is able to achieve a comparable or even better convergence speed than SGD-type algorithms. Our study shows that ZO-signSGD requires d times more iterations than signSGD, leading to a convergence rate of O( d/ T ) under mild conditions, where d is the number of optimization variables, and T is the number of iterations. In addition, we analyze the effects of different types of gradient estimators on the convergence of ZO-signSGD, and propose two variants of ZO-signSGD that at least achieve O( d/ T ) convergence rate. On the application side we explore the connection between ZO-signSGD and black-box adversarial attacks in robust deep learning. Our empirical evaluations on image classification datasets MNIST and CIFAR-10 demonstrate the superior performance of ZO-signSGD on the generation of adversarial examples from black-box neural networks.

1 INTRODUCTION
Zeroth-order (gradient-free) optimization has attracted an increasing amount of attention for solving machine learning (ML) problems in scenarios where explicit expressions for the gradients are difficult or infeasible to obtain. One recent application of great interest is to generate prediction-evasive adversarial examples, e.g., crafted images with imperceptible perturbations to deceive a well-trained image classifier into misclassification. However, the black-box optimization nature limits the practical design of adversarial examples, where internal configurations and operating mechanism of public ML systems (e.g., Google Cloud Vision API) are not revealed to practitioners and the only mode of interaction with the system is via submitting inputs and receiving the corresponding predicted outputs (Papernot et al., 2017; Liu et al., 2017; Chen et al., 2017; Tu et al., 2018; Ilyas et al., 2018b; Cheng et al., 2018; Bhagoji et al., 2018). It was observed in both white-box and black-box settings1 that simply leveraging the sign information of gradient estimates of an attacking loss can achieve superior empirical performance in generating adversarial examples (Goodfellow et al., 2015; Madry et al., 2018; Ilyas et al., 2018a). Spurred by that, this paper proposes a zeroth-order (ZO) sign-based descent algorithm (we call it `ZO-signSGD') for solving black-box optimization problems, e.g. design of black-box adversarial examples. The convergence behavior and algorithmic stability of the proposed ZO-signSGD algorithm are carefully studied in both theory and practice.
In the first-order setting, a sign-based stochastic gradient descent method, known as signSGD, was analyzed by (Bernstein et al., 2018; Balles & Hennig, 2017). It was shown in (Bernstein et al., 2018) that signSGD not only reduces the per iteration cost of communicating gradients (by only transmitting gradient signs), but also could yield a faster empirical convergence speed than SGD and Adam (Kinga & Adam, 2015), implying that fewer samples are needed to achieve the same solution quality. Theoretically, signSGD achieves O(1/ T ) convergence rate under the condition of a sufficiently large mini-batch size, which scales with T and is therefore impractical. Here T denotes the total number of iterations. The work in (Balles & Hennig, 2017) established a connection between signSGD and Adam with restrictive convex analysis. Prior to (Bernstein et al., 2018; Balles & Hennig, 2017), although signSGD was not formally defined, the fast gradient sign method (Goodfellow et al., 2015) to generate white-box adversarial examples actually obeys the algorithmic protocol of signSGD. The effectiveness of signSGD has been witnessed by robust adversarial training of deep neural networks (DNNs) (Madry et al., 2018). Given the advantages of signSGD, one may wonder if it can be generalized for ZO optimization and what the corresponding convergence rate is. In this paper, we answer these questions affirmatively.
1`white-box' (vs `black-box') implies whether the knowledge on the target model is known a priori.

1

Under review as a conference paper at ICLR 2019

Contributions We summarize our key contributions as follows. · Wepropose a new ZO algorithm, ZO-signSGD, and rigorously prove its convergence rate of O( d/ T ) under mild conditions, where d is the number of optimization variables. Our result matches the best known rate of ZO algorithms without using any additional variance reduced technique. Our analysis removes the impractical assumption of b = O(T ) used in signSGD, and allows mini-batch samples both with and without replacement.
· We develop and analyze two variants of ZO-signSGD, which are built on different types of gradient estimators, a) using central difference of function values, and b) using signs of estimates with majority vote. We show that these variants lead to at least the same convergence rate of ZO-signSGD.
· We conduct extensive synthetic experiments to thoroughly benchmark the performance of ZO-signSGD and to investigate its parameter sensitivity.
· We explore the connection between signSGD-type methods and the design of adversarial examples. We demonstrate the superior performance of ZO-signSGD for generating adversarial examples from black-box DNNs.

Related work Other types of ZO algorithms have been developed for convex and nonconvex optimization, where the full gradient is approximated via a random or deterministic gradient estimate (Jamieson et al., 2012; Nesterov & Spokoiny, 2015; Ghadimi & Lan, 2013; Duchi et al., 2015; Gao et al., 2014; Shamir, 2017; Hajinezhad et al., 2017; Ghadimi et al., 2016; Lian et al., 2016; Liu et al., 2018b;c; Wang et al., 2018). Examples include ZO-SGD (Ghadimi & Lan, 2013), ZO stochastic coordinate descent (ZO-SCD) (Lian et al., 2016), and ZO stochastic variance reduced gradient descent(ZO-SVRG) (Liu et al., 2018c;a; Gu et al., 2016). Both ZO-SGD and ZO-SCD can achieve O( d/ T ) convergence rate. And ZO-SVRG can further improve the iteration complexity to O(d/T ) but suffers from an increase of function query complexity due to the additional variance reduced step, known as `gradient blending' (Liu et al., 2018c), compared to ZO-SGD. The existing work showed that ZO algorithms align with the iteration complexity of their first-order counterparts up to a slowdown effect in terms of a small-degree polynomial of the problem size d.

2 SIGNSGD & ITS CONNECTION TO ADVERSARIAL MACHINE LEARNING

In this section, we provide a background on signSGD, together with the problem setup of our interest. In particular, we show that the commonly-used methods for generating adversarial attacks fall into the framework of signSGD.

Preliminaries on signSGD Consider a nonconvex finite-sum problem of the form

minimize x

f (x) := (1/n)

n i=1

fi

(x),

(1)

where x  Rd are optimization variables, and {fi} are n individual nonconvex cost functions. The finite-sum form (1) encompasses many ML problems, ranging from generalized linear models to neural networks. If the gradients of {fi} are available, then problem (1) can be solved by many first-order methods such as SGD, SCD, and signSGD. The method of our interest is signSGD, which
differs from SGD and SCD, takes the sign of gradient (or its estimate) as the descent direction. It
was recently shown in (Bernstein et al., 2018) that signSGD is quite robust to gradient noise and thus
yields fast empirical convergence.

Algorithm 1 provides a generic sign-based gradient descent framework that encapsulates different variants of signSGD. In Algorithm 1, GradEstimate(·) signifies a general gradient estimation procedure, which adopts either a stochastic gradient estimate in the first-order setting of signSGD (Bernstein et al., 2018) or a function difference based random gradient estimate in its ZO setting (Nesterov & Spokoiny, 2015; Duchi et al., 2015). The ZO variant of signSGD will be elaborated on in Sec. 3.

Adversarial attacks meet signSGD It is now widely known that ML models (e.g., deep neural networks) are vulnerable to adversarial attacks, which craft inputs (e.g., images) with imperceptible perturbations to cause incorrect classification (Szegedy et al., 2013; Goodfellow et al., 2015; Kurakin et al., 2017). The resulting inputs crafted by adversaries are known as adversarial examples. Investigating adversarial examples not only helps to understand the limitation of learning models, but also provides opportunities to improve the models' robustness (Papernot et al., 2016; Athalye et al., 2018; Madry et al., 2018). In what follows, we show that the generation of adversarial examples in (Goodfellow et al., 2015; Kurakin et al., 2017) can be interpreted through signSGD.

2

Under review as a conference paper at ICLR 2019

Algorithm 1 Generic sign-based gradient descent

1: Input: learning rate {k}, initial value x0, and number of iterations T 2: for k = 0, 1, . . . , T - 1 do
3: g^k - GradEstimate(xk) # applies to both first and zeroth order gradient estimates 4: sign-gradient update

xk+1 = xk - ksign(g^k), where sign(x) takes element-wise signs of x

(2)

5: end for

Let x0 denote the natural (legitimate) input of an ML model associated with the true label t0, and x = x0 +  be the adversarial example to be designed, where  are adversarial perturbations. If f (x, t0) is the training loss of a learning model, then the goal of (white-box) adversarial attack is to find minimal perturbation  that is sufficient to mislead the learning model, namely, to maximize the loss f (x0 + , t0). Taking the first-order approximation of f (x , t0) around x0, we obtain f (x , t0)  f (x0, t0) + xf (x0, t0),  . By constraining the strength of perturbation in the  ball of small radius (i.e.,    ), the linear approximation of f (x , t0) is then maximized at  = sign(xf (x0, t0)) (Shaham et al., 2018). Therefore, generation of adversarial examples proposed in (Goodfellow et al., 2015) obeys the sign-gradient update rule in (2),
x = x0 - sign(-xf (x0, t0)).
Such a connection between adversarial example generation and signSGD also holds in other attacks,
such as the iterative target attack method (Kurakin et al., 2017). Similarly, a so-called black-box attack
(Ilyas et al., 2018a; Bhagoji et al., 2018) is associated with our proposed ZO variants of signSGD.

3 ZO-SIGNSGD FOR BLACK-BOX OPTIMIZATION

One limitation of signSGD (Bernstein et al., 2018) is the need of first-order information, i.e., stochastic gradients. However, as highlighted in Sec. 1, there exists a large practical demand for solving ML problems where explicit expressions of the gradients are difficult or infeasible to obtain. This motivates the proposed ZO-signSGD method.

Gradient estimation via ZO oracle In the ZO setting where the first-order information is unavail-

able, the gradient estimator at Step 3 of Algorithm 1 has only access to function values of {fi(x)}

given a query point x. Based on that, we construct a ZO gradient estimate through a forward differ-

ence of two function values (Nesterov & Spokoiny, 2015; Gao et al., 2014; Duchi et al., 2015). In

Algorithm 1, GradEstimate(x) is then specified as

1 GradEstimate(x) =
bq

q

^ fi(x; ui,j ), ^ fi(x; ui,j )

:=

d[fi(x

+

µui,j ) µ

- fi(x)] ui,j ,

iIk j=1

(3)

where x = xk in Algorithm 1, Ik is a mini-batch of size |Ik| = b, {ui,j}jq=1 are i.i.d. random directions drawn from a uniform distribution over a unit sphere2, and ^ fi(x; ui,j) gives a conventional two-point based random gradient estimate with direction ui,j and smoothing parameter µ > 0.

We highlight that unlike the first-order stochastic gradient estimate, the ZO gradient estimate (3) is a

biased approximation to the true gradient of f . Instead, it becomes unbiased to the gradient of the

randomized smoothing function fµ (Duchi et al., 2012; Gao et al., 2014),

1n

1n

fµ(x) = Ev[f (x + µv)] = n Ev[fi(x + µv)] = n fi,µ(x),

i=1

i=1

(4)

where fi,µ gives the randomized smoothing version of fi, and the random variable v follows a uniform distribution over the unit Euclidean ball. Clearly, there exists a gap between a ZO gradient estimate and the true gradient of f , but as will be evident later, such a gap can be measured through the smoothing function fµ.

ZO-signSGD & technical challenges beyond signSGD Algorithm 1 becomes ZO-signSGD as the ZO gradient estimate (3) is applied. We note that the extension from first order to ZO is highly nontrivial, as the proposed ZO-signSGD algorithm yields three key differences to signSGD.

2The random direction vectors can also be drawn from the standard Gaussian distribution (Nesterov & Spokoiny, 2015). However, the uniform distribution could be more useful in practice since it is defined in a bounded space rather than the whole real space required for Gaussian.

3

Under review as a conference paper at ICLR 2019

First, ZO-signSGD has no restriction on the mini-batch size b. Recall that signSGD in (Bernstein et al., 2018) achieves O(1/ T ) convergence rate given the condition that the mini-batch size is sufficiently large, b = O(T ). However, this condition only becomes true when the mini-batch sample is randomly selected from [n] with replacement, which is unusual when n  T . Here [n] represents the integer set {1, 2, . . . , n}. And signSGD fails to cover signGD when b = n, since sampling with replacement leads to Ik = [n] even if b = n. In the proposed ZO-signSGD algorithm, we will relax the assumption on b and consider mini-batch sampling both with and without replacement.
ZO-signSGD requires more involved analysis to reveal the statistical properties of the ZO gradient estimator (3) since it covers two kinds of randomness from mini-batch sampling as well as from random direction sampling. By contrast, signSGD (Bernstein et al., 2018) only requires to bound the variance of (first-order) stochastic gradients under the assumption of i.i.d. mini-batch samples (with replacement).
Finally, ZO-signSGD requires to evaluate the error propagation from the sign of a ZO gradient estimate to the true gradient. However, both the sign operation and the random gradient estimation induce biased approximations to the true gradient. Thus, current analysis cannot handle this complex ZO scenario, and a new analysis beyond signSGD is required.

4 CONVERGENCE ANALYSIS OF ZO-SIGNSGD

In this section, we begin by stating assumptions used in our analysis. We then derive the convergence rate of ZO-signSGD for nonconvex optimization. Assumptions of problem (1) are listed as follows.

A1: Functions {fi} have L-Lipschitz continuous gradients, where L  (0, ). A2: The gradient of fi is upper bounded by fi(x) 2   for i  [n].

Both A1 and A2 are the standard assumptions used in nonconvex optimization literature (Bernstein

et al., 2018; Reddi et al., 2018; Chen et al., 2018). A1 implies the L-smoothness of fi, namely, for

any x and y we obtain fi(x) - fi(y)  fi(y), x - y + (L/2) x -

variance

of

fi

in

(Bernstein

et

al.,

2018,

Assumption 3),

namely,

1 n

y
n

2 i

.

i=1

A2 implies fi(x) -

the bounded

f (x)

2 2



42, where we have used the fact that f (x) 2   under A2. Throughout the paper, we assume

that problem (1) is solvable, namely, f (x) > - where x is an optimal solution.

We recall that Algorithm 1 becomes ZO-signSGD when the gradient estimation step (3) is applied.
For nonconvex problems, the convergence of an algorithm is typically measured by stationarity, e.g., using f (x) 2 in SGD (Ghadimi & Lan, 2013) and f (x) 1 in signSGD (Bernstein et al., 2018). For the latter, the 1 geometry is met while quantifying the stochasticity through the (non-linear) sign operation. Different from signSGD, ZO-signSGD only obtains a biased estimate to the true gradient.
In Proposition 1, we bypass such a bias by leveraging the randomized smoothing technique used for
ZO optimization (Gao et al., 2014; Nesterov & Spokoiny, 2015; Duchi et al., 2015).

Proposition 1 Under A1, the outputs {xk}Tk=-01 of ZO-signSGD, i.e., Algorithm 1 with (3), satisfies

T -1

T -1



(kE[ fµ(xk) 1]) E[fµ(x0) - fµ(xT )] +

2k d

k=0

k=0

E[ g^k - fµ(xk) 22]

+

dL 2

T -1

k2 ,

k=0

(5)

where the expectation is taken with respect to all the randomness of ZO-signSGD, fµ is the randomized smoothing function of f in (4), and g^k = GradEstimate(xk) in (3).

Proof: See Appendix 1.

In Proposition 1, the rationale behind introducing the smoothing function fµ is that fµ(xk) is the

mean of ZO gradient estimate g^k. And thus, the convergence of ZO-signSGD is now linked with the

variance of g^k, i.e., E[

g^k - fµ(xk)

2 2

].

This crucial relationship presented in Proposition 1 holds

for a general class of signSGD-type algorithms that use different ZO gradient estimators. Spurred by

(5), we next investigate the second-order moment of g^k in Proposition 2.

Proposition 2 Under A1 and A2, the variance of ZO gradient estimate g^k is upper bounded by

E

g^k - fµ(xk)

2 2

 4b(q + 1) 2 + (2b + b) C(d, µ), bq bq

(6)

4

Under review as a conference paper at ICLR 2019

where C(d, µ) := 2d2 + µ2L2d2/2. In (6), b and b are Boolean variables depending on the choice of mini-batch sampling,

b = 1, b = 0

for mini-batch with replacement

b = I(b < n), b = I(b > 1) for mini-batch without replacement,

(7)

where I(x > a) is the indicator function of x with respect to the constraint x > a, and I(x > a) = 1 if x > a and 0 otherwise.

Proof: See Appendix 2.

Compared to the variance bound (2/b) of the stochastic gradient estimate of f in signSGD (Bernstein

et al., 2018), Proposition 2 provides a novel and more general result for the ZO gradient estimate g^k.

It

is

clear

that

the

bound

in

(6)

contains

two

parts:

h1

:=

4b

(q+1) bq

2

and

h2

:=

(2b +b bq

)

C

(d,

µ),

where the former h1 = O(2/b) characterizes the reduced variance (using b mini-batch samples) for

the stochastic gradient estimate of the smoothing function fµ, and the latter h2 = O(C(d, µ)/(bq))

reveals the dimension-dependent variance induced by ZO gradient estimation using b mini-batch

samples and q random directions. If a stochastic gradient estimate of f is used in signSGD, then h2 is eliminated and the variance bound in (6) is reduced to (2/b).

Furthermore, Proposition 2 covers mini-batch sampling with and without replacement, while signSGD

only considers the first case. For the second case, Proposition 2 implies that if b = n (i.e., Ik = [n]

for a batch ZO-signSGD), then the variance E

g^k

- fµ(xk)

2 2

is reduced to O(C(d, µ)/(nq)),

corresponding to b = 0 and b = 1 in (7). In the other extreme case of b = 1, both the studied

mini-batch schemes become identical, leading to b = 1 and b = 0. Proposition 2 also implies that the use of large b and q reduces the variance of the gradient estimate, and will further improve the

convergence rate.

With the aid of Proposition 1 and 2, we can then show the convergence rate of ZO-signSGD in terms of stationarity of the original function f . The remaining difficulty is how to bound the gap between f and its smoothed version fµ. It has been shown in (Gao et al., 2014; Nesterov & Spokoiny, 2015) that there exists a tight relationship between fµ and f given the fact that the former is a convolution of the latter and the density function of a random perturbation v in (4). We demonstrate the convergence
rate of ZO-signSGD in Theorem 1.

Theorem 1 Under A1 and A2, if we randomly pick xR from {xk}Tk=-01 with probability P (R = k) =

k
T -1 k=0

k

,

then

the

convergence

rate of 

ZO-signSGD

is

given

by

E [ f (xR) 2] 

2(f (x0) - f  +





T -1 k=0

k

µ2L)

+

dL 2

T -1 k=0

k2

T -1 k=0

k

+

µLd 2

2 +

2

d

4b(q

+

1)2 

+

C (d,

µ)(2b

+

b)

,

(8)

bq

where f  denotes the minimum value.

Proof: See Appendix 3.

In Theorem 1, we translate the norm of the gradient from 1 to 2 based on x 2  x 1 for any x. Note that a probabilistic output xR is adopted in Theorem 1, proposed by (Ghadimi & Lan, 2013; Lei et al., 2017), in order to avoid exhaustive search over {xk} for mink f (xk) 2. We finally remark that the convergence rate of ZO-signSGD relies on the learning rate k, the problem size d, the smoothing parameter µ, the mini-batch size b, and the number of random perturbations q for ZO

gradient estimation. In order to acquire explicit dependence on these parameters, we next investigate

several special cases covered in Theorem 1.



If


k

=



=

O( 1
dT

)

and

µ

=

O( 1
dT

),

then

the

convergence

given

by

(8)

simplifies

to

O( d
T

+

d

b

q+(b bq

+b

)d

),

where

we

have

used

the

fact

that,

in

this

case,

we

have

C(d, µ) =


2d2


+

dL2 2T

.

According

to

(7),

ZO-signSGD

using

mini-batch

samples

with

replacement

yields

O(

d T

+

d b

+

d bq

)

convergence rate, while the rate under mini-batch without replacement remains the same at b  [1, n),

but

it

is

improved

to

O( d
T

+

d nq

)

at

b

=

n

(corresponding

to

the

batch

version

of

ZO-signSGD).

In

5

Under review as a conference paper at ICLR 2019



the

latter

case,

if

we

choose

q

=

O(

dT n

),

then

we

obtain

O(

d T

)

convergence

rate,

whose

optimality

was proved under the framework of ZO mirror descent (Duchi et al., 2015). Here the choice of

making the number of random direction samples q proportional to T yields the variance of the ZO

gradient estimate inversely proportional to T (see Proposition 2), commonly used in ZO optimization

for variance reduction. Furthermore, similar to signSGD, if we assume b = O(T ) and q = O(d), we

can also obtain O( d ) convergence rate in the case of mini-batch with replacement. Instead of using

T

a

constant

learning

rate,

if

we

choose

the

decaying

rate

k

=

1 dk

(with

0

=

1

=

1 ),
d

it

is

not

difficult to show that the aforementioned rates also hold.

5 VARIANTS OF ZO-SIGNSGD

Here we study two variants of ZO-signSGD, where the gradient will be estimated using a) the central

difference of function values or b) the signs of ZO gradient estimates with majority vote. That is,

a) GradEstimate(x) = 1

q d[fi(x + µui,j ) - fi(x - µui,j )]ui,j

bq 2µ

iIk j=1

(9)

1 b) GradEstimate(x) =
bq

q
sign ^ fi(x; ui,j ) ,

iIk j=1

(10)

where {ui,j} and ^ fi(x; ui,j) have been defined in (3).

The ZO gradient estimator (9) was used in (Shamir, 2017) for bandit convex optimization. Compared to the form of forward difference (3), the central difference (9) requires b(q - 1) times more function queries in gradient estimation. At the cost of more function queries, one may wonder if the convergence rate of ZO-signSGD can be further improved. We answer this question in Corollary 1, and verify the obtained theoretical results through a toy example of sparse noise perturbation (Fig. A1 in Appendix 4), which was first considered by (Bernstein et al., 2018).

Corollary 1 Suppose that the conditions in Theorem 1 hold, ZO-signSGD with gradient estimator (9) yields the same convergence rate of ZO-signSGD that uses the estimator (3).

Proof: Recall that Proposition 1 is independent of specific forms of gradient estimators, and thus holds for (9). Although Proposition 2 relies on the second-order moments of each gradient estimator, we prove that under A1 and A2, both (3) and (9) maintain the same statistical properties. As a result, Proposition 2 and Theorem 1 also hold for (9); see more details in Appendix 5.

We next study the gradient estimator (10), whose sign is equivalent to the majority vote (i.e., the element-wise median) of signs of individual gradient estimates {^ fi(x; ui,j)}. It was shown in (Bernstein et al., 2018) that signSGD with majority vote has a better convergence rate under additional
assumptions of unimodal symmetric noise distribution of coordinate-wise gradient estimates. In
Corollary 2, we show that such a speed-up in convergence can also be achieved by ZO-signSGD with
majority vote, which we refer to as "ZO-M-signSGD".

Corollary 2 Suppose that the conditions in Theorem 1 hold, and the distribution of gradient noise is

unimodal

and

symmetric.

Then,

ZO-M-signSGD

with

k

=

O( 1
dT

)

and

µ

=

O( 1
dT

)

yields



E [ f (xR) 2] = O d/ T + d/ bq .

(11)

Proof: See Appendix 6.

We recall from Theorem 1 that under the same parameter setting of Corollary 2, ZO-signSGD

yields

O( d
T

+

d b

+

d bq

)

convergence

rate in

the

worst

case.

It is

clear

from (11)

that the

error

correction term of order d is eliminated in ZO-M-signSGD. Such an improvement in convergence

b

is achieved under the condition of unimodal symmetric gradient noise. We remark that different from

the stochastic gradient noise studied in (Bernstein et al., 2018), the ZO gradient estimation noise

could violate this assumption. For example, in a scalar case, if the gradient estimate g follows the

distribution where g = 1 with probability 0.9, g = -10 with probability 0.1, then E[g] < 0 and

sign(E[g]) < 0. However, E[sign(g)] > 0. This implies that without the assumption of symmetry,

the sign of gradient estimates with majority vote (E[sign(g)]) can be in the opposite direction of the

sign of averaged gradients (sign(E[g])). Our experimental results in the next section show that the

empirical convergence of ZO-M-signSGD could be worse than that of ZO-signSGD.

6

Under review as a conference paper at ICLR 2019

(a) (b) (c)

(d) (e) (f)
Figure 1: Performance comparison of ZO-signSGD, ZO-M-signSGD, ZO-SGD, ZO-SCD, signSGD and SGD under a synthetic dataset. The solid line represents the loss/accuracy averaged over 10 independent trials with random initialization, and the shaded region indicates the standard deviation of results over random trials. (a)-(b): Training loss and test accuracy versus iterations. (c)-(d): Effects of mini-batch size q and number of random direction vectors q on the convergence of studied algorithms. Here (c) presents the training loss versus iterations, and (d) is the heat map of the final loss for different values of b and q. (e)-(f): Effects of problem size d. Here (e) shows the final training loss versus d, and (f) presents the convergence trajectory when d  {200, 400}.

6 EXPERIMENTS

In this section, we empirically show the effectiveness of ZO-signSGD, and validate its convergence behavior on both synthetic and real-world datasets such as MNIST and CIFAR-10. For the synthetic experiment, we study the problem of binary classification in the least squared formulation. For the real-world application, we design adversarial examples from black-box neural networks as mentioned in Sec. 2. Throughout this section, we compare ZO-signSGD and its variants with SGD, signSGD (Bernstein et al., 2018), ZO-SGD (Ghadimi & Lan, 2013), and ZO-SCD (Lian et al., 2016).

Binary classification

We

consider

the

least

squared

problem

of

the

form

minxRd

1 n

n i=1

(yi

-

1/(1 + e-aTi x))2. For generating the synthetic dataset, we randomly draw samples {ai} from

N (0, I), and obtain the label yi = 1 if 1/(1 + e-aiT x) > 0.5 and 0 otherwise. The number of

training samples {ai, yi} is set by n = 2000 against 200 testing samples. We find the best constant

learning rate for algorithms via a greedy search over   [0.001, 0.1] (see Appendix 7.1 for more

details), and we choose the smoothing parameter µ = 10/ T d. Unless specified otherwise, let

b = q = 10, T = 5000 and d = 100. In Fig. 1, we report the training loss, the test accuracy, as well

as the effects of algorithmic parameters on the convergence of the studied algorithms. We observe

from Fig. 1-(a) and (b) that ZO-signSGD outperforms other ZO algorithms, and signSGD yields the

best convergence performance once the first-order information is available. In Fig. 1-(c) and (d), we

observe that the convergence performance of ZO algorithms is improved as b and q increase. In

particular, ZO-signSGD and ZO-M-signSGD at b = q = 30 approach to the best result provided

by signSGD. In Fig. 1-(e) and (f), the convergence of all algorithms degrades as the problem size d

increases. However, ZO-signSGD and ZO-M-signSGD converge faster than ZO-SGD and ZO-SCD.

Generating black-box adversarial examples Here we study adversarial robustness by generating adversarial examples from a black-box image classifier trained by a deep neural network (DNN) model; see details on problem formulation in Appendix 7.2. We recall from Sec. 2 that the task of black-box adversarial attack falls within the category of ZO optimization as one can only access to the input-output relation of the DNN while crafting adversarial examples.

7

Under review as a conference paper at ICLR 2019

(a) MNIST ­ ID 2

(b) MNIST ­ ID 34

(c) CIFAR-10 ­ ID 6 (d) CIFAR-10 ­ ID 10

Figure 2: Black-box attacking loss versus iterations. The solid marker indicates the iteration number that finds the first successful adversarial example, and its loss corresponds to the squared 2 distortion. For each attack method, one iteration requires q + 1 model queries by using the ZO gradient estimator (3), where we set q = 10.

Table 1: Iteration comparison of attacking black-box DNN on MNIST (image ID 2).

Iteration

0 40 80 120 160 200 240 280 312 356

ZO-SGD

Classified as 1 1 1 1 1 1 1 1 4 4

Iteration

0 40 80 120 145 202 240 280 320 359

ZO-signSGD

Classified as 1 1 1 1 4 4 4 4 4 4

Iteration

0 40 80 120 142 200 240 279 320 360

ZO-M-signSGD Classified as 1 1 1 1 4 4 4 4 4 4

The DNN models trained on MNIST and CIFAR-10 (Carlini & Wagner, 2017) are performed as the zeroth-order oracle3. We select one image from each class of MNIST and CIFAR-10 and separately implement black-box attacks using the same attacking loss function (see Appendix 7.2) but with different ZO optimization algorithms (ZO-SGD, ZO-signSGD, and ZO-M-signSGD). We also set the same parameters for each method, i.e., µ = 0.01, q = 10, and  = 0.05 for MNIST and  = 0.0005 for CIFAR-10, to accommodate to the dimension factor d. All methods use the the same natural image as the initial point for finding adversarial examples.
Fig. 2 shows the plots of black-box attacking loss versus iterations (more results are shown in Appendix 7.3). We find that ZO-signSGD usually takes significantly less iterations than other methods to find the first successful adversarial example with a similar attacking loss. For MNIST, the average iteration to find the first successful adversarial example is 184 for ZO-SGD, 103 for ZO-signSGD, and 151 for ZO-M-signSGD. Their corresponding average 2 distortion is 2.345 for ZO-SGD, 2.381 for ZO-signSGD, and 2.418 for ZO-M-signSGD. For CIFAR-10, the average iteration to find the first successful adversarial example is 302 for ZO-SGD, 250 for ZO-signSGD, and 389 for ZO-M-signSGD. Their corresponding average 2 distortion is 0.177 for ZO-SGD, 0.208 for ZO-signSGD, and 0.219 for ZO-M-signSGD. As a visual illustration, we compare the adversarial examples of a hand-written digit "1" of each attacking method at different iterations in Table 1, corresponding to Fig. 2-(a). As we can see, ZO-signSGD and ZO-M-signSGD can reduce roughly 54% of iterations (around 600 less model queries) than ZO-SGD to find the first successful adversarial example with a similar 2 distortion. Note that the first successful adversarial examples are visually similar to the original ones but lead to different top-1 predictions; see more results in Appendix 7.3. Clearly, ZO-signSGD offers a provable and an efficient black-box adversarial attacking method.
7 CONCLUSION
Motivated by the impressive convergence behavior of (first-order) signSGD and the empirical success in crafting adversarial examples from black-box ML models, in this paper we rigorously prove the O( d/ T ) convergence rate of ZO-signSGD and its variants under mild conditions. Compared to signSGD, ZO-signSGD suffers a slowdown (proportional to the problem size d) in convergence rate, however, it enjoys the gradient-free advantages. Compared to other ZO algorithms, we corroborate the superior performance of ZO-signSGD on both synthetic and real-word datasets, particularly for its application to black-box adversarial attacks. In the future, we would like to generalize our analysis to nonsmooth and nonconvex constrained optimization problems.
3https://github.com/carlini/nn_robust_attacks

8

Under review as a conference paper at ICLR 2019
REFERENCES
A. Athalye, N. Carlini, and D. Wagner. Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples. arXiv preprint arXiv:1802.00420, 2018.
L. Balles and P. Hennig. Dissecting adam: The sign, magnitude and variance of stochastic gradients. arXiv preprint arXiv:1705.07774, 2017.
J. Bernstein, Y.-X. Wang, K. Azizzadenesheli, and A. Anandkumar. signsgd: compressed optimisation for non-convex problems. arXiv preprint arXiv:1802.04434, 2018.
A. N. Bhagoji, W. He, B. Li, and D. Song. Practical black-box attacks on deep neural networks using efficient query mechanisms. In Proceedings of the European Conference on Computer Vision (ECCV), pp. 154­169, 2018.
N. Carlini and D. Wagner. Towards evaluating the robustness of neural networks. In IEEE Symposium on Security and Privacy, pp. 39­57, 2017.
P.-Y. Chen, H. Zhang, Y. Sharma, J. Yi, and C.-J. Hsieh. Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models. In Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pp. 15­26. ACM, 2017.
X. Chen, S. Liu, R. Sun, and M. Hong. On the convergence of a class of adam-type algorithms for non-convex optimization. arXiv preprint arXiv:1808.02941, 2018.
M. Cheng, T. Le, P.-Y. Chen, J. Yi, H. Zhang, and C.-J. Hsieh. Query-efficient hard-label black-box attack: An optimization-based approach. arXiv preprint arXiv:1807.04457, 2018.
J. C. Duchi, P. L. Bartlett, and M. J. Wainwright. Randomized smoothing for stochastic optimization. SIAM Journal on Optimization, 22(2):674­701, 2012.
J. C. Duchi, M. I. Jordan, M. J. Wainwright, and A. Wibisono. Optimal rates for zero-order convex optimization: The power of two function evaluations. IEEE Transactions on Information Theory, 61(5):2788­2806, 2015.
X. Gao, B. Jiang, and S. Zhang. On the information-adaptive variants of the ADMM: an iteration complexity perspective. Optimization Online, 12, 2014.
S. Ghadimi and G. Lan. Stochastic first-and zeroth-order methods for nonconvex stochastic programming. SIAM Journal on Optimization, 23(4):2341­2368, 2013.
S. Ghadimi, G. Lan, and H. Zhang. Mini-batch stochastic approximation methods for nonconvex stochastic composite optimization. Mathematical Programming, 155(1-2):267­305, 2016.
I. Goodfellow, J. Shlens, and C. Szegedy. Explaining and harnessing adversarial examples. 2015 ICLR, arXiv preprint arXiv:1412.6572, 2015.
B. Gu, Z. Huo, and H. Huang. Zeroth-order asynchronous doubly stochastic algorithm with variance reduction. arXiv preprint arXiv:1612.01425, 2016.
D. Hajinezhad, M. Hong, and A. Garcia. Zenith: A zeroth-order distributed algorithm for multi-agent nonconvex optimization. 2017.
A. Ilyas, L. Engstrom, A. Athalye, and J. Lin. Black-box adversarial attacks with limited queries and information. In International Conference on Machine Learning, 2018a.
A. Ilyas, L. Engstrom, and A. Madry. Prior convictions: Black-box adversarial attacks with bandits and priors. arXiv preprint arXiv:1807.07978, 2018b.
K. G. Jamieson, R. Nowak, and B. Recht. Query complexity of derivative-free optimization. In Advances in Neural Information Processing Systems, pp. 2672­2680, 2012.
D. Kinga and J. B. Adam. A method for stochastic optimization. In International Conference on Learning Representations (ICLR), 2015.
Alexey Kurakin, Ian J. Goodfellow, and Samy Bengio. Adversarial machine learning at scale. 2017 ICLR, arXiv preprint arXiv:1611.01236, 2017. URL http://arxiv.org/abs/1611.01236.
L. Lei, C. Ju, J. Chen, and M. I. Jordan. Non-convex finite-sum optimization via scsg methods. In Advances in Neural Information Processing Systems, pp. 2345­2355, 2017.
9

Under review as a conference paper at ICLR 2019
X. Lian, H. Zhang, C.-J. Hsieh, Y. Huang, and J. Liu. A comprehensive linear speedup analysis for asynchronous stochastic parallel optimization from zeroth-order to first-order. In Advances in Neural Information Processing Systems, pp. 3054­3062, 2016.
L. Liu, M. Cheng, C.-J. Hsieh, and D. Tao. Stochastic zeroth-order optimization via variance reduction method. arXiv preprint arXiv:1805.11811, 2018a.
S. Liu, J. Chen, P.-Y. Chen, and A. O. Hero. Zeroth-order online ADMM: Convergence analysis and applications. In Proceedings of the Twenty-First International Conference on Artificial Intelligence and Statistics, volume 84, pp. 288­297, April 2018b.
S. Liu, B. Kailkhura, P.-Y. Chen, P. Ting, S. Chang, and L. Amini. Zeroth-order stochastic variance reduction for nonconvex optimization. arXiv preprint arXiv:1805.10367, 2018c.
Y. Liu, X. Chen, C. Liu, and D. Song. Delving into transferable adversarial examples and black-box attacks. ICLR, arXiv preprint arXiv:1611.02770, 2017.
A. Madry, A. Makelov, L. Schmidt, D. Tsipras, and A. Vladu. Towards deep learning models resistant to adversarial attacks. ICLR, 2018.
Y. Nesterov and V. Spokoiny. Random gradient-free minimization of convex functions. Foundations of Computational Mathematics, 2(17):527­566, 2015.
N. Papernot, P. McDaniel, S. Jha, M. Fredrikson, Z. B. Celik, and A. Swami. The limitations of deep learning in adversarial settings. In Security and Privacy (EuroS&P), 2016 IEEE European Symposium on, pp. 372­387. IEEE, 2016.
N. Papernot, P. McDaniel, I. Goodfellow, S. Jha, Z. B. Celik, and A. Swami. Practical black-box attacks against machine learning. In Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, pp. 506­519. ACM, 2017.
S. J. Reddi, S. Kale, and S. Kumar. On the convergence of adam and beyond. In International Conference on Learning Representations, 2018.
U. Shaham, Y. Yamada, and S. Negahban. Understanding adversarial training: Increasing local stability of supervised models through robust optimization. Neurocomputing, 2018.
O. Shamir. An optimal algorithm for bandit and zero-order convex optimization with two-point feedback. Journal of Machine Learning Research, 18(52):1­11, 2017.
C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow, and R. Fergus. Intriguing properties of neural networks. arXiv preprint arXiv:1312.6199, 2013.
C.-C. Tu, P. Ting, P.-Y. Chen, S. Liu, H. Zhang, J. Yi, C.-J. Hsieh, and S.-M. Cheng. Autozoom: Autoencoder-based zeroth order optimization method for attacking black-box neural networks. arXiv preprint arXiv:1805.11770, 2018.
Y. Wang, S. Du, S. Balakrishnan, and A. Singh. Stochastic zeroth-order optimization in high dimensions. In Proceedings of the Twenty-First International Conference on Artificial Intelligence and Statistics, volume 84, pp. 1356­1365. PMLR, April 2018.
10

Under review as a conference paper at ICLR 2019

APPENDIX

1 PROOF OF PROPOSITION 1

Based on the definition of the smoothing function fµ, for any x and y we have

fµ(x) - fµ(y) 2 = Ev[xf (x + µv) - yf (y + µv)] 2 E[ xf (x + µv) - yf (y + µv) 2]  L x - y 2,

(12)

where the first inequality holds due to Jensen's inequality, and the second inequality holds due to A1. It is known from (12) that fµ has L-Lipschitz continuous gradient.

By the L-smoothness of fµ, we obtain that

fµ(xk+1) fµ(xk) +

fµ(xk), xk+1 - xk

+L 2

xk+1 - xk

2 2

(=2)fµ(xk) - k

fµ(xk), sign(g^k)

+

L 2

k2

sign(g^k )

2 2

=fµ(xk) - k

fµ (xk )

1

+

k2 dL 2

d

+ 2k |(fµ(xk))i|I [sign(g^k,i) = sign((fµ(xk))i)] ,

i=1

(13)

where (fµ(x))i denotes the ith element of fµ(x).

Taking expectation for both sides of (13), we obtain that

E[fµ(xk+1) - fµ(xk)]  - k

fµ (xk )

1

+

k2 dL 2

d

+ 2k |(fµ(xk))i|Prob [sign(g^k,i) = sign((fµ(xk))i)] .

i=1

(14)

Similar to (Bernstein et al., 2018, Theorem 1), we relax Prob [sign(g^k,i) = sign((fµ(xk))i)] by Markov's inequality,

Prob [sign(g^k,i) = sign((fµ(xk))i)] Prob[|g^k,i - (fµ(xk))i|  |(fµ(xk))i|]  E[|g^k,i - (fµ(xk))i|] . |(fµ (xk ))i |

(15)

Substituting (15) into (14), we obtain

E[fµ(xk+1) - fµ(xk)]  - k

fµ (xk )

1

+

k2 dL 2

+

2k

d

E[|g^k,i - (fµ(xk))i|]

i=1

= - k

fµ (xk )

1

+

k2 dL 2

+

2k E[

g^k - fµ(xk)

1]

 - k

fµ (xk )

1

+

k2 dL 2

+

 2k dE[

g^k - fµ(xk)

2]

 - k

fµ (xk )

1

+

k2 dL 2

+

 2k d

E[

g^k - fµ(xk)

2 2

],



(16)

where the second inequality holds due to x 1  d x 2, and the last inequality holds by applying Jensen's

inequality to the concave function ·, i.e., E[ g^k - fµ(xk) 2] 

E[

g^k - fµ(xk)

2 2

].

Taking sum of both sides of (16), we then obtain (5).

2 PROOF OF PROPOSITION 2

We recall from (3) that

1 g^k = b

^ fi(xk),

^ fi(xk)

=

1 q

q

^ fi(xk; ui,j ).

iIk

j=1

(17)

11

Under review as a conference paper at ICLR 2019

Let zi := ^ fi(xk) - fµ(xk) and zi,j = ^ fi(xk; ui,j ) - fµ(xk). Thus,

g^k

-

fµ (xk )

=

1 b

1 zi = bq

q
zi,j

iIk

iIk j=1

(18)

where there are two sources of randomness: a) minibatch sampling i  Ik, and b) the random direction sampling u = ui,j. Note that these two sources of randomness are independent, and the random direction samples {ui,j} are i.i.d..
Next, we discuss two types of mini-batch sampling: a) mini-batch samples without replacement, and b) minibatch samples with replacement.
Suppose that Ik is a uniform random subset of [n] (no replacement), motivated by (Lei et al., 2017, Lemma A.1) we introduce a new variable Wi = I(i  Ik), where I is an indicator function, and I(i  Ik) = 1 if i  Ik, and 0 otherwise. As a result, we have

E[Wi2]

=

E[Wi]

=

b, n

b(b - 1) E[WiWj] = n(n - 1) , i = j.

(19)

From (18), the variance of g^k is given by

 2 



1 E b

zi

1n  = b2 

EiIk [Wi2]Eu[ zi

2 2

]

+

Ei,jIk [WiWj ] Eu[zi], Eu[zj ] 

iIk

2

i=1

i=j

1 = b2

b n

n

Eu[

zi

22 ]

+

b(b - 1) n(n - 1)

n

2

Eu[zi]

-

b(b - 1) n(n - 1)

n

Eu[zi]

2 2

i=1

i=1

2

i=1

(=a) 1 bn

n

Eu[

zi

2 2

]

-

b b(n

- -

1 1)n

n

Eu[zi]

2 2

i=1

i=1

=1 bn

n

Eu[

zi

2 2

]

-

b b(n

- -

1 1)n

n

Eu[

zi

2 2

]

+

b b(n

- -

1 1)n

n

Eu[ zi

22] -

Eu[zi]

2 2

i=1

i=1

i=1

(=b)

n (n

- -

b 1)

1 bn

n

Eu[

zi

2 2

]

+

b b(n

- -

1 1)n

n

Eu[ ^ fi(xk) - fi,µ(xk) 22].

i=1 i=1

(20)

In

(20), the

equality (a) holds since Eu[zi]

=

fi,µ(xk) - fµ(xk) and

fµ(x)

=

1 n

n i=1

fi,µ(x)

from

(4),

where we have used the fact that Eu[^ fi(xk)] = ^ fi,µ(xk) (Liu et al., 2018c, Lemma. 1), and recall that fi,µ

denotes the smoothing function of fi. The above implies that

n i=1

Eu[zi]

=

i fi,µ(xk) - nfµ(xk) = 0.

And the equality (b) holds due to Eu[ zi

2 2

]

-

Eu[zi]

2 2

= Eu

zi - Eu[zi]

2 2

.

On the other hand, suppose that the mini-batch Ik contains i.i.d. samples (namely, with replacement), the vectors {zi} are then i.i.d. under both mini-batch sampling and random direction sampling. Therefore, we obtain that



2  





1 E b

1 zi  = b2 E 

zi

2
2

+

E



zi, zj 

iIk

2

iIk

i=j,i,jIk

1 = b Eu[EiIk [

zi

2 2

]]

=

1 bn

n

Eu[ zi 22],

i=1

(21)

where

the

second

equality

holds

since

EiIk ,u [zi ]

=

1 n

Combining both (20) and (21), we obtain that

n i=1

Eu[zi]

=

1 n

n i=1

fi,µ (xk )

-

fµ (xk )

=

0.

 2

1 E b

zi





b bn

n

Eu[

zi

2 2

]

+

b bn

n

Eu[

^ fi(xk) - fi,µ(xk)

2 2

].

iIk

2

i=1

i=1

(22)

In (22), b = 1 and b = 0 if the mini-batch contains i.i.d. samples from [n] with replacement, and b = I(b < n) and b = I(b > 1) if samples are randomly selected without replacement.

12

Under review as a conference paper at ICLR 2019

In

(22),

we

next

bound

1 n

i Eu[ zi 22],

1 n

n

Eu[

zi

2 2

]

(1=8) 1 n

n

Eu

i=1 i=1

1q

2
1

q zi,j = nq2

j=1

2





Eu[

zi,j

2 2

]

+

Eu[zi,j ], Eu[zi,k] 

ij

j=k

1 =
nq2

qEu[

zi,1

2 2

]

+

(q2

-

q)

Eu[zi,1]

2 2

i

=1 qn

Eu[

zi,1

22 ]

+

q-1 qn

ii

Eu[zi,1] 22,

(23)

where we have used the facts that Eu[zi,j ] = Eu[zi,1] and Eu[

zi,j

2 2

]

=

Eu[

zi,1

2 2

]

for

any

j

since

random

direction vectors {ui,j}qj=1 are i.i.d. samples.

In (23), we further bound i Eu[ zi,1 22],

1 n

Eu[

zi,1

2 2

]

=

1 n

Eu

^ fi(xk; ui,1) - fµ(xk)

2 2

ii

=1 n

Eu[

^ fi - fi,µ + fi,µ - fµ

2 2

]

i

2 n

Eu[

^ fi - fi,µ

22 ]

+

2 n

fi,µ - fµ 22,

ii

(24)

where for ease of notation, let ^ fi := ^ fi(xk; ui,1), ^ fi,µ := ^ fi,µ(xk) and fµ := fµ(xk). According to (Liu et al., 2018c, Lemma 1), the first term at RHS of (24) yields

Eu[

^ fi - fi,µ

2 2

]



2d

fi

2 2

+

µ2L2d2 2

 2d2 + µ2L2d2 2

:= C(d, µ),

(25)

where the last inequality holds due to A2. Based on the definition of fµ, the second term at RHS of (24) yields

1 n

fi,µ - fµ

2 2

=1 n

Ev[fi(xk + µv) - f (xk + µv)]

2 2

ii

1 n

Ev [

fi(xk + µv) - f (xk + µv)

2 2

]



42,

i

(26)

where

we

have

used

the

Jensen's

inequality

and

1 n

n i=1

fi(x) - f (x)

2 2

 42 under A2.

Substituting (25) and (26) into (24), we have

1 n

Eu[

zi,1

2 2

]

=

1 n

Eu[ ^ fi - fµ 22]  4d2 + µ2L2d2 + 82 = 2C(d, µ) + 82,

ii

where C(d, µ) was defined in (25).

(27)

We

are

now

ready

to

bound

(23).

Based

on

1 n

i

Eu[zi,1]

2 2

=

1 n

i

fi,µ - fµ

2 2



42

from

(26),

and

substituting (27) into (23), we obtain that

1 n

Eu[

zi

2 2

]



2C(d, µ) + 82 q

4(q - 1)2 +.
q

i

(28)

In (22), we also need to bound Eu[ ^ fi(xk) - fi,µ(xk) 22]



Eu

^ fi(xk) - fi,µ(xk) 2 2

(1=7) Eu 

1 q

q

j=1

^ fi(x; ui,j ) - fi,µ(x)

2 
2

(=a)

1 q

Eu

^ fi(x; ui,1) - fi,µ(x) 2
2

(25)


1

q

2d2 + µ2L2d2 2

C(d, µ) =,
q

(29)

where the equality (a) holds since Eu[^ fi(x; ui,j)] = fi,µ(x) for any j, given by (Liu et al., 2018c, Lemma 1).

Substituting (28) and (29) into (22)

 2

E

g^k - fµ(xk)

2 2

= E

1 b

zi



 b b

2C(d, µ)

+ 42 q

+

42q

+

bC(d, µ) bq

iIk

2

= 4b(q + bq

1) 2

+

C(d, µ) bq (2b

+

b).

(30)

13

Under review as a conference paper at ICLR 2019

3 PROOF OF THEOREM 1

Substituting (6) into (5), we obtain

T -1

T -1

E k fµ(xk) 1 E[fµ(x0) - fµ(xT )] +

k=0

k=0



2k

d bq

4b(q + 1)2 + C(d, µ)(2b + b)

+

dL 2

T -1
k2 .

k=0

(31)

It is known from (Liu et al., 2018c, Lemma 1) that

f (x)

2 2



2

fµ(x)

2 2

+

µ2L2d2 2

,

|fµ(x) - f (x)|



µ2L .
2

(32)

From (32) we have fµ(x0)-f (x0)



µ2 L 2

and f  -fµ



µ2 L 2

,

where

fµ

=

minx fµ(x) and f 

=

minx f (x).

This yields fµ(x0) - f (x0) + f  - fµ  µ2L, and thus

fµ(x0) - fµ(xT )  fµ(x0) - fµ  (f (x0) - f ) + µ2L.

(33)

Substituting (33) into (31), we obtain

T -1
E k fµ(xk) 1 E[f (x0) - f )] + µ2L

k=0

T -1
+



2k

d bq

4b(q + 1)2 + C(d, µ)(2b + b)

+

dL 2

T -1
k2 .

(34)

k=0

k=0

Due to fµ(xk) 2  fµ(xk) 1 and dividing

T -1 k=0

k

for

both

sides

of

(34),

we

obtain

that

T -1
E
k=0

k

T -1 k=0

k

fµ(xk) 2



 f (x0)

- f +

T -1 k=0

k

µ2L

+

2 d bq

4b(q + 1)2 + C(d, µ)(2b + b)

+ dL 2

T -1 k=0 T -1 k=0

k2 k

.

(35)

By introducing the random variable R with probability P (R = k) =

k T -1 k=0

k

,

we

then

obtain

that

T -1

E [ fµ(xR) 2] = E [ER[ fµ(xR) 2]] = E

P (R = k) fµ(xk) 2 .

(36)

k=0

Based on (32), we further have

E [ f (xR) 2] E

2

fµ(xR)

2 2

+

µ2L2d2 2

  2E[

fµ(xR)

2] +

µLd ,

2



where we have used the fact that a2 + b2  (a + b) for a, b  0.

(37)

Substituting (35) and (36) into (37), we finally obtain (8).

4 EXAMPLE OF SPARSE NOISE PERTURBATION

We

consider

to

minimize

the

function

f (x)

=

1 2

x

2 2

.

Similar

to

(Bernstein

et

al.,

2018,

Figure

A.1),

we

assume

that the ZO gradient estimate of f (x) and its first-order gradient f (x) = x suffer from a sparse noise vector v,

where v1  N (0, 1002), and vi = 0 for i  2. As a result, the used descent direction at iteration t is given by

^ f (xt) + v or f (xt) + v. Fig. A1 presents the convergence performance of 5 algorithms: SGD, signSGD,

ZO-SGD, ZO-signSGD and ZO-signSGD with gradient estimator (9) that uses the central difference of two

function values. Here we tune a constant learning rate finding 0.001 best for SGD and ZO-SGD and 0.01 best

for signSGD and its ZO variants. As we can see, sign-based first-order and zeroth-order algorithms converge

much faster than the full gradient-based descent algorithms. This is not surprising since the noise v1 leads to

an inaccurate gradient value, and thus degrades the convergence of SGD and ZO-SGD. By contrast, the sign

information is more robust to outlier and thus leads to better convergence performance of sign SGD and its

variants. We also note that the convergence trajectory of ZO-signSGD using the gradient estimator (9) coincides

with that using the gradient estimator (3), defined by the forward difference of two function values.

14

Under review as a conference paper at ICLR 2019

Figure A1: Comparison of different gradient-based and gradient sign-based first-order and zeroth-order algorithms in the example of sparse noise perturbation. The solid line represents the loss averaged over 10 independent trials with random initialization, and the shaded region indicates the standard deviation of results over random trials. Left: Loss value against iterations for SGD, signSGD, ZO-SGD, ZO-signSGD and ZOsignSGD using the gradient estimator (9). Right: Local region to highlight the effect of the gradient estimators (3) and (9) on the convergence of ZO-signSGD.

5 PROOF OF COROLLARY 1

Upon

defining

~ fi(x; u)

=

d[fi (x+µu)-fi (x-µu)]u 2µ

(against

^ fi(x; u)

in

(3)),

our

major

task

is

to

derive

the

first- and second-order moments of ~ fi(x; u).

Given x, we first study the mean of ~ fi(x; u),

Eu ~ fi(x; u)

= Eu

d 2µ

(fi

(x

+

µu)

-

fi

(x

-

µu))u

=Eu

d 2µ fi(x + µu)u

+ Eu

d 2µ

fi

(x

-

µu)(-u)

(=a) Eu

d µ fi(x + µu)u

(=b)Eu

d µ

(fi(x

+

µu)

-

fi(x))

u

= Eu

^ fi(x; u)

(=c) fi,µ(x),

(38)

where (a) holds since the distribution of u is symmetric around the origin, (b) holds since E[u] = 0, and (c)

holds since fi,µ(x) = Eu

d µ

fi

(x

+

µu)u

obtained from (Gao et al., 2014, Lemma 4.1). It is clear from

(38) that Eu ~ fi(x; u) = Eu ^ fi(x; u) .

We next study the second-order moment of ~ fi(x; u),

Eu

^ fi(x; u) 2

d2 = 4µ2 Eu

(fi(x + µu) - fi(x - µu))2

u

2



d2 2µ2

Eu

(fi(x + µu) - fi(x))2 + (fi(x) - fi(x - µu))2

=Eu

d µ

(fi(x

+

µu)

-

fi(x))u

2

= Eu

~ fi(x; u) 2 ,

(39)

where we have used the fact that u 2 = 1.
Based on (38) and (39), we can conclude that both (3) and (9) maintain the same statistical properties. Following the proofs of Proposition 2 and Theorem 1, it is not difficult to reach the convergence rate in (8).

6 PROOF OF COROLLARY 2
Let g^ki,j := ^ fi(xk; ui,j ). If we replace g^k with g^ki,j in (15), we then have |(fµ(xk))l| Prob sign(g^ki,,jl) = sign((fµ(xk))l) E[|g^ki,,jl - (fµ(xk))l|],

(40)

15

Under review as a conference paper at ICLR 2019

where g^ki,,jl is the lth coordinate of g^ki,j .
By letting b = 1 and q = 1 in Proposition 2, we know that E by Jensen's inequality we have

g^ki,j - fµ(xk)

2 2

is upper bounded. Moreover,

E[|g^ki,,jl - (fµ(xk))l|]  E[(g^ki,,jl - (fµ(xk))l)2] := l,

where l is finite since E

g^ki,j - fµ(xk)

2 2

is upper bounded.

Substituting (41) into (40), we have

(41)

|(fµ(xk))l| Prob sign(g^ki,,jl) = sign((fµ(xk))l) l.

(42)

With the new gradient estimate g¯k =

iIk

q j=1

sign(g^ki,j

)

in

(10),

we

require

to

bound

Prob [sign(g¯k,l) = sign((fµ(xk))l)] ,

(43)

where g¯k,l is the lth coordinate of g¯k.

We recall that g^ki,,jl is an unbiased stochastic approximation to gradient component (fµ(xk))l with variance l2. Under the assumption that the noise distribution is unimodal and symmetric, we know from (Bernstein et al.,
2018, Lemma D1) that

Prob sign(g^ki,,jl) = sign((fµ(xk))l := Q 

21

9 S2

1 2

-

S 23

S > 2 3
otherwise

< 1, 2

(44)

where S := |(fµ(xk))l|/l.
Let Z count the number of estimates {g^ki,,jl} yielding the correct sign of ((fµ(xk))l. Thus, the probability of error in (43) is equal to

Prob [sign(g¯k,l) = sign((fµ(xk))l)] = Prob

Z  bq 2

.

(45)

Following the proof of (Bernstein et al., 2018, Theorem 2b) under (44), it is not difficult to obtain that

Prob Z  bq   1 . 2 bqS

That is,

|(fµ(xk))l| Prob [sign(g¯k,l)

=

sign((fµ (xk ))l )]



l . bq

(46) (47)

Replace g^k with g¯k in (14), we obtain that

E[fµ(xk+1) - fµ(xk)]  - k

fµ (xk )

1

+

k2 dL 2

d

+ 2k |(fµ(xk))l|Prob [sign(g¯k,l) = sign((fµ(xk))l)]

l=1

(47)
 - k

fµ (xk )

1

+

k2 dL 2

+

2k

1 bq



1



 - k

fµ (xk )

1

+

k2 dL 2

+

2k

d bq



2 2



(4=1) - k

fµ (xk )

1

+

k2 dL 2

+

2k

d bq

E[

g^ki,j

- fµ(xk)

2 2

].

(48)

Compared (48) with (16), the standard deviation

E[

g^ki,j - fµ(xk)



2 2

]

is

reduced

by

the

factor

1/

bq.

According to Proposition 2, let b = q = 1, we obtain

E

g^ki,j - fµ(xk)

2 2

8b2 + (2b + b)C(d, µ).

(49)

16

Under review as a conference paper at ICLR 2019

Based on (48)-(49) and following the proof of Theorem 1, we have

E[

f (xR) 

2]



 2

f (x0)

- f
T -1 k=0

+ k

µ2L

+ 2 2 d bq

8b2 + C(d, µ)(2b + b) + dL 2

where C(d, µ) := 2d2 + µ2L2d2/2.

T -1 k=0

k2

T -1 k=0

k

+

µLd , 2



If µ

=

O( 1 ) dT

and k

=

O( 1 ), then dT

the

convergence

rate simplifies to O( d T

+

d bq

).

(50)

7 SUPPLEMENTAL EXPERIMENTS

7.1 SYNTHETIC EXPERIMENTS
In Fig. A2, we demonstrate the effect of the learning rate  on the training loss of SGD, signSGD, ZO-SGD, ZO-SCD, ZO-signSGD and ZO-M-signSGD. We observe that compared to the gradient-based algorithms (SGD, ZO-SGD and ZO-SCD), the gradient sign-based algorithms support a more flexible choice of learning rates (corresponding to less variance), since the sign operation has an normalization effect to reduce oscillations in convergence. We find  = 0.1 best for SGD,  = 0.009 best for signSGD,  = 0.1 best for ZOSGD and ZOSCD,  = 0.0178 best for ZOsignSGD, and  = 0.0501 best for ZO-M-signSGD.

Figure A2: The training loss at the last iteration versus the constant learning rate   [10-3, 0.1]. Here the solid line represents the loss averaged over 10 independent trials with random initialization, and the shaded region indicates the standard deviation of results over random trials.

7.2 BLACK-BOX ATTACK FORMULATION

The target DNN classifier F = [F1, F2, . . . , FK ] takes an image as an input and produces the classification predictions (here the probability distribution) of K image classes, where Fk denotes the prediction of class k. Given F , an adversarial example x of a legitimate example x0 means it is visually similar to x0 but will yield a different top-1 prediction than x0.

Let (x0, t0) denote a legitimate image x0 and its groundtruth label t0  {1, 2, . . . , K}. Without loss of generality, we assume the pixel value range of x0 lies within [-0.5, 0.5]d. By using the tanh transformation on the adversarial image x such that x = tanh(w)/2, where w  Rd, we adopt the untargeted black-box attacking
loss designed in (Chen et al., 2017), which is defined as

minimize wRd

c

·

max{log

Ft0

(tanh(w)/2)

-

max
j=t0

log

Fj

(tanh(w)/2),

0}

+

tanh(w)/2 - x0

2 2

,

(51)

where c is a regularization coefficient and x = tanh(w)/2 ensures x lies within the valid image space [-0.5, 0.5]d. The first term in the attacking objective is a hinge loss function that penalizes the top-1 prediction of x being t0. The log F (·) operation preserves the class prediction ranking and better handles numerical stability. The second term encourages the visual similarity between x and x0 through penalizing their squared 2 difference (i.e., the squared distortion). In our experiment, we set c = 1 for MNIST and c = 0.1 for CIFAR-10.

We also note that different from the use of signed gradients in existing black-box attacks (e.g., Ilyas et al. (2018a);

Bhagoji et al. (2018)) due to the explicit  perturbation constraint, the use and benefit of ZO-signSGD for solving (51) in our experiment are non-trivial since the attacking objective does not impose any  constraint.

17

Under review as a conference paper at ICLR 2019

7.3 ADDITIONAL BLACK-BOX ATTACKING RESULTS ON MNIST AND CIFAR-10 Table A1: First successful adversarial examples attacking black-box DNN on MNIST.
Image ID 3 2 38 44 4 15 21 34 177 7 Original Classified as 0 1 2 3 4 5 6 7 8 9
ZO-SGD Classified as 6 4 1 5 9 3 5 1 0 4
ZO-signSGD Classified as 6 4 1 5 9 3 5 1 0 4
ZO-M-signSGD Classified as 6 4 1 5 9 3 5 1 0 4

Table A2: First successful adversarial examples attacking black-box DNN on CIFAR-10.

Image ID

10

6 25 68 36 33 5 17 1

28

Original Classified as airplane automobile bird cat deer dog frog horse

ship

truck

ZO-SGD Classified as

bird

truck truck dog horse cat cat dog

truck automobile

ZO-signSGD Classified as

bird

truck truck dog horse cat cat dog

truck automobile

ZO-M-signSGD Classified as

bird

truck truck dog horse cat cat dog automobile automobile

Table A3: Iteration comparison of attacking black-box DNN on MNIST (image ID 177).

Iteration

0 30 60 90 120 162 181 210 241 271

ZO-SGD

Classified as 8 8 8 8 8 0 0 0 0 0

Iteration

0 30 60 90 114 151 180 210 241 271

ZO-signSGD

Classified as 8 8 8 8 0 0 0 0 0 0

Iteration

0 30 60 90 120 150 180 198 240 271

ZO-M-signSGD Classified as 8 8 8 8 8 8 8 0 0 0

18

Under review as a conference paper at ICLR 2019

(a) MNIST ­ image ID 3

(b) MNIST ­ image ID 4

(c) MNIST ­ image ID 7

(d) MNIST ­ image ID 15

(e) MNIST ­ image ID 21

(f) MNIST ­ image ID 38

(g) MNIST ­ image ID 44

(h) MNIST ­ image ID 177

Figure A3: Additional plots of black-box attacking loss versus iteration on MNIST. The solid marker indicates the iteration number that finds the first successful adversarial example, and its loss corresponds to the squared 2 distortion. For each attack method, one iteration requires q + 1 model queries by using the ZO gradient estimator (3), where we set q = 10.

19

Under review as a conference paper at ICLR 2019

(a) CIFAR-10 ­ image ID 1

(b) CIFAR-10 ­ image ID 5

(c) CIFAR-10 ­ image ID 17

(d) CIFAR-10 ­ image ID 25

(e) CIFAR-10 ­ image ID 28

(f) CIFAR-10 ­ image ID 33

(g) CIFAR-10 ­ image ID 36

(h) CIFAR-10 ­ image ID 68

Figure A4: Additional plots of black-box attacking loss versus iteration on CIFAR-10. The solid marker indicates the iteration number that finds the first successful adversarial example, and its loss corresponds to the squared 2 distortion. For each attack method, one iteration requires q + 1 model queries by using the ZO gradient estimator (3), where we set q = 10.

20

