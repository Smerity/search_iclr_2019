Under review as a conference paper at ICLR 2019
DISCOVERY OF NATURAL LANGUAGE CONCEPTS
IN INDIVIDUAL UNITS
Anonymous authors Paper under double-blind review
ABSTRACT
Although deep convolutional networks have achieved improved performance in many natural language tasks, they have been treated as black boxes because they are difficult to interpret. Especially, little is known about how they represent language in their intermediate layers. In an attempt to understand the representations of deep convolutional networks trained on language tasks, we show that individual units are selectively responsive to specific morphemes, words, and phrases, rather than responding to arbitrary and uninterpretable patterns. In order to quantitatively analyze such intriguing phenomenon, we propose a concept alignment method based on how units respond to replicated text. We conduct analyses with different architectures on multiple datasets for classification and translation tasks and provide new insights into how deep models understand natural language.
1 INTRODUCTION
Understanding and interpreting how deep neural networks process natural language is a crucial and challenging problem. While deep neural networks have achieved state-of-the-art performances in neural machine translation (NMT) (Sutskever et al., 2014; Cho et al., 2014; Kalchbrenner et al., 2016; Vaswani et al., 2017), sentiment classification tasks (Zhang et al., 2015; Conneau et al., 2017) and many more, the sequence of non-linear transformations makes it difficult for users to make sense of any part of the whole model. Because of their lack of interpretability, deep models are often regarded as hard to debug and unreliable for deployment, not to mention that they also prevent the user from learning about how to make better decisions based on the model's outputs.
An important research direction toward interpretable deep networks is to understand what their hidden representations learn and how they encode informative factors when solving the target task. Among them, studies including Bau et al. (2017); Fong & Vedaldi (2018); Olah et al. (2017; 2018) have researched on what information is captured by individual or multiple units in visual representations learned for image recognition tasks. These studies showed that some of the individual units are selectively responsive to specific visual concepts, as opposed to getting activated in an uninterpretable manner. By analyzing individual units of deep networks, not only were they able to obtain more fine-grained insights about the representations than analyzing representations as a whole, but they were also able to find meaningful connections to various problems such as generalization of network (Morcos et al., 2018) or generating explanations for the decision of the model (Zhou et al., 2018a; Olah et al., 2018; Zhou et al., 2018b).
Since these studies of unit-level representations have mainly been conducted on models learned for computer vision-oriented tasks, little is known about the representation of models learned from natural language processing (NLP) tasks. Several studies that have previously analyzed individual units of natural language representations assumed that they align a predefined set of specific concepts, such as sentiment present in the text (Radford et al., 2017), text lengths, quotes and brackets (Karpathy et al., 2015). They discovered the emergence of certain units that selectively activate to those specific concepts. Building upon these lines of research, we consider the following question: What natural language concepts are captured by each unit in the representations learned from NLP tasks?
To answer this question, we newly propose a simple but highly effective concept alignment method that can discover which natural language concepts are aligned to each unit in the representation. Here we use the term unit to refer to each channel in convolutional representation, and natural language concepts to refer to the grammatical units of natural language that preserve meanings; i.e.
1

Under review as a conference paper at ICLR 2019

Unit 108: legal, law, legislative · Better legal protection for accident victims. · These rights are guaranteed under law. · This should be guaranteed by law. · This legislative proposal is unusual. · Animal feed must be safe for animal health.

Unit 711: should, would, not, can · That would not be democratic. · That would be cheap and it would not be right. · This is not how it should be in a democracy. · I hope that you would not want that! · Europe cannot and must not tolerate this.

Figure 1: We discover the most activated sentences and aligned concepts to the units in hidden representations of deep convolutional networks. Aligned concepts appear frequently in most activated sentences, implying that those units respond selectively to specific natural language concepts.

morphemes, words, and phrases. Our approach first identifies the most activated sentences per unit and breaks those sentences into these natural language concepts. It then aligns specific concepts to each unit by measuring activation value of replicated text that indicates how much each concept contributes to the unit activation. This method also allows us to systematically analyze the concepts carried by units in diverse settings, including depth of layers, the form of supervision, and dataspecific or task-specific dependencies.
The contributions of this work can be summarized as follows:
· We show that the units of deep CNNs learned in NLP tasks could act as a natural language concept detector. Without any additional labeled data or re-training process, we can discover, for each unit of the CNN, natural language concepts including morphemes, words and phrases that are present in the training data.
· We systematically analyze what information is captured by units in representation in multiple settings by varying network architectures, tasks, and datasets. We use VDCNN (Conneau et al., 2017) for sentiment and topic classification tasks on Yelp Reviews, AG News (Zhang et al., 2015), and DBpedia ontology dataset (Lehmann et al., 2015) and ByteNet (Kalchbrenner et al., 2016) for translation tasks on Europarl (Koehn, 2005) and News Commentary (Tiedemann, 2012) datasets.
· We also analyze how aligned natural language concepts evolve as the layer gets deeper. As part of our analysis, we show that our interpretation of learned representations could be utilized at designing network architectures with fewer parameters but with comparable performance to baseline models.
2 RELATED WORK
2.1 INTERPRETATION OF INDIVIDUAL UNITS IN DEEP MODELS
Recent work on interpreting hidden representations at unit-level were mostly motivated from their counterparts in computer vision. In computer vision community, Zhou et al. (2015) retrieved image samples with the highest unit activation, for each of units in a CNN trained on image recognition tasks. They used these retrieved samples to show that visual concepts like color, texture and object parts are aligned to specific units, and the concepts were aligned to units by human annotators. Bau et al. (2017) introduced BRODEN dataset, which consists of pixel-level segmentation labels for diverse visual concepts and then analyzed the correlation between activation of each unit and such visual concepts. In their work, although aligning concepts which absent from BRODEN dataset requires additional labeled images or human annotation, they showed that some individual units respond to specific visual concepts.
On the other hand, Erhan et al. (2009); Olah et al. (2017); Simonyan et al. (2013) discovered visual concepts aligned to each unit by optimizing a random initial image to maximize the unit activation by gradient descent. In these cases, the resulting interpretation of each unit is in the form of optimized images, and not in the natural language form as the aforementioned ones. However, these continuous interpretation results make it hard for further quantitative analyses of discrete properties of representations, such as quantifying characteristics of representations in layer-wise (Bau et al., 2017) and correlations between the interpretability of a unit and regularization (Zhou et al., 2018a). Nevertheless, these methods have the advantage that the results are not constrained to a predefined set of concepts, giving flexibility as to which concepts are captured by each unit.

2

Under review as a conference paper at ICLR 2019
In the NLP domain, studies including Karpathy et al. (2015) and Tang et al. (2017) analyzed the internal mechanisms of deep models used for NLP and found intriguing properties that appear in units of hidden representations. Among those studies, the closest one to ours is Radford et al. (2017), who defined a unit as each element in the representation of an LSTM learned for language modeling and found that the concept of sentiment was aligned to a particular unit. Compared with these previous studies, we focus on discovering a much wider variety of natural language concepts, including any morphemes, words, and phrases all found in the training data. To the best our knowledge, this is the first attempt to discover concepts among all that exist in the form of natural language from the training corpus. By extending the scope of detected concepts to meaningful building blocks of natural language, we provide insights into how various linguistic features are encoded by the hidden units of deep representations.
2.2 ANALYSIS OF DEEP REPRESENTATIONS LEARNED FOR NLP TASKS
Most previous work that analyzes the learned representation of NLP tasks focused on constructing downstream tasks that predict concepts of interest. A common approach is to measure the performance of a regression/classification model that predicts the concept of interest to see whether those concepts are encoded in representation of a input sentence. For example, Conneau et al. (2018); Adi et al. (2017); Zhu et al. (2018) proposed several probing tasks to test whether the (non-)linear regression model can predict well the syntactic or semantic information from the representation learned on translation tasks or the skip-thought or word embedding vectors. Shi et al. (2016); Belinkov et al. (2017) constructed regression tasks that predict labels such as voice, tense, part-of-speech tag, and morpheme from the encoder representation of the learned model in translation task.
Compared with previous work, our contributions can be summarized as follows. (1) By identifying the role of the individual units, rather than analyzing the representation as a whole, we provide more fine-grained understanding of how the representations encode informative factors in training data. (2) Rather than limiting the linguistic features within the representation to be discovered, we focus on covering concepts of fundamental building blocks of natural language (morphemes, words, and phrases) present in the training data, providing more flexible interpretation results without relying on a predefined set of concepts. (3) Our concept alignment method does not need any additional labeled data or re-training process, so it can always provide deterministic interpretation results using only the training data.
3 APPROACH
We focus on convolutional neural networks (CNNs), particularly their character-level variants. CNNs have shown great success on various natural language applications, including translation, language modeling, and sentence classification (Kalchbrenner et al., 2016; Kim et al., 2016; Zhang et al., 2015; Conneau et al., 2017). Compared to deep architectures based on fully connected layers, CNNs are natural candidates for unit-level analysis because their channel-level representations are reported to work as templates for detecting concepts (Bau et al., 2017).
Our approach for aligning natural language concepts to units is summarized as follows. We first train a CNN model for each natural language task and retrieve training sentences that highly activate specific units. Interestingly, we discover morphemes, words, and phrases that appear dominantly within these retrieved sentences, implying that those concepts have a significant impact on the activation value of the unit. Then, we find a set of concepts which attribute a lot to the unit activation by measuring activation value of each replicated candidate concept, and align them to unit.
3.1 THE MODEL AND THE TASK
We analyze representations learned on three classification and four translation datasets shown in Table 1. Training details for each dataset are available in Appendix B. We then focus on the representations in each encoder layer of ByteNet and convolutional layer of VDCNN, because as Mou et al. (2016) pointed out, the representation of the decoder (the output layer in the case of classification) is specialized for predicting the output of the target task rather than for learning the semantics of the input text.
3

Under review as a conference paper at ICLR 2019

Dataset AG News DBpedia Yelp Review WMT17' EN-DE WMT14' EN-FR WMT14' EN-CS EN-DE Europarl-v7

Task Ontology Classification
Topic Classification Polarity Classification
Translation Translation Translation Translation

Model VDCNN VDCNN VDCNN ByteNet ByteNet ByteNet ByteNet

# of Layers 4 4 4 15 15 15 15

# of Units [64, 128, 256, 512] [64, 128, 256, 512] [64, 128, 256, 512]
[1024] for all [1024] for all [1024] for all [1024] for all

Table 1: Datasets and model descriptions used in our analysis.

3.2 TOP K ACTIVATED SENTENCES PER UNIT
Once we train a CNN model for a given task, we feed again all sentences in the training data to the CNN and measure the activation in the unit of interest. The dimension of sentence representation is l × d, where l is the length of the activation map and d is the number of units per layer. That is, the activation of each of d units is l-dimensional. For each unit, we retrieve top K training sentences with the highest mean activation over the l entries of the vector. Interestingly, some natural language patterns such as morphemes, words, phrases frequently appear in the retrieved sentences, implying that those concepts might have a large attribution to the activation value of that unit.

3.3 CONCEPT ALIGNMENT WITH REPLICATED TEXT

We propose a simple approach for identifying the concepts as follows. For constructing candidate concepts, we parse each of top K sentences with a constituency parser (Kitaev & Klein, 2018).
Within the constituency-based parse tree, we define candidate concepts as all terminal and nonterminal nodes (e.g. from sentence John hit the balls, we obtain candidate concepts as {John, hit, the, balls, the balls, hit the balls, John hit the balls}). We also break each word into morphemes
using a morphological analysis tool (Virpioja et al., 2013) and add them to candidate concepts (e.g. from word balls, we obtain morphemes {ball, s}). We repeat this process for every top K sentence and build a set of candidate concepts for unit u, which is denoted as Cu = {c1, ..., cN }, where N is the number of candidate concepts of the unit.

Next, we measure how each candidate concept attributes to the unit's activation value. We create a

synthetic sentence by replicating each candidate concept so that its length is identical to the average

length of all training sentences (e.g. candidate concept the ball is replicated as the ball the ball

the ball...). Replicated sentences are denoted as R = {r1, ..., rN }, and each rn  R is forwarded to CNN, and their activation value of unit u is measured as au(rn)  R , which is averaged over l entries. Finally, the degree of alignment (DoA) between a candidate concept cn and a unit u is
defined as follows:

DoAu,cn = au(rn)

(1)

In short, the DoA measures the extent to which unit u's activation is sensitive to the presence of

candidate concept cn. If a candidate concept cn appears in the top K sentences and unit's activation
value au is responsive to cn a lot, then DoAu,cn gets large, suggesting that candidate concept cn is strongly aligned to unit u.

Finally, for each unit u, we define a set of its aligned concepts Cu = {c1, ..., cM } as M candidate concepts with the largest DoA values in Cu. Depending on how we set M , we can detect different numbers of concepts per unit. In this experiments, we set M to 3.

4 EXPERIMENTS

4.1 EVALUATION OF CONCEPT ALIGNMENT

To quantitatively evaluate how well our approach aligns concepts, we measure how selectively each

unit responds to the aligned concept. Motivated by Morcos et al. (2018), we define the concept selectivity of a unit u, to which a set of concepts Cu that our alignment method detects, as follows:

Selu

=

maxsS

µ+ - µ- au(s) - minsS

au(s)

(2)

4

Under review as a conference paper at ICLR 2019

Selectivity

1.5 replicate

1.0

inclusion random

0.5

0.0 dbpedia

ag

yelp enD-daeta-nseewt s en-fr-news en-cs-news en-de-europarl

Figure 2: Mean and variance of selectivity values over all units in representation learned for each

dataset. Sentences including the concepts that our alignment method discovers always activate units

significantly more than random sentences. See section 4.1 for details.

where

S

denotes

all

sentences

in

training

set,

and

µ+

=

1 |S+ |

sS+ au(s) is the average value of

unit activation when forwarding a set of sentences S+, which is defined as one of the following:

· replicate: S+ contains the sentences created by replicating each concept in Cu. As before, the sentence length is set as the average length of all training sentences for fair comparison.
· inclusion: S+ contains the training sentences that include at least one concept in Cu.
· random: S+ contains randomly sampled sentences from the training data.

In

contrast,

µ-

=

1 |S- |

sS- au(s) is the average value of unit activation when forwarding S-,

which consists of sentences that do not include any concept in Cu.

Intuitively, if unit u's activation is highly sensitive to Cu (i.e. those found by our alignment method) and if it is not to other factors, then Selu gets large; otherwise, Selu is near 0.

Figure 2 shows the mean and variance of selectivity values for all units learned in each dataset for the three S+ categories. Consistent with our intuition, in all datasets, the mean selectivity of the replicate set is the highest with a significant margin, that of inclusion set is the runner-up, and that
of the random set is the lowest. These results support our claim that our method is successful to
align concepts in which the unit responds selectively.

4.2 CONCEPT ALIGNMENT OF UNITS
Figure 3 shows examples of the top K sentences and the aligned concepts that are discovered by our method, for selected units. For each unit, we find the top K = 10 sentences that activate the most in the several encoding layer of ByteNet and VDCNN, and select some of them (only up to five sentences are shown due to space constraints). We observe that some patterns appear frequently within the top K sentences. For example, in the top K sentences that activate unit 124 of 0th layer of ByteNet, the concepts of `(', `)', `-' appear in common, while the concepts of soft, software, wi appear frequently in the sentences for unit 19 of 1st layer of VDCNN. These results qualitatively show that individual units are selectively responsive to specific natural language concepts.
More interestingly, we discover that many units could capture specific meanings or syntactic roles beyond superficial, low-level patterns. For example, unit 690 of the 14th layer in ByteNet captures (what, who, where) concepts, all of which play the similar grammatical role. On the other hand, unit 224 of the 14th layer in ByteNet and unit 53 of the 0th layer in VDCNN each captures semantically similar concepts, with the ByteNet unit detecting the meaning of certainty in knowledge (sure, know, aware) and the VDCNN unit detecting years (1999, 1969, 1992). This suggests that, although we train character-level CNNs with feeding sentences as the form of discrete symbols (i.e. character indices), individual units could capture natural language concepts sharing similar semantic or grammatical role.
We note that there are units that detect concepts more abstract than just morphemes, words, or phrases, and for these units our method tends to align relevant lower-level concepts. For example, in units 477 and 244 of the 3rd layer in VDCNN, while each aligned concept emerges only once in the top K sentences, all top K sentences have similar nuances like positive and negative sentiments. In these cases, our method does capture relevant phrase-level concepts (e.g., very disappointing, absolute worst place), indicating that the higher-level nuance (e.g., negativity) is indirectly captured.
We also note that, because the number of morphemes, words and phrases present in training corpus is usually much greater than the number of units per layer, we do not expect to always align any

5

Under review as a conference paper at ICLR 2019

Morpheme

Layer00, Unit 124: [#]( , [#]) , [#]-

Layer00, Unit 53: [#]1999, [#]1969, [#]1992

· [COM(2001) 24 - C5-0527/2001 - 2001/2207(COS)] · 19 august 1918 ­ 26 december 1999...

· Exemptions will follow a two-stage procedure.

· victor hernández cruz (born february 6 1949) is a puerto

· Such exceptions were completely inappropriate.

rican poet who in 1969 became the..

· (Exchange of views with microphones switched off) · vicki schneider (born august 12 1957) is a republican

· [COM(2001) 1 - C5-0007/2001 - 2001/0005(COD)]') member...

Word

Layer14, Unit 690: what, who, where · Who gets what, how much and when? · On what basis, when and how? · Then we need to ask: where do we start? · However, what should we do at this point? · What I am wondering now is: where are they?
Layer14, Unit 224: sure, know, aware · Are you sure you are aware of our full potential? · They know that and we know that. · I am sure you will understand. · I am sure you will do this. · I am confident that we will find a solution. Layer 06, Unit 396: of this communication, will, communication · That is not the subject of this communication. · That is the purpose of this communication. · I would like to ask the Commissioner for a reply. · This is impossible without increasing efficiency. · Will we be able to achieve this, Commissioner?

Layer01, Unit 19: soft, software, [#]wi · qualcomm has inked a licensing agreement with Microsoft · peoplesoft wants its customers to get aggressive with
software upgrades to increase efficiency. · provide its customers with access to wi-fi hotspots around
the world. · realnetworks altered the software for market-leading ipod. · apple lost one war to microsoft by not licensing its mac... Layer01, Unit 33: stock, google, stocks · google has a new one for the labs - google suggest · google has released google desktop search, ... · google shares jumped 18% in their stock market debut... · web search leader google inc. unveiled google scholar... · new york (reuters) - stocks moving on thursday:...
Layer03, Unit 477: a great place, the best meat, is a great place · one of the best restaurants and the best meat in town... · friendly service sweet tomatoes is a great place. · the margaritas are fantastic, the service was great... · love love love this place!... · paul is a great chef & manager,...

Phrase

Layer 14, Unit 360: the first step, first, be the first step · This is the first time, it is the first exercise. · These, however, are just the first steps. · This ought to be the first step forward. · That will be just the first step. · We can already see the first results.

Layer03, Unit 244: very disappointing, absolute worst place · very disappointing. ordered a vegetarian entrée,... · what the hell did i pay for?... · the absolute worst place i have ever done business with! · the is by far the worst restaurant i have ever been to... · this place is a rip off!...

(a) Translation (ByteNet)

(b) Classification (VDCNN)

Figure 3: Examples of top activated sentences and aligned concepts for some units in the several encoding layers of ByteNet and VDCNN. For each unit, aligned concept and it's presence in top K sentences are painted by the same color. [#] symbol denotes morpheme concept. See section 4.2 for details.

natural language concepts in the corpus to one of the units. Our approach thus tends to find concepts that are considered as more important than others for solving the target task.
Overall, these results suggest how input sentences are represented in the hidden representation of the CNN as follows:
· Several units in the CNN learned on NLP tasks respond selectively to specific natural language concepts, rather than getting activated in an uninterpretable way. This means that these units can serve as detectors for specific natural language concepts.
· There are units capturing syntactically or semantically related concepts, suggesting that they model the meaning or grammatical role shared between those concepts, as opposed to superficially modeling each natural language symbol.
4.3 CONCEPT DISTRIBUTION IN LAYERS
Using the concept alignments found earlier, we can visualize how concepts are distributed across layers. Figure 4 shows the concepts of the units in the 0th, 1st, 2nd, 3rd layer of VDCNN learned on AG-News dataset, and 0th, 5th, 9th and 14th layer of the ByteNet encoder learned on Englishto-German Europarl dataset with their number of aliged units. For each layer, we sort concepts in a decreasing order by the number of aligned units and show 30 concepts most aligned. Recall that,

6

Under review as a conference paper at ICLR 2019
Figure 4: 30 concepts selected by the number of aligned units in four encoding layers in VDCNN learned on AG-News (top two rows), and ByteNet learned on the Europarl translation dataset (bottom two rows). [#] symbol denotes morpheme concept. See section 4.3 for details.
since we align concepts for each unit, there are concepts aligned to multiple units simultaneously. Concept distribution for other datasets are available in appendix C. Overall, we find that data and task-specific concepts are likely to be aligned to many units. In AG News, since the task is to classify given sentences into following categories; World, Sports, Business and Science/Tech, concepts related to these topics commonly emerge. Similarly, we can see that units learned for Europarl dataset focus to encode some key words in the training corpus.
4.4 HOW DOES CONCEPT GRANULARITY EVOLVE WITH LAYER? In computer vision tasks, visual concepts captured by units in CNN representations learned for image recognition tasks evolve with layer depths; color, texture concepts are emergent in earlier layers and more abstract concepts like parts and objects are emergent in deeper layers. To confirm that it also holds for representations learned in NLP tasks, we divide granularity of natural language concepts to morhpeme, word and N -gram phrase (N = 2, 3, 4, 5), and observe the number of units that they are aligned in different layers. Figure 5 shows this trend, where in lower layers such as the 0th layer, less phrase concepts but more morphemes and words are detected. This is because we use a character-level CNN, whose receptive fields of convolution may not be large enough to detect lengthy phrases. Further, interestingly in translation cases, we observe that aligned concepts significantly change in shallower layers (e.g. from the 0th to the 4th), but do not change much from middle to deeper layers (e.g. from the 5th to the 14th). Thus, it remains for us to answer the following question: for the representations learned on translation datasets, why does concept granularity not evolve much in deeper layers? One possibility is that the capacity of the network is large enough so that the representations in middle layers could be sufficiently informative to solve the task. To validate this hypothesis, we re-train ByteNet from scratch while varying only layer depth of the encoder and fixing other conditions. We record their BLEU scores on the validation data as shown in Figure 6. The performance of the translation model does not change much with more than six encoder layers, but it significantly drops at the models with fewer than 4 encoder layers. This trend coincides with the result from Figure 5 that the evolution of concept granularity stops around middle-to-higher layers. This shared pattern suggests that about six encoder layers are enough to encode informative factors in the given datasets to perform optimally on the translation task. In deeper models, this may suggest that the middle layer's representation
7

Under review as a conference paper at ICLR 2019

# of aligned concepts

dbpedia
1000 1000 800 800 600 600 400 400
200 200

ag

yelp
700 600 500 400 300 200 100

Morpheme Word Phrase(2-gram) Phrase(3-gram) Phrase(4-gram) Phrase(5-gram)

000

0.0 0.e5 n1-.0de1.-5ne2.0ws2.5 3.0 0.0 0.5en1.-0fr1-.n5 e2w.0 s2.5 3.0 0.0 0.5en1.-0cs1-.5ne2.w0 s2.5 3.0

2000 1750

2000

2000 1750

2000 1750

1500 1250

1500

1500 1250

1500 1250

1000 750

1000

1000 750

1000 750

500 500 500 500

250 250 250

en-de-europarl

0000

0 2 4 6 8 10 12 14

Layer Index0 2 4 6 8 10 12 14 0 2 4 6 8 10 12 14

0 2 4 6 8 10 12 14

Figure 5: Aligned concepts are divided into six different levels of granularity: morphemes, words and N-gram phrases (N=2,3,4,5). The number of units aligned to each concept are shown layerwise across multiple datasets and tasks. Note that the number of units increases with layers in the classification models (i.e. [64, 128, 256, 512]), but in translation the number is constant (i.e. 1024) across all layers.

BLEU
enc15 eeeeennnnnccccc0000068142

32.5

30.0

27.5 25.0 22.5 20.0

en-fr-news en-de-news en-cs-news

17.5

15.0

12.5

# of encoder layers
Figure 6: BLEU scores on the validation data for three translation models. We train ByteNet from scratch on each translation dataset by varying the number of encoder layers.

may be already informative enough to encode the input text, and our result may partly coincide with that of Mou et al. (2016), which shows that representation of intermediate layers is more transferable than that of deeper layers in language tasks, unlike in computer vision where deeper layers are usually more useful and discriminative.
5 CONCLUSION
We proposed a simple but highly effective concept alignment method for character-level CNNs to confirm that each unit of the hidden layers serves as detectors of natural language concepts. Using this method, we analyzed the characteristics of units with multiple datasets on classification and translation tasks. Consequently, we shed light on how deep representations capture natural language, and how they vary with various conditions.
An interesting future direction is to extend the concept coverage from natural language to more abstract forms such as sentence structure, nuance and tone. Another direction is to quantify the properties of individual units in other models widely used in NLP tasks. In particular, combining our definition of concepts with the attention mechanism (e.g. Bahdanau et al. (2015)) could be a promising direction, because it can reveal how the representations are attended by the model to capture concepts, helping us better understand the decision making process of popular deep models.
8

Under review as a conference paper at ICLR 2019
REFERENCES
Mart´in Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dandelion Mane´, Rajat Monga, Sherry Moore, Derek Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Vie´gas, Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. TensorFlow: Large-scale machine learning on heterogeneous systems, 2015.
Yossi Adi, Einat Kermany, Yonatan Belinkov, Ofer Lavi, and Yoav Goldberg. Fine-grained analysis of sentence embeddings using auxiliary prediction tasks. ICLR, 2017.
Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly learning to align and translate. ICLR, 2015.
David Bau, Bolei Zhou, Aditya Khosla, Aude Oliva, and Antonio Torralba. Network dissection: Quantifying interpretability of deep visual representations. In CVPR, 2017.
Yonatan Belinkov, Nadir Durrani, Fahim Dalvi, Hassan Sajjad, and James Glass. What do neural machine translation models learn about morphology? In ACL, 2017.
Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. Learning phrase representations using rnn encoder­decoder for statistical machine translation. In EMNLP, 2014.
Alexis Conneau, Holger Schwenk, Lo¨ic Barrault, and Yann Lecun. Very deep convolutional networks for text classification. In EACL, 2017.
Alexis Conneau, Germa´n Kruszewski, Guillaume Lample, Lo¨ic Barrault, and Marco Baroni. What you can cram into a single \$&!# vector: Probing sentence embeddings for linguistic properties. In ACL, 2018.
Dumitru Erhan, Yoshua Bengio, Aaron Courville, and Pascal Vincent. Visualizing higher-layer features of a deep network. University of Montreal, 2009.
Ruth Fong and Andrea Vedaldi. Net2vec: Quantifying and explaining how concepts are encoded by filters in deep neural networks. In CVPR, 2018.
Nal Kalchbrenner, Lasse Espeholt, Karen Simonyan, Aaron van den Oord, Alex Graves, and Koray Kavukcuoglu. Neural machine translation in linear time. arXiv preprint arXiv:1610.10099, 2016.
Andrej Karpathy, Justin Johnson, and Li Fei-Fei. Visualizing and understanding recurrent networks. arXiv preprint arXiv:1506.02078, 2015.
Yoon Kim, Yacine Jernite, David Sontag, and Alexander M Rush. Character-aware neural language models. In AAAI, 2016.
Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. ICLR, 2015.
Nikita Kitaev and Dan Klein. Constituency parsing with a self-attentive encoder. ACL, 2018.
Philipp Koehn. Europarl: A parallel corpus for statistical machine translation. In MT summit, volume 5, pp. 79­86, 2005.
Jens Lehmann, Robert Isele, Max Jakob, Anja Jentzsch, Dimitris Kontokostas, Pablo N Mendes, Sebastian Hellmann, Mohamed Morsey, Patrick Van Kleef, So¨ren Auer, et al. Dbpedia­a largescale, multilingual knowledge base extracted from wikipedia. Semantic Web, 6(2):167­195, 2015.
Ari S. Morcos, David G.T. Barrett, Neil C. Rabinowitz, and Matthew Botvinick. On the importance of single directions for generalization. In ICLR, 2018.
Lili Mou, Zhao Meng, Rui Yan, Ge Li, Yan Xu, Lu Zhang, and Zhi Jin. How transferable are neural networks in nlp applications? In EMNLP, 2016.
9

Under review as a conference paper at ICLR 2019
Chris Olah, Alexander Mordvintsev, and Ludwig Schubert. Feature visualization. Distill, 2017. doi: 10.23915/distill.00007. https://distill.pub/2017/feature-visualization.
Chris Olah, Arvind Satyanarayan, Ian Johnson, Shan Carter, Ludwig Schubert, Katherine Ye, and Alexander Mordvintsev. The building blocks of interpretability. Distill, 2018. doi: 10.23915/ distill.00010. https://distill.pub/2018/building-blocks.
Alec Radford, Rafal Jozefowicz, and Ilya Sutskever. Learning to generate reviews and discovering sentiment. arXiv preprint arXiv:1704.01444, 2017.
Franois Role and Mohamed Nadif. Handling the impact of low frequency events on co-occurrence based measures of word similarity. KDIR, 2011.
Xing Shi, Inkit Padhi, and Kevin Knight. Does string-based neural mt learn source syntax? In EMNLP, 2016.
Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman. Deep inside convolutional networks: Visualising image classification models and saliency maps. arXiv preprint arXiv:1312.6034, 2013.
Ilya Sutskever, Oriol Vinyals, and Quoc V Le. Sequence to sequence learning with neural networks. In NIPS, 2014.
Zhiyuan Tang, Ying Shi, Dong Wang, Yang Feng, and Shiyue Zhang. Memory visualization for gated recurrent neural networks in speech recognition. In ICASSP, 2017.
Jrg Tiedemann. Parallel data, tools and interfaces in opus. In LREC. ELRA, 2012. ISBN 978-29517408-7-7.
Ashish Vaswani, Noam Shazeer, Niki Parmar, Llion Jones, Jakob Uszkoreit, Aidan N Gomez, and L ukasz Kaiser. Attention is all you need. In NIPS, 2017.
Sami Virpioja, Peter Smit, Stig-Arne Gronroos, and Mikko Kurimo. Morfessor 2.0: Python implementation and extensions for morfessor baseline. In Aalto University publication series. Department of Signal Processing and Acoustics, Aalto University, 2013.
Xiang Zhang, Junbo Zhao, and Yann LeCun. Character-level convolutional networks for text classification. In NIPS, 2015.
Bolei Zhou, Aditya Khosla, Agata Lapedriza, Aude Oliva, and Antonio Torralba. Object detectors emerge in deep scene cnns. In ICLR, 2015.
Bolei Zhou, David Bau, Aude Oliva, and Antonio Torralba. Interpreting deep visual representations via network dissection. IEEE TPAMI, 2018a.
Bolei Zhou, Yiyou Sun, David Bau, and Antonio Torralba. Interpretable basis decomposition for visual explanation. In ECCV, 2018b.
Xunjie Zhu, Tingfeng Li, and Gerard Melo. Exploring semantic properties of sentence embeddings. In ACL, 2018.
A OTHER METRICS FOR DOA WITH BIASED ALIGNMENT RESULT
In section 3.3, we define Degree of Alignment (DoA) between concept cn and unit u as activation value of unit u for replication of cn. We tried lots of stuff while we were working on DoA metrics, but a lot of it give biased concept alignment result for several reasons. We here provide the things we tried and their reasons of failure.
10

Under review as a conference paper at ICLR 2019

A.1 POINT-WISE MUTUAL INFORMATION

Point-wise Mutual Information (PMI) is a measure of association used in information theory and statistics. The PMI of a pair of samples x and y sampled from random variables X and Y quantifies the discrepancy between the probability of their coincidence as follows:

p(x, y) pmi(x, y) = log
p(x)p(y)

(3)

We then define DoA between candidate concept cn and unit u by using PMI as follow:

DoAu,cn

=

pmi(u, cn)

=

log

p(u, cn) , where p(u)p(cn)

p(u)

=

#[s



S, s #[s

 

topK(u)] S]

,

p(cn)

=

#[s  S, cn  #[s  S]

s] ,

p(u, cn)

=

#[s  topK(u), cn  #[s  topK(u)]

s]

(4a) (4b) (4c) (4d)

However, this metric has bias of always preferring lengthy concepts even in earlier layers, which is not possible considering the receptive field of the convolution. Our intuition for this bias is consistent with Role & Nadif (2011),where it is a well-known problem with PMI, which is its tendency to give very high association scores to pairs involving low-frequency ones, as the denominator is small in such cases. If certain concept cn in top K sentences is very lengthy, then its frequency in the corpus p(cn) would get very small, and pmi(u, cn) would be large with regardless of correlation between u and cn.

A.2 CONCEPT OCCLUSION

We tested concept alignments with following concept occlusion method. For each of top K sentences, we replace a cn by dummy character tokens which have no meaning, forward it to the model, and measure the reduction of the unit activation value. We repeat this for every candidate concept in the sentences ­ as a result, we can identify which candidate concept greatly reduce unit activation values. We thus define concepts aligned to each unit as the candidate concept that consistently lower the unit activation across the top K sentences.

More formally, for each unit u, let S = {s1, ..., sK} be top K activated sentences. Since we occlude each candidate concept in sentences, we define the set of candidate concept C = {c1, ..., cN }, obtained from parsing each sentence in S.

We define the degree of alignment (DoA) between a concept c  C and a unit u as:

1

DoAu,cn = Z

1(cn  s)(au(s) - au(Occcn (s)))

sS

(5)

where Z is a normalizing factor, and au indicates the mean activation of unit u, Occcn (s) is a sentence s where candidate concept cn is occluded, and 1(cn  s) is an indicator of whether cn is included in the sentence s. In short, the DoA measures how much candidate concept contributes to the activation of the unit's top K sentences. If a candidate concept cn appears in the top K sentences S and greatly reduces the activation of unit u, then DoAu,cn gets large, implying that the cn is strongly aligned to unit u.
Unfortunately, this metric could not fairly compare attribution of several candidate concepts. For example, consider following two concepts c1 = hit, c2 = hit the ball are included in one sentence. Occluding c2 might gives relatively large decrement in unit activation value than that of c1, since c1 includes c2. For this reason, occlusion based metric is unnecessarily dependant of length of concept, rather than it's attribution.

11

Under review as a conference paper at ICLR 2019

A.3 INCLUSION SELECTIVITY

Note that inclusion selectivity in section 4.1 is also used as DoA. Recall that inclusion selectivity is

calculated

as equation 2.

In

this case, µ+

=

1 |S+ |

sS+ au(s) is the average value of unit activa-

tion when forwarding a set of sentences S+, where S+ denotes that sentences including candidate

concept cn.

However, it induces similar bias which is similar to section A.1. It always prefers lengthy phrases
since those lengthy concept occur few times in entire corpus. For example, assume that activation value of unit u for the sentence including specific lengthy phase is very high. If such phrase occur only one time over the entire corpus, µ+ is equal to the activation value of the sentence, which is relatively very high than µ+ for other candidate concepts. This error could be alleviated on very large corpus where every candidate concept occurs enough in the corpus so that estimation of µ+ get relatively accurate, which is practically not possible.

B TRAINING DETAILS
In this work, we trained a ByteNet for the translation tasks and a VDCNN for the classification tasks, both to analyze properties of representations for language. Training details are as follows.
B.1 BYTENET
We trained a ByteNet on the translation tasks, in particular on the WMT'17 English-to-German Europarl dataset, the English-to-German news dataset, WMT'16 English-to-French, English-toCzech news dataset. We used the same model architecture and hyperparameters for both datasets. We set the batch size to 8 and the learning rate to 0.001. The parameters were optimized with Adam (Kingma & Ba, 2015) for 5 epochs, and early stopping was actively used for finding parameters that generalize well. Our code is based on a TensorFlow (Abadi et al., 2015) implementation of ByteNet found in https://github.com/paarthneekhara/byteNet-tensorflow.
B.2 VERY DEEP CNN (VDCNN)
We trained a VDCNN for classfication tasks, in particular on the AG News dataset, the binarized version of the Yelp Reviews dataset, and DBpedia ontology dataset. For each task, we used 1 temporal convolutional layer, 4 convolutional blocks with each convolutional layer having a filter width of 3. In our experiments, we analyze representations of each convolutional block layer. The number of units in each layer representation is 64, 128, 256, 512 respectively. We set the batch size to 64 and the learning rate to 0.01. The parameters are optimized using SGD optimizer for 50 epochs, and early stopping is actively used. For each of the AG News, Yelp Reviews and DBpedia datasets, a VDCNN was learned with the same structure and hyperparameters. Our code is based on a TensorFlow implementation of VDCNN found in https://github.com/zonetrooper32/VDCNN.

C CONCEPT DISTRIBUTION IN LAYERS FOR OTHER DATASETS
In section 4.3, we visualized how concepts are distributed across layers, where model is trained on AG News dataset and English-to-German Europarl dataset. Here, Figure 7 shows concept distribution in other datasets noted in Table 1.
In the classification tasks, we expect to find more concepts that are directly related to predicting the output label, as opposed to the translation tasks where the representations may have to include information on most of the words for an accurate translation. While our goal is not to relate each concept to one of labels, we find several concepts that are more predictive to a particular label than others.
In consistent with section 4.3, there are data-specific and task-specific concepts aligned in each layer; i.e. {worst, 2 stars, awful} at Yelp Review, {film, ship, school} at DBpedia, and some key words at translation datasets. Note that Yelp Review and DBpedia is a classification dataset, where model is required to predict the polarity (i.e. +1 or -1) or ontology (i.e. Company, Educational Institution,

12

Under review as a conference paper at ICLR 2019
Figure 7: 30 concepts selected by the number of aligned units in four encoding layers in VDCNN learned on Yelp Review dataset and DBpedia ontology dataset, and ByteNet learned on the English-to-German, English-to-French, and English-to-Czech parallel corpus. [#] symbol denotes morpheme concept. Artist, Athelete, Officeholder, Mean of Transportation, Building, Natural Place, Village, Animal, Plant, Album, Film, Written Work) for given sentence in supervised setting.
13

