Under review as a conference paper at ICLR 2019
DELIBGAN: COARSE-TO-FINE TEXT GENERATION VIA ADVERSARIAL NETWORK
Anonymous authors Paper under double-blind review
ABSTRACT
In this paper, we propose a novel adversarial learning framework, namely DelibGAN, for generating high-quality sentences without supervision. Our framework consists of a coarse-to-fine generator, which contains a first-pass decoder and a second-pass decoder, and a multiple instance discriminator. And we propose two training mechanisms DelibGAN-I and DelibGAN-II. The discriminator is used to fine-tune the second-pass decoder in DelibGAN-I and further evaluate the importance of each word and tune the first-pass decoder in DelibGAN-II. We compare our models with several typical and state-of-the-art unsupervised generic text generation models on three datasets (a synthetic dataset, a descriptive text dataset and a sentimental text dataset). Both qualitative and quantitative experimental results show that our models produce more realistic samples, and DelibGAN-II performs best.
1 INTRODUCTION
Building a good text generative model has always been a fundamental problem in the natural language processing field. The most common generative model is Recurrent Neural Networks (RNN)(Mikolov et al., 2011), which predicts each word of a sentence conditioned on the previous word and an evolving hidden state. However, it suffers from two main drawbacks: First, RNN based models are always trained through the maximum likelihood approach, which suffers from exposure bias(Bengio et al., 2015); Second, the loss function used to train the model is at word level but the performance is typically evaluated at sentence level(Wang & Wan, 2018a).
Some recent studies have tried to solve these problems. Some approaches work indirectly by making the hidden state dynamics predictable (Professor Forcing (Goyal et al., 2016)) or by randomly adjusting the sampling words during training time (Scheduled Sampling (Bengio et al., 2015)). But they do not directly specify the cost function on the RNN output to encourage high sample quality. Later works used Generative Adversarial Networks (GAN)(Goodfellow et al., 2014) or reinforcement learning to directly affect the decoding sequence, such as Gumbel-softmax distribution(Kusner & Herna´ndez-Lobato, 2016), SeqGAN(Yu et al., 2017), MaskGAN(Fedus et al., 2018), etc. However, they all adopt an one-pass forward decoding , which can only see words that have been decoded. Recently, coarse-to-fine generator with multiple decoders has achieved great success on some tasks. But they either do not define the meaning of the sketch(Xia et al., 2017), or are limited to specific tasks such as logical form parsing, code generation, SQL query generation, etc(Lapata & Dong, 2018). And they all are supervised learning methods.
Inspired by Deliberation Networks(Xia et al., 2017), we propose a novel adversarial learning framework, namely DelibGAN, for generating high-quality sentences without supervision. Our framework consists of a coarse-to-fine generator and a multiple instance discriminator, and the coarseto-fine generator contains a first-pass decoder and a second-pass decoder. Further, we propose two training mechanisms, named DelibGAN-I and DelibGAN-II. The former one uses the sentencelevel penalty predicted by the discriminator to fine-tune the second-pass decoder. And the latter one imposes the influence of word importance on the first-pass decoder, with the purpose of decoding important words as much as possible in the first pass, and thus better guiding the decoding of the second-pass decoder. The word importance is obtained through the multiple instance learning mechanism of the discriminator, which is used to directly tune the first-pass decoder and later guide the second-pass decoding. In short, for DelibGAN-I, the discriminator is used to fine-tune the second-
1

Under review as a conference paper at ICLR 2019

pass decoder G2, while for DelibGAN-II, the discriminator is further used to evaluate the importance of each word and tune G1.
Our motivation is two-fold: (1) We use a coarse-to-fine generator to generate important words (i.e., sketch) as much as possible during the first decoding and utilize the global information (i.e., the sentence decoded in the first pass) at the time of final decoding; (2) The discriminator can evaluate the sentence-level quality to guide the final generation via policy gradients, moreover, it can provide word-level importance, which can be used to adjust the sketches in the first-pass generation to make sense.
We compare our models with several typical and state-of-the-art unsupervised generic text generation models, including RNNLM(Mikolov et al., 2011), SeqGAN(Yu et al., 2017), SentiGAN(Wang & Wan, 2018a), MaskGAN(Fedus et al., 2018). Experimental results on three datasets (a synthetic dataset, a descriptive text dataset and a sentimental text dataset) show that our models can produce more realistic samples. The major contributions of this paper are summarized as follows:
· We propose a novel adversarial learning framework - DelibGAN, which consists of a coarse-to-fine generator and a multiple instance discriminator, to generate high-quality sentences without supervision.
· We propose two training mechanisms, DelibGAN-I and DelibGAN-II, to make the generator generate higher-quality sentences.
· Both qualitative and quantitative results show that DelibGAN-I and DelibGAN-II can produce more realistic samples, and DelibGAN-II performs best.

2 FRAMEWORK

2.1 ARCHITECTURE
The architecture of our proposed DelibGAN is show in Figure1. The entire model consists of two modules: a coarse-to-fine generator and a multiple instance discriminator. The coarse-to-fine generator has a first-pass decoder G1 and a second-pass decoder G2. The multiple instance discriminator D can evaluate both a whole sentence and each individual word in the sentence by using the multiple instance learning mechanism, and thus the two decoders can be influenced by the discriminator D in different ways. In our first training mechanism DelibGAN-I, the sentence-level penalty predicted by the discriminator is used to fine-tune the second-pass decoder G2. In our second training mechanism DelibGAN-II, in addition to the fine-tuning of G2, the word-level importance is predicted and used to tune G1, to make G1 decode important words as much as possible, and thus better guide the decoding of G2.

G1 z ~ Pz

x^0 h^0

Coarse-to-fine Generator

x^1 x^t

h^1 ... h^t

...

x^l h^l

attention ct

G2 x0 h0

x1 xt

xm

h1 ... ht

... hm

DelibGAN-I
DelibGAN-II
Sentence-level penalty

Multiple Instance Discriminator

pD

p0 p1

pt

pn

s0 s1 ... st ... sn

w0 w1

wt

wn

Figure 1: The architecture of DelibGAN. Two training mechanisms DelibGAN-I and DelibGAN-II are detailed in section 2.4.
2

Under review as a conference paper at ICLR 2019

2.2 COARSE-TO-FINE GENERATOR

Inspired by Deliberation Networks(Xia et al., 2017), we propose a coarse-to-fine generator with the following two purposes: The first is to enable the generator to utilize the global information (i.e., the sentence decoded in the first pass) at the time of final decoding, rather than only the sequence that has been decoded; The second is to force the generator to generate important words (i.e., sketch) as much as possible during the first-pass decoding, so as to provide more useful clues for decoding in the second pass.
Our coarse-to-fine generator contains a first-pass decoder G1 and a second-pass decoder G2. Both decoders are RNN and can be easily replaced with its variants such as LSTM and GRU (In this work, we use LSTM). The prior input noise z sampled from a distribution Pz (e.g., a normal distribution) is used to initialize the input of G1, then G1 will generate a first-pass sequence x^ = {x^1, x^2 · · · x^l}, and a series of hidden states H^ = {h^1, h^2 · · · h^l}, where l is the length of the generated sequence. At step t, h^t is calculated as h^t = RNN(f (x^t-1), h^ t-1), where f is a word embedding representation function. Then h^t is fed into a softmax layer, and x^t is sampled out from the obtained multinomial distribution. Finally, the first-pass output sequence x^ is generated by G1.
In the second-pass decoding, we take the hidden state of the last moment of G1 as the initial hidden state of G2. And we use an attention model in G2, Specifically, at step t, the attention model in G2 first generates a context ct defined as follows:

ll
ct = aih^i; ai  exp (vaT tanh(Watth^i + Uattht-1))i  [1, l]; ai = 1.
i=1 i=1

(1)

After receiving ct, we calculate the hidden state ht as ht = RNN([f (xt-1); ct], ht-1). Then xt is sampled in the same way of sampling x^t, and the second-pass output sequence x is generated and its length is m.

2.3 MULTIPLE INSTANCE DISCRIMINATOR

Like Yu et al. (2017) and Wang & Wan (2018a), in order to evaluate the performance of a generator at the sentence-level, we use a discriminator to calculate rewards. Further, we want to get the importance of each word in the sentence to adjust the generator to decode the important words as much as possible in the first-pass decoding. Thus we adopt a multi-instance learning (MIL) mechanism in our discriminator. MIL deals with problems where labels are associated with groups of instances or bags (sentences in our case), while instance labels (word-level importance) are unobserved (Keeler & Rumelhart, 1991; Zhang et al., 2002; Wang & Wan, 2018b).

Our multiple instance discriminator D uses a structure similar to a bidirectional RNN. Supposing
the input to D is a sentence w = {w1, w2, · · · , wn}, where n is the length of w. We apply a bidirectional LSTM on the sentence, and for each word wt(t  n), we concatenate its corresponding
forward and backward hidden state vectors:

-st

=

---- LSTM(wt);

s-t

=

---- LSTM(wt);

st

=

-st ||s-t ,

(2)

----

----

where LSTM(wt) and LSTM(wt) represent the forward and backward LSTM hidden state vectors

for wt. Then we use a softmax classifier to get the word-level probability distribution over target

labels (i.e., real and f ake).

pt = softmax(tanh(Wdst + bd), where pt = [p(rte)al, p(fta)ke]; pr(te)al + p(fta)ke = 1.

(3)

pr(te)al and p(fta)ke represent the probability that the t-th word is predicted to be real and fake, respectively; Wd and bd are parameters, shared across all words. Finally, we use the average of the word-level distribution as the sentence-level distribution over the target labels:

1 pi = n

n

p(it), i  {real, fake}; p = [preal, pfake].

t=1

(4)

3

Under review as a conference paper at ICLR 2019

2.4 TRAINING

Here we introduce the adversarial training of the generator and the discriminator in detail. In this paper, we formalize the text generation problem as a sequential decision making process (Bachman & Precup, 2015), which solves the problem that the gradient cannot pass back to the generative model when the output is discrete. Moreover, we use policy gradients to update parameters of the generator.

We propose two loss functions for the generator, named DelibGAN-I and DelibGAN-II. DelibGAN-

I just forces the first-pass decoder G1 to maintain the same decoding result, while DelibGAN-II

utilizes the result of the discriminator at the word level, forcing G1 to decode important words

(evaluated by the discriminator) as much as possible. But for the second-pass decoder G2, both

of them use the penalty-based objective function (Wang & Wan, 2018a) to update the parameters

G2 of G2. Specifically, at each timestep t, the existing sequence generated by G2 is x1:t-1 = {x1, ..., xt-1}, and the next token xt selected in the next step is an action sampling from the policy

G2(xt|x1:t-1; G2 ), and we use the Monte Carlo rollouts method (Dai et al., 2017; Yu et al., 2017)

to simulate intermediate penalty Then, the total penalty of G2 can

RG2 ,D (xt), where be computed by:

D

is

the

parameters

of

the

discriminator

D.

m

ExG2 (x) = [(RG2 ,D (xt) - b)G2(xt|x1:t-1; G2 )]
t=1

=

m1 [( ( q

q

(1 - D(xt|x1(j:t)-1; D))) - b)G2(xt|x1:t-1; G2 )],

t=1 j=1

(5)

where b is the bias, x1(j:t)-1 is the q-time Monte Carlo search sampled based on the roll-out policy G2(xt|x1:t-1; G2 ), and D(xt|x(1j:t)-1; D) is the sentence probability preal given by the discriminator for sentence x(1j:t)-1||xt.
DelibGAN-I: For DelibGAN-I, we just force the first-pass decoder G1 to maintain the same decoding result. Specifically, after we use (G1, G2) to sample a pair of sentences (x^, x), we first use the discriminator to calculate the sentence-level penalties. Then in the process of using penalties to update the generator, we force the first-pass decoder G1 to decode the same result, which is x^. The loss of generator G1 (the parameters are denoted as G1 ) is defined as follows:

(I )
ExG1

(x^)

=

1 l

l

- log(G1(x^t|x^1:t-1; G1 ))

t=1

(6)

we propose it with the purpose of keeping the results of G1 as constant as possible, and just finetuning G2 based on the sentence-level penalty mentioned above. Finally, the objective of the gener-
ator is to minimize:

JG(I1),G2 (G1 , G2 )

=

(I )
ExG1

(x^)

+

ExG2

(x)

=

1 l

l

- log(G1(x^t|x^1:t-1; G1 ))

t=1

+

m1 [( ( q

q

(1 - D(xt|x(1j:t)-1; D))) - b)G2(xt|x1:t-1; G2 )].

t=1 j=1

(7)

DelibGAN-II: For DelibGAN-II, we want to impose direct influence to G1, forcing it to decode important words as much as possible in the first-pass decoding, to better guide the decoding of G2. We tried different ways of influencing, including using sentence-level penalties like Eq5, but finally
we introduced and leveraged a multi-instance learning mechanism in the discriminator. This is
because it can provide the importance of words in a sentence, and we add the word-level importance to the loss as weights. So the loss of generator G1 is changed as follows:

(I I )
ExG1

(x^)

=

1 l

l

-pr(te)al log(G1(x^t|x^1:t-1; G1 ))

t=1

(8)

4

Under review as a conference paper at ICLR 2019

where p(rte)al is the probability that the discriminator predicts x^t as real. Therefore, the objective of the generator is to minimize the total loss:

JG(I1I,G)2 (G1 , G2 )

=

(I I )
ExG1

(x^)

+

ExG2

(x)

=

1 l

l

-preal(x^) log(G1(x^t|x^1:t-1; G1 ))

t=1

+

m1 [( ( q

q

(1 - D(xt|x(1j:t)-1; D))) - b)G2(xt|x1:t-1; G2 )].

t=1 j=1

(9)

For discriminator D, the goal is to distinguish between real text and generated text as much as possible. It is worth noting that we only have the target label for the sentence, but do not have labels on words. The objective function of the discriminator is to minimize:

JD(D) = -ExG log pfake - ExS log preal,

(10)

where S is real sentences in the corpus. We perform the adversarial training of the generator and the discriminator, and train them alternately, as shown in Algorithm 1.

Algorithm 1 The adversarial training process in DelibGAN
Input: Input noise, z; Generator, (G1 , G2); Discriminator, D; Real text dataset, S; Output: Well trained generator, (G1 , G2); 1: Initialize (G1 , G2),D with random weights; 2: Pre-train (G1 , G2) using MLE on S; 3: repeat
4: for d-steps do 5: Generate fake texts ({x^}, {x}) using (G1, G2); 6: Update D using ({x}, S) by minimizing Eq 10;
7: end for
8: for g-steps do 9: Generate fake texts ({x^}, {x}) using (G1, G2); 10: Calculate penalty ExG2 (x) by Eq (5) ; 11: For DelibGAN-I, Update (G1, G2) by minimizing Eq (7); 12: For DelibGAN-II, Update (G1, G2) by minimizing Eq (9); 13: end for
14: until Model converges
15: return ;

3 EXPERIMENTS
3.1 SETUP
In this study, we hope that our unsupervised models can generate sentences with higher quality. Without loss of generality, we evaluate our model 1 on three benchmark datasets: a synthetic dataset, a descriptive text dataset and a sentimental text dataset. We compare with several typical and stateof-the-art unsupervised generic text generation models, including RNNLM(Mikolov et al., 2011), SeqGAN(Yu et al., 2017), SentiGAN(Wang & Wan, 2018a), MaskGAN(Fedus et al., 2018). It is worth noting that pre-training was used for all selected baselines.
After training models, we let them generate 1k sentences each. Measuring the quality of generated sentences has always been a difficult problem. For synthetic data, we have an oracle model to measure the negative log-likelihood (NLL) scores. But for real texts, we use automatic quantitative indicators (e.g., Fluency, Novelty and Diversity) and human evaluation methods (e.g., Grammaticality, Topicality and Overall) to evaluate the quality of generated sentences.
For automatic quantitative indicators, same as Wang & Wan (2018a), we use a language modeling toolkit - SRILM (Stolcke, 2002) to test the fluency of generated sentences, which calculates the perplexity of generated sentences using the language model trained on respective corpus. In addition,
1We will release the source codes of our methods upon the acceptance of this paper.
5

Under review as a conference paper at ICLR 2019

Table 1: The performance comparison on the synthetic data in terms of the NLL scores.

Methods MLE SeqGAN SentiGAN DelibMLE DelibGAN-I DelibGAN-II

NLL 9.038 8.736

6.924

8.604

5.594

5.250

given the generated sentence set A and its training corpus set B, the novelty N ovelty(A|B) and the diversity Diversity(A) are defined as follows:

N ovelty(A|B)

=

1 |A|

(1
iA

-

max{(i, j); j



B}),

(11)

Diversity(A)

=

1 |A|

(1 -
iA

max{(i, j); j



A\{i}}),

(12)

 is the Jaccard similarity function. It is worth noting that in terms of the fluency indicator, a smaller value is better, but the novelty and diversity indicators are just the opposite.

For human evaluation, we randomly extracted 100 sentences from the generated sentences, and then let five experts rate each sentence according to its "grammaticality", "topicality" and "overall" aspects, where "topicality" indicates whether the sentence accords with the topic/genre of the dataset (i.e., happy moment and sentimental text for the two real datasets, respectively). Scores range from 1 to 5, with 5 being the best. We finally calculate the average of the scores.

3.2 SIMULATION ON SYNTHETIC DATA
Here we use the synthetic dataset2 used by Yu et al. (2017), which consists of a set of sequential tokens which can be seen as the simulated data comparing to the real-word language data. Moreover, it automatically evaluates the negative log-likelihood (NLL) scores of our generated sequences, which brings us convenience. We compare our model with various models on this dataset, as shown in Table 1 and Figure 2. It is worth noting that the DelibMLE method is just using our coarse-to-fine generator.

Figure 2: The illustration of learning curves. Dotted line is the end of pre-training.
From the results, we can see that: (1) Our coarse-to-fine generator (DelibMLE) performs better and even outperforms seqGAN. (2) Our proposed methods DelibGAN-I and DelibGAN-II outperform all other competitors with a large margin which means the framework we proposed is better than
2The synthetic data and the oracle model (LSTM model) are publicly available at https://github.com/LantaoYu/SeqGAN
6

Under review as a conference paper at ICLR 2019

Table 2: Comparison of automatic quantitative indicators of generated sentences on HappyDB cor-

pus.  means that the smaller the better, and  is the opposite.

Methods SeqGAN SentiGAN MaskGAN DelibMLE DelibGAN-I DelibGAN-II

Fluency() 156.212 130.655 121.273 138.353 105.593

98.348

Novelty() 0.275 0.324

0.267

0.305

0.359

0.399

Diversity() 0.694 0.732

0.753

0.723

0.765

0.767

Table 3: Comparison of human evaluation of generated sentences on HappyDB corpus.

Methods

SeqGAN SentiGAN MaskGAN DelibMLE DelibGAN-I DelibGAN-II

Grammaticality 2.256 2.694

3.548

2.438

3.864

3.871

Topicality

2.331 2.652

3.361

3.237

3.763

4.026

Overall

2.384 2.698

3.525

2.752

3.644

3.836

the other models in capturing the dependency of the sequential tokens. (3) DelibGAN-II is better than DelibGAN-I, which indicates that it is useful to use the word-level information given by the discriminator during the first-pass decoding.
3.3 RESULTS ON DESCRIPTIVE TEXT DATA
In this section, we validate our model on the descriptive text corpus: HappyDB(Asai et al., 2018). HappyDB is a corpus of 100,000+ crowd-sourced happy moments. Its content is mainly about events that make people happy in the past, and 83% of corpora contain only one sentence. We only use those instances that contain one sentence, and we get a total of 83711 happy moments. Table 2 shows the results on the automatic quantitative indicators, and we can see that DelibGAN-I and DelibGAN-II perform exceptionally well, with the ability of keeping the fluency of sentences, generating sentences different from that in the training corpus and generating a variety of sentences.
Further, we use human evaluation to evaluate generated sentences. Table 3 shows the results, and we can see DelibGAN-I and DelibGAN-II outperform other models, especially in topicality.
3.4 RESULTS ON SENTIMENTAL TEXT DATA
Here we validate our model on the sentimental text corpus: Stanford Sentiment Treebank (SSTB, Socher et al. (2013)), which contains 9613 sentimental reviews of movies. Tables 4 and 5 show the results of automatic quantitative indicators and human evaluation, respectively. Both results show that our models DelibGAN-I and DelibGAN-II produce more realistic samples of sentimental texts than other models, and DelibGAN-II performs best.
3.4.1 CASE STUDY
In Table 6, we show example sentences generated by DelibMLE, DelibGAN-I and DelibGAN-II. From the examples, we can see that: (1) In DelibMLE, there is no significant correlation between the first-pass decoding result G1 and the second-pass decoding result G2. (2) Compared with DelibGANI, DelibGAN-II is more likely to decode important words in G1, and those words behave like keywords in HappyDB and sentiment words in SSTB.

Table 4: Comparison of automatic quantitative indicators of generated sentences on SSTB corpus.

 means that the smaller the better, and  is the opposite.

Methods SeqGAN SentiGAN MaskGAN DelibMLE DelibGAN-I DelibGAN-II

Fluency() 98.253 82.554 83.967 89.365

75.573

71.365

Novelty() 0.298 0.344

0.342

0.348

0.387

0.393

Diversity() 0.641 0.711

0.723

0.673

0.734

0.740

7

Under review as a conference paper at ICLR 2019

Table 5: Comparison of human evaluation of generated sentences on SSTB corpus.

Methods

SeqGAN SentiGAN MaskGAN DelibMLE DelibGAN-I DelibGAN-II

Grammaticality 2.534 3.712

3.826

3.529

3.684

4.037

Topicality

2.164 3.231

3.567

3.471

3.973

4.304

Overall

2.865 3.284

3.483

3.197

4.082

4.243

Table 6: Examples sentences generated by our models trained on HappyDB and SSTB.

DelibMLE

G1 i got out . had a money money . . G2 i worked extra and well donut with really well recently .

HappyDB Corpus

DelibGAN-I

G1 G2

i got a new car . . . i purchased a new car for my family .

DelibGAN-II

G1 G2

i friends to to visit a games . weekend our friends came over to play video game last weekend .

SSTB Corpus

DelibMLE

G1 my <UNK>review : deeply deeply romantic film that cynicism G2 fantastic summer thrill ride !

DelibGAN-I

G1 G2

it was <UNK>. it was a very important classic !

DelibGAN-II

G1 G2

it funny . <UNK> us . a funny story for the former child star in all of us

4 RELATED WORK
Unsupervised text generation models are usually based on RNN(Mikolov et al., 2011), which easily suffers from exposure bias(Bengio et al., 2015) and the inconsistency between word-level loss function and sentence-level evaluation(Wang & Wan, 2018a). Several strategies have been exploited later, including Professor Forcing (Goyal et al., 2016), Scheduled SamplingBengio et al. (2015) and MaskMLE(Fedus et al., 2018).
Generative Adversarial Networks (GAN)(Goodfellow et al., 2014) has also been applied for text generation. Due to the non-differentiable problem and more complex modes of languages, the quality of generated texts are usually not very satisfactory. Some studies apply GAN in text generation by modifying the word prediction function, such as Gumbel-softmax distribution(Kusner & Herna´ndezLobato, 2016). Some other works apply reinforcement learning to solve the non-differentiable problem, including SeqGAN(Yu et al., 2017), LeakGAN(Guo et al., 2018), RankGAN(Lin et al., 2017), SentiGAN(Wang & Wan, 2018a) and MaskGAN(Fedus et al., 2018). However, they all adopt an one-pass forward decoding , which can only see words that have been decoded.
Recently, Deliberation networks(Xia et al., 2017), which has two decoders and produces better sequences by modifying sketches, has achieved good results on machine translation tasks. Later, Lapata & Dong (2018) also propose a similar structure and make meaningful settings for the sketches. But this is limited to specific tasks such as logical form parsing, code generation and SQL query generation. Moreover, these methods are supervised learning methods.
Multiple Instance Learning (MIL)(Keeler & Rumelhart, 1991) deals with problems where labels are associated with groups of instances or bags (sentences in our case), while instance labels (word-level importance in our case) are unobserved. The initial MIL makes a strong assumption that a bag is negative only if all of its instances are negative, and positive otherwise(Dietterich et al., 1997; Maron & Ratan, 1998; Zhang et al., 2002), and subsequent works relax this assumption and make it more suitable for the task at hand(Cour et al., 2011; Kotzias et al., 2015; Wang & Wan, 2018b).
5 CONCLUSIONS AND FUTURE WORK
In this paper, we propose a novel adversarial learning framework DelibGAN to generate high-quality sentences without supervision, by making use of a coarse-to-fine generator and a multiple instance discriminator. Evaluation results on various datasets verifies the efficacy of our proposed models. In future work, we will try to make the sketch more meaningful and apply our framework to more tasks.

8

Under review as a conference paper at ICLR 2019
REFERENCES
Akari Asai, Sara Evensen, Behzad Golshan, Alon Y. Halevy, Vivian Li, Andrei Lopatenko, Daniela Stepanov, Yoshihiko Suhara, Wang-Chiew Tan, and Yinzhan Xu. Happydb: A corpus of 100, 000 crowdsourced happy moments. In Proceedings of the Eleventh International Conference on Language Resources and Evaluation, LREC 2018, Miyazaki, Japan, May 7-12, 2018., 2018.
Philip Bachman and Doina Precup. Data generation as sequential decision making. In Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems 2015, December 7-12, 2015, Montreal, Quebec, Canada, pp. 3249­3257, 2015.
Samy Bengio, Oriol Vinyals, Navdeep Jaitly, and Noam Shazeer. Scheduled sampling for sequence prediction with recurrent neural networks. In Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems 2015, December 7-12, 2015, Montreal, Quebec, Canada, pp. 1171­1179, 2015.
Timothee Cour, Ben Sapp, and Ben Taskar. Learning from partial labels. Journal of Machine Learning Research, 12(4):1501­1536, 2011.
Bo Dai, Sanja Fidler, Raquel Urtasun, and Dahua Lin. Towards diverse and natural image descriptions via a conditional GAN. In IEEE International Conference on Computer Vision, ICCV 2017, Venice, Italy, October 22-29, 2017, pp. 2989­2998, 2017. doi: 10.1109/ICCV.2017.323.
Thomas G. Dietterich, Richard H. Lathrop, and Toma´s Lozano-Pe´rez. Solving the multiple instance problem with axis-parallel rectangles. Artif. Intell., 89(1-2):31­71, 1997. doi: 10.1016/ S0004-3702(96)00034-3.
William Fedus, Ian J. Goodfellow, and Andrew M. Dai. Maskgan: Better text generation via filling in the . In ICLR, 2018, 2018.
Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron C. Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in Neural Information Processing Systems 27: Annual Conference on Neural Information Processing Systems 2014, December 8-13 2014, Montreal, Quebec, Canada, pp. 2672­2680, 2014.
Anirudh Goyal, Alex Lamb, Ying Zhang, Saizheng Zhang, Aaron C. Courville, and Yoshua Bengio. Professor forcing: A new algorithm for training recurrent networks. In Advances in Neural Information Processing Systems 29: Annual Conference on Neural Information Processing Systems 2016, December 5-10, 2016, Barcelona, Spain, pp. 4601­4609, 2016.
Jiaxian Guo, Sidi Lu, Han Cai, Weinan Zhang, Yong Yu, and Jun Wang. Long text generation via adversarial training with leaked information. In Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, New Orleans, Louisiana, USA, February 2-7, 2018, 2018.
James D. Keeler and David E. Rumelhart. A self-organizing integrated segmentation and recognition neural net. In Advances in Neural Information Processing Systems 4, [NIPS Conference, Denver, Colorado, USA, December 2-5, 1991], pp. 496­503, 1991.
Dimitrios Kotzias, Misha Denil, Nando De Freitas, and Padhraic Smyth. From group to individual labels using deep features. In ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 597­606, 2015.
Matt J. Kusner and Jose´ Miguel Herna´ndez-Lobato. GANS for sequences of discrete elements with the gumbel-softmax distribution. CoRR, abs/1611.04051, 2016.
Mirella Lapata and Li Dong. Coarse-to-fine decoding for neural semantic parsing. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018, Melbourne, Australia, July 15-20, 2018, Volume 1: Long Papers, pp. 731­742, 2018.
Kevin Lin, Dianqi Li, Xiaodong He, Ming-Ting Sun, and Zhengyou Zhang. Adversarial ranking for language generation. In Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, 4-9 December 2017, Long Beach, CA, USA, pp. 3158­3168, 2017.
9

Under review as a conference paper at ICLR 2019
Oded Maron and Aparna Lakshmi Ratan. Multiple-instance learning for natural scene classification. In Proceedings of the Fifteenth International Conference on Machine Learning (ICML 1998), Madison, Wisconsin, USA, July 24-27, 1998, pp. 341­349, 1998.
Tomas Mikolov, Stefan Kombrink, Luka´s Burget, Jan Cernocky´, and Sanjeev Khudanpur. Extensions of recurrent neural network language model. In Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, ICASSP 2011, May 22-27, 2011, Prague Congress Center, Prague, Czech Republic, pp. 5528­5531, 2011. doi: 10.1109/ICASSP.2011. 5947611.
Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D. Manning, Andrew Y. Ng, and Christopher Potts. Recursive deep models for semantic compositionality over a sentiment treebank. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, EMNLP 2013, 18-21 October 2013, Grand Hyatt Seattle, Seattle, Washington, USA, A meeting of SIGDAT, a Special Interest Group of the ACL, pp. 1631­1642, 2013.
Andreas Stolcke. Srilm an extensible language modeling toolkit. 2002. Ke Wang and Xiaojun Wan. Sentigan: Generating sentimental texts via mixture adversarial net-
works. In Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence, IJCAI 2018, July 13-19, 2018, Stockholm, Sweden., pp. 4446­4452, 2018a. doi: 10.24963/ijcai.2018/618. Ke Wang and Xiaojun Wan. Sentiment analysis of peer review texts for scholarly papers. In The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval, SIGIR 2018, Ann Arbor, MI, USA, July 08-12, 2018, pp. 175­184, 2018b. doi: 10.1145/3209978. 3210056. Yingce Xia, Fei Tian, Lijun Wu, Jianxin Lin, Tao Qin, Nenghai Yu, and Tie-Yan Liu. Deliberation networks: Sequence generation beyond one-pass decoding. In Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, 4-9 December 2017, Long Beach, CA, USA, pp. 1782­1792, 2017. Lantao Yu, Weinan Zhang, Jun Wang, and Yong Yu. Seqgan: Sequence generative adversarial nets with policy gradient. In Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence, February 4-9, 2017, San Francisco, California, USA., pp. 2852­2858, 2017. Qi Zhang, Sally A. Goldman, Wei Yu, and Jason Fritts. Content-based image retrieval using multiple-instance learning. In Nineteenth International Conference on Machine Learning, pp. 682­689, 2002.
10

